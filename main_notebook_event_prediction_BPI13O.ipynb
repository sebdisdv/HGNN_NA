{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sebdis/ProcessMining/HGNN/HGNN_NA\n",
      "/home/sebdis/ProcessMining/HGNN/HGNN_NA/data/datasets/original/\n",
      "/home/sebdis/ProcessMining/HGNN/HGNN_NA/data/datasets/processed/\n",
      "/home/sebdis/ProcessMining/HGNN/HGNN_NA/data/datasets/graphs/\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from os.path import dirname\n",
    "\n",
    "\n",
    "\n",
    "root_path = dirname(os.getcwd()) + \"/HGNN_NA\"\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "data_dir = root_path + \"/data/datasets/original/\"\n",
    "data_dir_processed = root_path + \"/data/datasets/processed/\"\n",
    "data_dir_graphs = root_path + \"/data/datasets/graphs/\"\n",
    "\n",
    "print(root_path, data_dir, data_dir_processed, data_dir_graphs, sep=\"\\n\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"BPI_Challenge_2013_open_problems\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['org:group', 'resource country', 'org:resource', 'oranization country',\n",
    "       'org:role', 'Activity', 'impact', 'product', \"org:resource:role\"]\n",
    "real_value_columns = [\"time:timestamp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>org:group</th>\n",
       "      <th>resource country</th>\n",
       "      <th>org:resource</th>\n",
       "      <th>oranization country</th>\n",
       "      <th>org:role</th>\n",
       "      <th>Activity</th>\n",
       "      <th>impact</th>\n",
       "      <th>product</th>\n",
       "      <th>time:timestamp</th>\n",
       "      <th>CaseID</th>\n",
       "      <th>org:resource:role</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Org line A2</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Tomas</td>\n",
       "      <td>cn</td>\n",
       "      <td>A2_2</td>\n",
       "      <td>Accepted_In Progress</td>\n",
       "      <td>Medium</td>\n",
       "      <td>PROD753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1-147898401</td>\n",
       "      <td>Role 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Org line A2</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Tomas</td>\n",
       "      <td>cn</td>\n",
       "      <td>A2_2</td>\n",
       "      <td>Accepted_In Progress</td>\n",
       "      <td>Medium</td>\n",
       "      <td>PROD753</td>\n",
       "      <td>9.315421</td>\n",
       "      <td>1-147898401</td>\n",
       "      <td>Role 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Org line A2</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Tomas</td>\n",
       "      <td>cn</td>\n",
       "      <td>A2_2</td>\n",
       "      <td>Accepted_Wait</td>\n",
       "      <td>Medium</td>\n",
       "      <td>PROD753</td>\n",
       "      <td>18.388883</td>\n",
       "      <td>1-147898401</td>\n",
       "      <td>Role 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Org line A2</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Tomas</td>\n",
       "      <td>cn</td>\n",
       "      <td>A2_2</td>\n",
       "      <td>Accepted_In Progress</td>\n",
       "      <td>Medium</td>\n",
       "      <td>PROD753</td>\n",
       "      <td>18.840289</td>\n",
       "      <td>1-147898401</td>\n",
       "      <td>Role 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Org line A2</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>Tomas</td>\n",
       "      <td>cn</td>\n",
       "      <td>A2_2</td>\n",
       "      <td>Accepted_In Progress</td>\n",
       "      <td>Medium</td>\n",
       "      <td>PROD753</td>\n",
       "      <td>16.256809</td>\n",
       "      <td>1-165554831</td>\n",
       "      <td>Role 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     org:group resource country org:resource oranization country org:role  \\\n",
       "0  Org line A2           Sweden        Tomas                  cn     A2_2   \n",
       "1  Org line A2           Sweden        Tomas                  cn     A2_2   \n",
       "2  Org line A2           Sweden        Tomas                  cn     A2_2   \n",
       "3  Org line A2           Sweden        Tomas                  cn     A2_2   \n",
       "4  Org line A2           Sweden        Tomas                  cn     A2_2   \n",
       "\n",
       "               Activity  impact  product  time:timestamp       CaseID  \\\n",
       "0  Accepted_In Progress  Medium  PROD753        0.000000  1-147898401   \n",
       "1  Accepted_In Progress  Medium  PROD753        9.315421  1-147898401   \n",
       "2         Accepted_Wait  Medium  PROD753       18.388883  1-147898401   \n",
       "3  Accepted_In Progress  Medium  PROD753       18.840289  1-147898401   \n",
       "4  Accepted_In Progress  Medium  PROD753       16.256809  1-165554831   \n",
       "\n",
       "  org:resource:role  \n",
       "0            Role 1  \n",
       "1            Role 1  \n",
       "2            Role 1  \n",
       "3            Role 1  \n",
       "4            Role 1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab_all = pd.read_csv(data_dir_processed+dataset+\"_processed_all.csv\")\n",
    "tab_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Tomas': 'Role 1',\n",
       " 'Niklas': 'Role 1',\n",
       " 'Ewa': 'Role 1',\n",
       " 'Pawel': 'Role 1',\n",
       " 'Panigrahy': 'Role 1',\n",
       " 'Jerker': 'Role 1',\n",
       " 'Srinivasan': 'Role 1',\n",
       " 'Aneesh V': 'Role 1',\n",
       " 'Rijin': 'Role 1',\n",
       " 'Celine': 'Role 1',\n",
       " 'Anna': 'Role 1',\n",
       " 'Sumesh': 'Role 1',\n",
       " 'Prasad': 'Role 1',\n",
       " 'Peter': 'Role 1',\n",
       " 'Craig': 'Role 1',\n",
       " 'Stefan': 'Role 1',\n",
       " 'David': 'Role 1',\n",
       " 'Jonas': 'Role 1',\n",
       " 'Joakim': 'Role 1',\n",
       " 'Per': 'Role 1',\n",
       " 'Stephen': 'Role 1',\n",
       " 'Christer': 'Role 1',\n",
       " 'Ing-Marie': 'Role 1',\n",
       " 'Nicolas': 'Role 1',\n",
       " 'Kenneth': 'Role 1',\n",
       " 'Fredrik': 'Role 1',\n",
       " 'Viktoria': 'Role 1',\n",
       " 'Roland': 'Role 1',\n",
       " 'Marco': 'Role 1',\n",
       " 'Katarina': 'Role 1',\n",
       " 'Ian': 'Role 1',\n",
       " 'Martin': 'Role 1',\n",
       " 'Olivier': 'Role 1',\n",
       " 'Britt': 'Role 1',\n",
       " 'Michal': 'Role 1',\n",
       " 'Timothy': 'Role 1',\n",
       " 'Andrew': 'Role 1',\n",
       " 'Mikael': 'Role 1',\n",
       " 'Erik': 'Role 1',\n",
       " 'Arun': 'Role 1',\n",
       " 'Els': 'Role 1',\n",
       " 'Jo': 'Role 1',\n",
       " 'Lars': 'Role 1',\n",
       " 'Daniel': 'Role 1',\n",
       " 'Rickard': 'Role 1',\n",
       " 'Thiago': 'Role 1',\n",
       " 'Cyril': 'Role 1',\n",
       " 'Mattias': 'Role 1',\n",
       " 'Bharath': 'Role 1',\n",
       " 'Praveen': 'Role 1',\n",
       " 'Steve': 'Role 1',\n",
       " 'Murali': 'Role 1',\n",
       " 'Rohan': 'Role 1',\n",
       " 'Wim': 'Role 1',\n",
       " 'Inger': 'Role 1',\n",
       " 'Frederic': 'Role 1',\n",
       " 'Miroslaw': 'Role 1',\n",
       " 'Lena': 'Role 1',\n",
       " 'Radoslaw': 'Role 1',\n",
       " 'Robert': 'Role 1',\n",
       " 'Anup': 'Role 1',\n",
       " 'Lars-Ove': 'Role 1',\n",
       " 'Jörgen': 'Role 1',\n",
       " 'Hineesh': 'Role 1',\n",
       " 'Carlos': 'Role 1',\n",
       " 'Adam': 'Role 1',\n",
       " 'Ann-Charlotte': 'Role 1',\n",
       " 'Mats': 'Role 1',\n",
       " 'Olle': 'Role 1',\n",
       " 'Richard': 'Role 1',\n",
       " 'Samira': 'Role 1',\n",
       " 'Vikrant': 'Role 1',\n",
       " 'Kymaria': 'Role 1',\n",
       " 'Agneta': 'Role 1',\n",
       " 'Ramith': 'Role 1',\n",
       " 'Urban': 'Role 1',\n",
       " 'Börje': 'Role 1',\n",
       " 'Lennart': 'Role 1',\n",
       " 'Andreas': 'Role 1',\n",
       " 'Sameer': 'Role 1',\n",
       " 'Partha': 'Role 1',\n",
       " 'Jari': 'Role 1',\n",
       " 'Bruno': 'Role 1',\n",
       " 'Alan': 'Role 1',\n",
       " '-': 'Role 1',\n",
       " 'Vesa': 'Role 1',\n",
       " 'Freddy': 'Role 1',\n",
       " 'Pascal': 'Role 1',\n",
       " 'Maria': 'Role 1',\n",
       " 'Kristina': 'Role 1',\n",
       " 'Bikshamaiah': 'Role 1',\n",
       " 'Marie': 'Role 1',\n",
       " 'Venkata': 'Role 1',\n",
       " 'Michel': 'Role 1',\n",
       " 'Rakesh': 'Role 1',\n",
       " 'Leif': 'Role 1',\n",
       " 'Rajkishore': 'Role 1',\n",
       " 'Vaibhav': 'Role 1',\n",
       " 'Kjell': 'Role 1',\n",
       " 'Jitender': 'Role 1',\n",
       " 'Håkan': 'Role 1',\n",
       " 'Fabrice': 'Role 1',\n",
       " 'Tomasz': 'Role 1',\n",
       " 'Paulina': 'Role 1',\n",
       " 'Kåre': 'Role 1',\n",
       " 'Marc': 'Role 1',\n",
       " 'Santosh': 'Role 1',\n",
       " 'Amar': 'Role 1',\n",
       " 'Jay': 'Role 1',\n",
       " 'Rajesh Kumar': 'Role 1',\n",
       " 'Emil': 'Role 1',\n",
       " 'Saki': 'Role 1',\n",
       " 'Anson': 'Role 1',\n",
       " 'Krzysztof': 'Role 1',\n",
       " 'Piotr': 'Role 1',\n",
       " 'Laurens': 'Role 1',\n",
       " 'Ryouhei': 'Role 1',\n",
       " 'John': 'Role 1',\n",
       " 'Dusan': 'Role 1',\n",
       " 'Ganesh': 'Role 1',\n",
       " 'Anandgiri': 'Role 1',\n",
       " 'Gaurav': 'Role 1',\n",
       " 'Mohsin': 'Role 1',\n",
       " 'Rohit': 'Role 1',\n",
       " 'Gitt': 'Role 1',\n",
       " 'Vinodhkumar': 'Role 1',\n",
       " 'Umar Farooque': 'Role 1',\n",
       " 'Pankaj': 'Role 1',\n",
       " 'Raja': 'Role 1',\n",
       " 'Aurelien': 'Role 1',\n",
       " 'Tarun': 'Role 1',\n",
       " 'Harshavardhan': 'Role 1',\n",
       " 'Åsa': 'Role 1',\n",
       " 'Himanshu': 'Role 1',\n",
       " 'Przemyslaw': 'Role 1',\n",
       " 'Pratap': 'Role 1',\n",
       " 'Joacim': 'Role 1',\n",
       " 'Alice': 'Role 1',\n",
       " 'Jesper': 'Role 1',\n",
       " 'Olof': 'Role 1',\n",
       " 'Joris': 'Role 1',\n",
       " 'Katarzyna': 'Role 1',\n",
       " 'Grzegorz': 'Role 1',\n",
       " 'Marcin': 'Role 1',\n",
       " 'Diogo': 'Role 1',\n",
       " 'Björn': 'Role 1',\n",
       " 'Raphael': 'Role 1',\n",
       " 'Eva': 'Role 1',\n",
       " 'Jon': 'Role 1',\n",
       " 'Patrick': 'Role 1',\n",
       " 'Vijayakumar': 'Role 1',\n",
       " 'Maciej': 'Role 1',\n",
       " 'Avvaru': 'Role 1',\n",
       " 'Joey': 'Role 1',\n",
       " 'Marianne': 'Role 1',\n",
       " 'Göran': 'Role 1',\n",
       " 'Jimmy': 'Role 1',\n",
       " 'Henrik': 'Role 1',\n",
       " 'Hicham': 'Role 1',\n",
       " 'Johan': 'Role 1',\n",
       " 'Kell': 'Role 1',\n",
       " 'Valter': 'Role 1',\n",
       " 'Marise': 'Role 1',\n",
       " 'Stephane': 'Role 1',\n",
       " 'Arup': 'Role 1',\n",
       " 'Mathias': 'Role 1',\n",
       " 'James': 'Role 1',\n",
       " 'Henrique': 'Role 1',\n",
       " 'Devakumar': 'Role 1',\n",
       " 'Christoffer': 'Role 1',\n",
       " 'Gunilla': 'Role 1',\n",
       " 'Susan': 'Role 1',\n",
       " 'Michael': 'Role 1',\n",
       " 'Jennifer': 'Role 1',\n",
       " 'Steven': 'Role 1',\n",
       " 'Marilyn': 'Role 1',\n",
       " 'Katia': 'Role 1',\n",
       " 'Ilona': 'Role 1',\n",
       " 'Emmanuel': 'Role 1',\n",
       " 'Alain': 'Role 1',\n",
       " 'Amitabh': 'Role 1',\n",
       " 'Jubin': 'Role 1',\n",
       " 'Mariusz': 'Role 1',\n",
       " 'Hampus': 'Role 1',\n",
       " 'Thomas': 'Role 1',\n",
       " 'Kim': 'Role 1',\n",
       " 'Bhaskar': 'Role 1',\n",
       " 'Louis': 'Role 1',\n",
       " 'Rosemary': 'Role 1',\n",
       " 'Fiona': 'Role 1',\n",
       " 'Christian': 'Role 1',\n",
       " 'Hongming': 'Role 1',\n",
       " 'Flavio': 'Role 1',\n",
       " 'Jonathan': 'Role 1',\n",
       " 'Janusz': 'Role 1',\n",
       " 'Astrid': 'Role 1',\n",
       " 'Shamna': 'Role 1',\n",
       " 'Avronil': 'Role 1',\n",
       " 'Ingela': 'Role 1',\n",
       " 'Pramod': 'Role 1',\n",
       " 'Lars-Göran': 'Role 1',\n",
       " 'Kreeti': 'Role 1',\n",
       " 'Sandeep': 'Role 1',\n",
       " 'Ranveer': 'Role 1',\n",
       " 'Habib': 'Role 1',\n",
       " 'Johnny': 'Role 1',\n",
       " 'Rolf': 'Role 1',\n",
       " 'Yu': 'Role 1',\n",
       " 'Charlotta': 'Role 1',\n",
       " 'Bartlomiej': 'Role 1',\n",
       " 'Carla': 'Role 1',\n",
       " 'Cindy': 'Role 1',\n",
       " 'William': 'Role 2',\n",
       " 'Ruhi': 'Role 1',\n",
       " 'Tonie': 'Role 1',\n",
       " 'Rajendra': 'Role 1',\n",
       " 'Atul': 'Role 1',\n",
       " 'Linda': 'Role 1',\n",
       " 'Ludwig': 'Role 1',\n",
       " 'Jagannath': 'Role 1',\n",
       " 'Amit': 'Role 1',\n",
       " 'Parbhat': 'Role 1',\n",
       " 'Ankit': 'Role 1',\n",
       " 'Ratikanta': 'Role 1',\n",
       " 'Jenny': 'Role 1',\n",
       " 'Sujith': 'Role 1',\n",
       " 'Ryou': 'Role 1',\n",
       " 'Eric': 'Role 1',\n",
       " 'Manisha': 'Role 1',\n",
       " 'Sachin': 'Role 1',\n",
       " 'Neeraj': 'Role 1',\n",
       " 'Sophie': 'Role 1',\n",
       " 'Aurelie': 'Role 1',\n",
       " 'Milos': 'Role 1',\n",
       " 'Conny': 'Role 1',\n",
       " 'Sten': 'Role 1',\n",
       " 'Krystian': 'Role 1',\n",
       " 'Lotta': 'Role 1',\n",
       " 'Christophe': 'Role 1',\n",
       " 'Hanna': 'Role 1'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data import utils\n",
    "\n",
    "one_hot_resource = utils.get_one_hot_encoder(tab_all, \"org:resource\")\n",
    "one_hot_resource_role = utils.get_one_hot_encoder(tab_all, \"org:resource:role\")\n",
    "resources = tab_all[\"org:resource\"]\n",
    "resources_role = tab_all[\"org:resource:role\"]\n",
    "map_resource_to_role = {}\n",
    "for i in range(len(resources)):\n",
    "    map_resource_to_role[resources[i]] = resources_role[i]\n",
    "\n",
    "map_resource_to_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Tomas': 223,\n",
       " 'Niklas': 159,\n",
       " 'Ewa': 57,\n",
       " 'Pawel': 170,\n",
       " 'Panigrahy': 163,\n",
       " 'Jerker': 93,\n",
       " 'Srinivasan': 209,\n",
       " 'Aneesh V': 12,\n",
       " 'Rijin': 191,\n",
       " 'Celine': 36,\n",
       " 'Anna': 15,\n",
       " 'Sumesh': 217,\n",
       " 'Prasad': 175,\n",
       " 'Peter': 172,\n",
       " 'Craig': 44,\n",
       " 'Stefan': 210,\n",
       " 'David': 47,\n",
       " 'Jonas': 105,\n",
       " 'Joakim': 99,\n",
       " 'Per': 171,\n",
       " 'Stephen': 213,\n",
       " 'Christer': 38,\n",
       " 'Ing-Marie': 83,\n",
       " 'Nicolas': 158,\n",
       " 'Kenneth': 114,\n",
       " 'Fredrik': 63,\n",
       " 'Viktoria': 234,\n",
       " 'Roland': 195,\n",
       " 'Marco': 138,\n",
       " 'Katarina': 110,\n",
       " 'Ian': 81,\n",
       " 'Martin': 145,\n",
       " 'Olivier': 160,\n",
       " 'Britt': 31,\n",
       " 'Michal': 150,\n",
       " 'Timothy': 222,\n",
       " 'Andrew': 11,\n",
       " 'Mikael': 152,\n",
       " 'Erik': 55,\n",
       " 'Arun': 18,\n",
       " 'Els': 51,\n",
       " 'Jo': 97,\n",
       " 'Lars': 123,\n",
       " 'Daniel': 46,\n",
       " 'Rickard': 190,\n",
       " 'Thiago': 220,\n",
       " 'Cyril': 45,\n",
       " 'Mattias': 148,\n",
       " 'Bharath': 27,\n",
       " 'Praveen': 177,\n",
       " 'Steve': 214,\n",
       " 'Murali': 156,\n",
       " 'Rohan': 193,\n",
       " 'Wim': 237,\n",
       " 'Inger': 85,\n",
       " 'Frederic': 62,\n",
       " 'Miroslaw': 154,\n",
       " 'Lena': 128,\n",
       " 'Radoslaw': 179,\n",
       " 'Robert': 192,\n",
       " 'Anup': 17,\n",
       " 'Lars-Ove': 125,\n",
       " 'Jörgen': 109,\n",
       " 'Hineesh': 78,\n",
       " 'Carlos': 35,\n",
       " 'Adam': 1,\n",
       " 'Ann-Charlotte': 14,\n",
       " 'Mats': 147,\n",
       " 'Olle': 161,\n",
       " 'Richard': 189,\n",
       " 'Samira': 204,\n",
       " 'Vikrant': 233,\n",
       " 'Kymaria': 121,\n",
       " 'Agneta': 2,\n",
       " 'Ramith': 185,\n",
       " 'Urban': 227,\n",
       " 'Börje': 33,\n",
       " 'Lennart': 129,\n",
       " 'Andreas': 10,\n",
       " 'Sameer': 203,\n",
       " 'Partha': 166,\n",
       " 'Jari': 89,\n",
       " 'Bruno': 32,\n",
       " 'Alan': 4,\n",
       " '-': 0,\n",
       " 'Vesa': 231,\n",
       " 'Freddy': 61,\n",
       " 'Pascal': 167,\n",
       " 'Maria': 139,\n",
       " 'Kristina': 118,\n",
       " 'Bikshamaiah': 29,\n",
       " 'Marie': 141,\n",
       " 'Venkata': 230,\n",
       " 'Michel': 151,\n",
       " 'Rakesh': 184,\n",
       " 'Leif': 127,\n",
       " 'Rajkishore': 183,\n",
       " 'Vaibhav': 228,\n",
       " 'Kjell': 116,\n",
       " 'Jitender': 96,\n",
       " 'Håkan': 80,\n",
       " 'Fabrice': 58,\n",
       " 'Tomasz': 224,\n",
       " 'Paulina': 169,\n",
       " 'Kåre': 122,\n",
       " 'Marc': 136,\n",
       " 'Santosh': 206,\n",
       " 'Amar': 6,\n",
       " 'Jay': 90,\n",
       " 'Rajesh Kumar': 182,\n",
       " 'Emil': 52,\n",
       " 'Saki': 202,\n",
       " 'Anson': 16,\n",
       " 'Krzysztof': 120,\n",
       " 'Piotr': 173,\n",
       " 'Laurens': 126,\n",
       " 'Ryouhei': 200,\n",
       " 'John': 102,\n",
       " 'Dusan': 50,\n",
       " 'Ganesh': 64,\n",
       " 'Anandgiri': 9,\n",
       " 'Gaurav': 65,\n",
       " 'Mohsin': 155,\n",
       " 'Rohit': 194,\n",
       " 'Gitt': 66,\n",
       " 'Vinodhkumar': 235,\n",
       " 'Umar Farooque': 226,\n",
       " 'Pankaj': 164,\n",
       " 'Raja': 180,\n",
       " 'Aurelien': 23,\n",
       " 'Tarun': 219,\n",
       " 'Harshavardhan': 73,\n",
       " 'Åsa': 239,\n",
       " 'Himanshu': 77,\n",
       " 'Przemyslaw': 178,\n",
       " 'Pratap': 176,\n",
       " 'Joacim': 98,\n",
       " 'Alice': 5,\n",
       " 'Jesper': 94,\n",
       " 'Olof': 162,\n",
       " 'Joris': 107,\n",
       " 'Katarzyna': 111,\n",
       " 'Grzegorz': 67,\n",
       " 'Marcin': 137,\n",
       " 'Diogo': 49,\n",
       " 'Björn': 30,\n",
       " 'Raphael': 187,\n",
       " 'Eva': 56,\n",
       " 'Jon': 104,\n",
       " 'Patrick': 168,\n",
       " 'Vijayakumar': 232,\n",
       " 'Maciej': 134,\n",
       " 'Avvaru': 25,\n",
       " 'Joey': 100,\n",
       " 'Marianne': 140,\n",
       " 'Göran': 69,\n",
       " 'Jimmy': 95,\n",
       " 'Henrik': 74,\n",
       " 'Hicham': 76,\n",
       " 'Johan': 101,\n",
       " 'Kell': 113,\n",
       " 'Valter': 229,\n",
       " 'Marise': 143,\n",
       " 'Stephane': 212,\n",
       " 'Arup': 19,\n",
       " 'Mathias': 146,\n",
       " 'James': 87,\n",
       " 'Henrique': 75,\n",
       " 'Devakumar': 48,\n",
       " 'Christoffer': 40,\n",
       " 'Gunilla': 68,\n",
       " 'Susan': 218,\n",
       " 'Michael': 149,\n",
       " 'Jennifer': 91,\n",
       " 'Steven': 215,\n",
       " 'Marilyn': 142,\n",
       " 'Katia': 112,\n",
       " 'Ilona': 82,\n",
       " 'Emmanuel': 53,\n",
       " 'Alain': 3,\n",
       " 'Amitabh': 8,\n",
       " 'Jubin': 108,\n",
       " 'Mariusz': 144,\n",
       " 'Hampus': 71,\n",
       " 'Thomas': 221,\n",
       " 'Kim': 115,\n",
       " 'Bhaskar': 28,\n",
       " 'Louis': 132,\n",
       " 'Rosemary': 197,\n",
       " 'Fiona': 59,\n",
       " 'Christian': 39,\n",
       " 'Hongming': 79,\n",
       " 'Flavio': 60,\n",
       " 'Jonathan': 106,\n",
       " 'Janusz': 88,\n",
       " 'Astrid': 20,\n",
       " 'Shamna': 207,\n",
       " 'Avronil': 24,\n",
       " 'Ingela': 84,\n",
       " 'Pramod': 174,\n",
       " 'Lars-Göran': 124,\n",
       " 'Kreeti': 117,\n",
       " 'Sandeep': 205,\n",
       " 'Ranveer': 186,\n",
       " 'Habib': 70,\n",
       " 'Johnny': 103,\n",
       " 'Rolf': 196,\n",
       " 'Yu': 238,\n",
       " 'Charlotta': 37,\n",
       " 'Bartlomiej': 26,\n",
       " 'Carla': 34,\n",
       " 'Cindy': 42,\n",
       " 'William': 236,\n",
       " 'Ruhi': 198,\n",
       " 'Tonie': 225,\n",
       " 'Rajendra': 181,\n",
       " 'Atul': 21,\n",
       " 'Linda': 130,\n",
       " 'Ludwig': 133,\n",
       " 'Jagannath': 86,\n",
       " 'Amit': 7,\n",
       " 'Parbhat': 165,\n",
       " 'Ankit': 13,\n",
       " 'Ratikanta': 188,\n",
       " 'Jenny': 92,\n",
       " 'Sujith': 216,\n",
       " 'Ryou': 199,\n",
       " 'Eric': 54,\n",
       " 'Manisha': 135,\n",
       " 'Sachin': 201,\n",
       " 'Neeraj': 157,\n",
       " 'Sophie': 208,\n",
       " 'Aurelie': 22,\n",
       " 'Milos': 153,\n",
       " 'Conny': 43,\n",
       " 'Sten': 211,\n",
       " 'Krystian': 119,\n",
       " 'Lotta': 131,\n",
       " 'Christophe': 41,\n",
       " 'Hanna': 72}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_resource_index = {}\n",
    "for x in tab_all[\"org:resource\"].unique():\n",
    "    map_resource_index[x] = torch.argmax(torch.tensor(utils.get_one_hot_encodings(one_hot_resource, np.array([x])))).item()\n",
    "map_resource_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Role 1': 0, 'Role 2': 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_resource_role_index = {}\n",
    "for x in tab_all[\"org:resource:role\"].unique():\n",
    "    map_resource_role_index[x] = torch.argmax(torch.tensor(utils.get_one_hot_encodings(one_hot_resource_role, np.array([x])))).item()\n",
    "map_resource_role_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{223: 0,\n",
       " 159: 0,\n",
       " 57: 0,\n",
       " 170: 0,\n",
       " 163: 0,\n",
       " 93: 0,\n",
       " 209: 0,\n",
       " 12: 0,\n",
       " 191: 0,\n",
       " 36: 0,\n",
       " 15: 0,\n",
       " 217: 0,\n",
       " 175: 0,\n",
       " 172: 0,\n",
       " 44: 0,\n",
       " 210: 0,\n",
       " 47: 0,\n",
       " 105: 0,\n",
       " 99: 0,\n",
       " 171: 0,\n",
       " 213: 0,\n",
       " 38: 0,\n",
       " 83: 0,\n",
       " 158: 0,\n",
       " 114: 0,\n",
       " 63: 0,\n",
       " 234: 0,\n",
       " 195: 0,\n",
       " 138: 0,\n",
       " 110: 0,\n",
       " 81: 0,\n",
       " 145: 0,\n",
       " 160: 0,\n",
       " 31: 0,\n",
       " 150: 0,\n",
       " 222: 0,\n",
       " 11: 0,\n",
       " 152: 0,\n",
       " 55: 0,\n",
       " 18: 0,\n",
       " 51: 0,\n",
       " 97: 0,\n",
       " 123: 0,\n",
       " 46: 0,\n",
       " 190: 0,\n",
       " 220: 0,\n",
       " 45: 0,\n",
       " 148: 0,\n",
       " 27: 0,\n",
       " 177: 0,\n",
       " 214: 0,\n",
       " 156: 0,\n",
       " 193: 0,\n",
       " 237: 0,\n",
       " 85: 0,\n",
       " 62: 0,\n",
       " 154: 0,\n",
       " 128: 0,\n",
       " 179: 0,\n",
       " 192: 0,\n",
       " 17: 0,\n",
       " 125: 0,\n",
       " 109: 0,\n",
       " 78: 0,\n",
       " 35: 0,\n",
       " 1: 0,\n",
       " 14: 0,\n",
       " 147: 0,\n",
       " 161: 0,\n",
       " 189: 0,\n",
       " 204: 0,\n",
       " 233: 0,\n",
       " 121: 0,\n",
       " 2: 0,\n",
       " 185: 0,\n",
       " 227: 0,\n",
       " 33: 0,\n",
       " 129: 0,\n",
       " 10: 0,\n",
       " 203: 0,\n",
       " 166: 0,\n",
       " 89: 0,\n",
       " 32: 0,\n",
       " 4: 0,\n",
       " 0: 0,\n",
       " 231: 0,\n",
       " 61: 0,\n",
       " 167: 0,\n",
       " 139: 0,\n",
       " 118: 0,\n",
       " 29: 0,\n",
       " 141: 0,\n",
       " 230: 0,\n",
       " 151: 0,\n",
       " 184: 0,\n",
       " 127: 0,\n",
       " 183: 0,\n",
       " 228: 0,\n",
       " 116: 0,\n",
       " 96: 0,\n",
       " 80: 0,\n",
       " 58: 0,\n",
       " 224: 0,\n",
       " 169: 0,\n",
       " 122: 0,\n",
       " 136: 0,\n",
       " 206: 0,\n",
       " 6: 0,\n",
       " 90: 0,\n",
       " 182: 0,\n",
       " 52: 0,\n",
       " 202: 0,\n",
       " 16: 0,\n",
       " 120: 0,\n",
       " 173: 0,\n",
       " 126: 0,\n",
       " 200: 0,\n",
       " 102: 0,\n",
       " 50: 0,\n",
       " 64: 0,\n",
       " 9: 0,\n",
       " 65: 0,\n",
       " 155: 0,\n",
       " 194: 0,\n",
       " 66: 0,\n",
       " 235: 0,\n",
       " 226: 0,\n",
       " 164: 0,\n",
       " 180: 0,\n",
       " 23: 0,\n",
       " 219: 0,\n",
       " 73: 0,\n",
       " 239: 0,\n",
       " 77: 0,\n",
       " 178: 0,\n",
       " 176: 0,\n",
       " 98: 0,\n",
       " 5: 0,\n",
       " 94: 0,\n",
       " 162: 0,\n",
       " 107: 0,\n",
       " 111: 0,\n",
       " 67: 0,\n",
       " 137: 0,\n",
       " 49: 0,\n",
       " 30: 0,\n",
       " 187: 0,\n",
       " 56: 0,\n",
       " 104: 0,\n",
       " 168: 0,\n",
       " 232: 0,\n",
       " 134: 0,\n",
       " 25: 0,\n",
       " 100: 0,\n",
       " 140: 0,\n",
       " 69: 0,\n",
       " 95: 0,\n",
       " 74: 0,\n",
       " 76: 0,\n",
       " 101: 0,\n",
       " 113: 0,\n",
       " 229: 0,\n",
       " 143: 0,\n",
       " 212: 0,\n",
       " 19: 0,\n",
       " 146: 0,\n",
       " 87: 0,\n",
       " 75: 0,\n",
       " 48: 0,\n",
       " 40: 0,\n",
       " 68: 0,\n",
       " 218: 0,\n",
       " 149: 0,\n",
       " 91: 0,\n",
       " 215: 0,\n",
       " 142: 0,\n",
       " 112: 0,\n",
       " 82: 0,\n",
       " 53: 0,\n",
       " 3: 0,\n",
       " 8: 0,\n",
       " 108: 0,\n",
       " 144: 0,\n",
       " 71: 0,\n",
       " 221: 0,\n",
       " 115: 0,\n",
       " 28: 0,\n",
       " 132: 0,\n",
       " 197: 0,\n",
       " 59: 0,\n",
       " 39: 0,\n",
       " 79: 0,\n",
       " 60: 0,\n",
       " 106: 0,\n",
       " 88: 0,\n",
       " 20: 0,\n",
       " 207: 0,\n",
       " 24: 0,\n",
       " 84: 0,\n",
       " 174: 0,\n",
       " 124: 0,\n",
       " 117: 0,\n",
       " 205: 0,\n",
       " 186: 0,\n",
       " 70: 0,\n",
       " 103: 0,\n",
       " 196: 0,\n",
       " 238: 0,\n",
       " 37: 0,\n",
       " 26: 0,\n",
       " 34: 0,\n",
       " 42: 0,\n",
       " 236: 1,\n",
       " 198: 0,\n",
       " 225: 0,\n",
       " 181: 0,\n",
       " 21: 0,\n",
       " 130: 0,\n",
       " 133: 0,\n",
       " 86: 0,\n",
       " 7: 0,\n",
       " 165: 0,\n",
       " 13: 0,\n",
       " 188: 0,\n",
       " 92: 0,\n",
       " 216: 0,\n",
       " 199: 0,\n",
       " 54: 0,\n",
       " 135: 0,\n",
       " 201: 0,\n",
       " 157: 0,\n",
       " 208: 0,\n",
       " 22: 0,\n",
       " 153: 0,\n",
       " 43: 0,\n",
       " 211: 0,\n",
       " 119: 0,\n",
       " 131: 0,\n",
       " 41: 0,\n",
       " 72: 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_resource_to_role = { map_resource_index[k] : map_resource_role_index[v] for k,v in map_resource_to_role.items()}\n",
    "map_resource_to_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'org:group': ['Org line A2',\n",
       "  'Org line G3',\n",
       "  'Org line G4',\n",
       "  'Org line B',\n",
       "  'Org line C',\n",
       "  'Org line F',\n",
       "  'Org line D',\n",
       "  'Org line V2',\n",
       "  'Org line V11',\n",
       "  'Org line G1',\n",
       "  'Org line V5'],\n",
       " 'resource country': ['Sweden',\n",
       "  'POLAND',\n",
       "  'INDIA',\n",
       "  'France',\n",
       "  '0',\n",
       "  'USA',\n",
       "  'United Kingdom',\n",
       "  'Belgium',\n",
       "  'Brazil',\n",
       "  'China',\n",
       "  'Japan',\n",
       "  'Denmark',\n",
       "  'Australia',\n",
       "  'Canada'],\n",
       " 'org:resource': ['Tomas',\n",
       "  'Niklas',\n",
       "  'Ewa',\n",
       "  'Pawel',\n",
       "  'Panigrahy',\n",
       "  'Jerker',\n",
       "  'Srinivasan',\n",
       "  'Aneesh V',\n",
       "  'Rijin',\n",
       "  'Celine',\n",
       "  'Anna',\n",
       "  'Sumesh',\n",
       "  'Prasad',\n",
       "  'Peter',\n",
       "  'Craig',\n",
       "  'Stefan',\n",
       "  'David',\n",
       "  'Jonas',\n",
       "  'Joakim',\n",
       "  'Per',\n",
       "  'Stephen',\n",
       "  'Christer',\n",
       "  'Ing-Marie',\n",
       "  'Nicolas',\n",
       "  'Kenneth',\n",
       "  'Fredrik',\n",
       "  'Viktoria',\n",
       "  'Roland',\n",
       "  'Marco',\n",
       "  'Katarina',\n",
       "  'Ian',\n",
       "  'Martin',\n",
       "  'Olivier',\n",
       "  'Britt',\n",
       "  'Michal',\n",
       "  'Timothy',\n",
       "  'Andrew',\n",
       "  'Mikael',\n",
       "  'Erik',\n",
       "  'Arun',\n",
       "  'Els',\n",
       "  'Jo',\n",
       "  'Lars',\n",
       "  'Daniel',\n",
       "  'Rickard',\n",
       "  'Thiago',\n",
       "  'Cyril',\n",
       "  'Mattias',\n",
       "  'Bharath',\n",
       "  'Praveen',\n",
       "  'Steve',\n",
       "  'Murali',\n",
       "  'Rohan',\n",
       "  'Wim',\n",
       "  'Inger',\n",
       "  'Frederic',\n",
       "  'Miroslaw',\n",
       "  'Lena',\n",
       "  'Radoslaw',\n",
       "  'Robert',\n",
       "  'Anup',\n",
       "  'Lars-Ove',\n",
       "  'Jörgen',\n",
       "  'Hineesh',\n",
       "  'Carlos',\n",
       "  'Adam',\n",
       "  'Ann-Charlotte',\n",
       "  'Mats',\n",
       "  'Olle',\n",
       "  'Richard',\n",
       "  'Samira',\n",
       "  'Vikrant',\n",
       "  'Kymaria',\n",
       "  'Agneta',\n",
       "  'Ramith',\n",
       "  'Urban',\n",
       "  'Börje',\n",
       "  'Lennart',\n",
       "  'Andreas',\n",
       "  'Sameer',\n",
       "  'Partha',\n",
       "  'Jari',\n",
       "  'Bruno',\n",
       "  'Alan',\n",
       "  '-',\n",
       "  'Vesa',\n",
       "  'Freddy',\n",
       "  'Pascal',\n",
       "  'Maria',\n",
       "  'Kristina',\n",
       "  'Bikshamaiah',\n",
       "  'Marie',\n",
       "  'Venkata',\n",
       "  'Michel',\n",
       "  'Rakesh',\n",
       "  'Leif',\n",
       "  'Rajkishore',\n",
       "  'Vaibhav',\n",
       "  'Kjell',\n",
       "  'Jitender',\n",
       "  'Håkan',\n",
       "  'Fabrice',\n",
       "  'Tomasz',\n",
       "  'Paulina',\n",
       "  'Kåre',\n",
       "  'Marc',\n",
       "  'Santosh',\n",
       "  'Amar',\n",
       "  'Jay',\n",
       "  'Rajesh Kumar',\n",
       "  'Emil',\n",
       "  'Saki',\n",
       "  'Anson',\n",
       "  'Krzysztof',\n",
       "  'Piotr',\n",
       "  'Laurens',\n",
       "  'Ryouhei',\n",
       "  'John',\n",
       "  'Dusan',\n",
       "  'Ganesh',\n",
       "  'Anandgiri',\n",
       "  'Gaurav',\n",
       "  'Mohsin',\n",
       "  'Rohit',\n",
       "  'Gitt',\n",
       "  'Vinodhkumar',\n",
       "  'Umar Farooque',\n",
       "  'Pankaj',\n",
       "  'Raja',\n",
       "  'Aurelien',\n",
       "  'Tarun',\n",
       "  'Harshavardhan',\n",
       "  'Åsa',\n",
       "  'Himanshu',\n",
       "  'Przemyslaw',\n",
       "  'Pratap',\n",
       "  'Joacim',\n",
       "  'Alice',\n",
       "  'Jesper',\n",
       "  'Olof',\n",
       "  'Joris',\n",
       "  'Katarzyna',\n",
       "  'Grzegorz',\n",
       "  'Marcin',\n",
       "  'Diogo',\n",
       "  'Björn',\n",
       "  'Raphael',\n",
       "  'Eva',\n",
       "  'Jon',\n",
       "  'Patrick',\n",
       "  'Vijayakumar',\n",
       "  'Maciej',\n",
       "  'Avvaru',\n",
       "  'Joey',\n",
       "  'Marianne',\n",
       "  'Göran',\n",
       "  'Jimmy',\n",
       "  'Henrik',\n",
       "  'Hicham',\n",
       "  'Johan',\n",
       "  'Kell',\n",
       "  'Valter',\n",
       "  'Marise',\n",
       "  'Stephane',\n",
       "  'Arup',\n",
       "  'Mathias',\n",
       "  'James',\n",
       "  'Henrique',\n",
       "  'Devakumar',\n",
       "  'Christoffer',\n",
       "  'Gunilla',\n",
       "  'Susan',\n",
       "  'Michael',\n",
       "  'Jennifer',\n",
       "  'Steven',\n",
       "  'Marilyn',\n",
       "  'Katia',\n",
       "  'Ilona',\n",
       "  'Emmanuel',\n",
       "  'Alain',\n",
       "  'Amitabh',\n",
       "  'Jubin',\n",
       "  'Mariusz',\n",
       "  'Hampus',\n",
       "  'Thomas',\n",
       "  'Kim',\n",
       "  'Bhaskar',\n",
       "  'Louis',\n",
       "  'Rosemary',\n",
       "  'Fiona',\n",
       "  'Christian',\n",
       "  'Hongming',\n",
       "  'Flavio',\n",
       "  'Jonathan',\n",
       "  'Janusz',\n",
       "  'Astrid',\n",
       "  'Shamna',\n",
       "  'Avronil',\n",
       "  'Ingela',\n",
       "  'Pramod',\n",
       "  'Lars-Göran',\n",
       "  'Kreeti',\n",
       "  'Sandeep',\n",
       "  'Ranveer',\n",
       "  'Habib',\n",
       "  'Johnny',\n",
       "  'Rolf',\n",
       "  'Yu',\n",
       "  'Charlotta',\n",
       "  'Bartlomiej',\n",
       "  'Carla',\n",
       "  'Cindy',\n",
       "  'William',\n",
       "  'Ruhi',\n",
       "  'Tonie',\n",
       "  'Rajendra',\n",
       "  'Atul',\n",
       "  'Linda',\n",
       "  'Ludwig',\n",
       "  'Jagannath',\n",
       "  'Amit',\n",
       "  'Parbhat',\n",
       "  'Ankit',\n",
       "  'Ratikanta',\n",
       "  'Jenny',\n",
       "  'Sujith',\n",
       "  'Ryou',\n",
       "  'Eric',\n",
       "  'Manisha',\n",
       "  'Sachin',\n",
       "  'Neeraj',\n",
       "  'Sophie',\n",
       "  'Aurelie',\n",
       "  'Milos',\n",
       "  'Conny',\n",
       "  'Sten',\n",
       "  'Krystian',\n",
       "  'Lotta',\n",
       "  'Christophe',\n",
       "  'Hanna'],\n",
       " 'oranization country': ['cn',\n",
       "  'se',\n",
       "  'us',\n",
       "  'in',\n",
       "  'fr',\n",
       "  'gb',\n",
       "  'pl',\n",
       "  'be',\n",
       "  'br',\n",
       "  '0',\n",
       "  'jp',\n",
       "  'dk',\n",
       "  'au',\n",
       "  'ca'],\n",
       " 'org:role': ['A2_2',\n",
       "  'NAN',\n",
       "  'D_1',\n",
       "  'E_10',\n",
       "  'V3_3',\n",
       "  'C_6',\n",
       "  'E_7',\n",
       "  'A2_4',\n",
       "  'A2_1',\n",
       "  'A2_3',\n",
       "  'E_6',\n",
       "  'E_8',\n",
       "  'C_2',\n",
       "  'E_3',\n",
       "  'D_2',\n",
       "  'C_3',\n",
       "  'E_4',\n",
       "  'E_1',\n",
       "  'C_1',\n",
       "  'E_2',\n",
       "  'V3_2',\n",
       "  'V3_1',\n",
       "  'A2_5',\n",
       "  'E_5',\n",
       "  'C_4',\n",
       "  'C_5'],\n",
       " 'Activity': ['Accepted_In Progress',\n",
       "  'Accepted_Wait',\n",
       "  'Queued_Awaiting Assignment',\n",
       "  'Accepted_Assigned',\n",
       "  'Completed_Closed'],\n",
       " 'impact': ['Medium', 'Low', 'High', 'Major'],\n",
       " 'product': ['PROD753',\n",
       "  'PROD681',\n",
       "  'PROD98',\n",
       "  'PROD611',\n",
       "  'PROD368',\n",
       "  'PROD262',\n",
       "  'PROD793',\n",
       "  'PROD660',\n",
       "  'PROD698',\n",
       "  'PROD153',\n",
       "  'PROD551',\n",
       "  'PROD374',\n",
       "  'PROD424',\n",
       "  'PROD412',\n",
       "  'PROD821',\n",
       "  'PROD304',\n",
       "  'PROD546',\n",
       "  'PROD411',\n",
       "  'PROD235',\n",
       "  'PROD154',\n",
       "  'PROD791',\n",
       "  'PROD236',\n",
       "  'PROD448',\n",
       "  'PROD108',\n",
       "  'PROD436',\n",
       "  'PROD67',\n",
       "  'PROD330',\n",
       "  'PROD756',\n",
       "  'PROD714',\n",
       "  'PROD473',\n",
       "  'PROD802',\n",
       "  'PROD253',\n",
       "  'PROD397',\n",
       "  'PROD209',\n",
       "  'PROD673',\n",
       "  'PROD618',\n",
       "  'PROD325',\n",
       "  'PROD148',\n",
       "  'PROD348',\n",
       "  'PROD597',\n",
       "  'PROD745',\n",
       "  'PROD671',\n",
       "  'PROD327',\n",
       "  'PROD535',\n",
       "  'PROD337',\n",
       "  'PROD804',\n",
       "  'PROD607',\n",
       "  'PROD408',\n",
       "  'PROD659',\n",
       "  'PROD805',\n",
       "  'PROD350',\n",
       "  'PROD13',\n",
       "  'PROD591',\n",
       "  'PROD231',\n",
       "  'PROD631',\n",
       "  'PROD646',\n",
       "  'PROD494',\n",
       "  'PROD776',\n",
       "  'PROD761',\n",
       "  'PROD306',\n",
       "  'PROD815',\n",
       "  'PROD221',\n",
       "  'PROD544',\n",
       "  'PROD521',\n",
       "  'PROD789',\n",
       "  'PROD176',\n",
       "  'PROD214',\n",
       "  'PROD320',\n",
       "  'PROD49',\n",
       "  'PROD834',\n",
       "  'PROD617',\n",
       "  'PROD200',\n",
       "  'PROD319',\n",
       "  'PROD785',\n",
       "  'PROD488',\n",
       "  'PROD509',\n",
       "  'PROD120',\n",
       "  'PROD449',\n",
       "  'PROD239',\n",
       "  'PROD94',\n",
       "  'PROD243',\n",
       "  'PROD700',\n",
       "  'PROD537',\n",
       "  'PROD178',\n",
       "  'PROD375',\n",
       "  'PROD122',\n",
       "  'PROD187',\n",
       "  'PROD613',\n",
       "  'PROD160',\n",
       "  'PROD391',\n",
       "  'PROD124',\n",
       "  'PROD592',\n",
       "  'PROD601',\n",
       "  'PROD295',\n",
       "  'PROD193',\n",
       "  'PROD558',\n",
       "  'PROD405',\n",
       "  'PROD332',\n",
       "  'PROD276',\n",
       "  'PROD767',\n",
       "  'PROD612',\n",
       "  'PROD818',\n",
       "  'PROD502',\n",
       "  'PROD589',\n",
       "  'PROD134',\n",
       "  'PROD343',\n",
       "  'PROD557',\n",
       "  'PROD442',\n",
       "  'PROD525',\n",
       "  'PROD41',\n",
       "  'PROD530',\n",
       "  'PROD615',\n",
       "  'PROD406',\n",
       "  'PROD552',\n",
       "  'PROD452',\n",
       "  'PROD328',\n",
       "  'PROD74',\n",
       "  'PROD126',\n",
       "  'PROD196',\n",
       "  'PROD379',\n",
       "  'PROD257',\n",
       "  'PROD30',\n",
       "  'PROD567',\n",
       "  'PROD609',\n",
       "  'PROD149',\n",
       "  'PROD500',\n",
       "  'PROD730',\n",
       "  'PROD292',\n",
       "  'PROD382',\n",
       "  'PROD135',\n",
       "  'PROD143',\n",
       "  'OTHERS',\n",
       "  'PROD110',\n",
       "  'PROD417',\n",
       "  'PROD42',\n",
       "  'PROD240',\n",
       "  'PROD409',\n",
       "  'PROD600',\n",
       "  'PROD10'],\n",
       " 'org:resource:role': ['Role 1', 'Role 2']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_unique = {k : list(tab_all[k].unique()) for k in categorical_columns}\n",
    "list_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir_graphs + dataset + \"_TRAIN_event_prediction_FINAL.pkl\", \"rb\") as f:\n",
    "    X_train = pickle.load(f)\n",
    "with open(data_dir_graphs + dataset + \"_VALID_event_prediction_FINAL.pkl\", \"rb\") as f:\n",
    "    X_valid = pickle.load(f)\n",
    "with open(data_dir_graphs + dataset + \"_TEST_event_prediction_FINAL.pkl\", \"rb\") as f:\n",
    "    X_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch_geometric.data import Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.transforms import ToUndirected, NormalizeFeatures\n",
    "\n",
    "transform = ToUndirected()\n",
    "\n",
    "with torch.no_grad():\n",
    "        for i in range(len(X_train)):\n",
    "                X_train[i] = transform(X_train[i])\n",
    "        for i in range(len(X_valid)):\n",
    "                X_valid[i] = transform(X_valid[i])\n",
    "        for i in range(len(X_test)):\n",
    "                X_test[i] = transform(X_test[i])\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_types = set()\n",
    "node_types = set()\n",
    "for i in range(len(X_train)):\n",
    "    n, edge_type = X_train[i].metadata()\n",
    "    for x in n:\n",
    "        node_types.add(x)\n",
    "    for x in edge_type:\n",
    "        edge_types.add(x)\n",
    "for i in range(len(X_valid)):\n",
    "    n, edge_type = X_valid[i].metadata()\n",
    "    for x in n:\n",
    "        node_types.add(x)\n",
    "    for x in edge_type:\n",
    "        edge_types.add(x)\n",
    "for i in range(len(X_test)):\n",
    "    n, edge_type = X_test[i].metadata()\n",
    "    for x in n:\n",
    "        node_types.add(x)\n",
    "    for x in edge_type:\n",
    "        edge_types.add(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_types = list(node_types)\n",
    "edge_types = list(edge_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(load, key):\n",
    "    weights = []\n",
    "    \n",
    "    cl_train = [0 for _ in tab_all[key].unique()]\n",
    "    \n",
    "    print(cl_train)\n",
    "    \n",
    "    for i,x in enumerate(load):\n",
    "\n",
    "        \n",
    "        classes = x.y[key]\n",
    "\n",
    "        # print(classes)\n",
    "        \n",
    "        for c in list(classes):\n",
    "            try:\n",
    "                cl_train[c] +=1\n",
    "            except KeyError:\n",
    "                cl_train[c] = 1\n",
    "    s = sum(cl_train)\n",
    "    \n",
    "    print(cl_train)\n",
    "    \n",
    "    weights = [s/x if x > 0 else 0 for x in cl_train]\n",
    "\n",
    "    # weights = [0.7,0.7,1,0.7,0.7,0.7,0.7,0.7,0.7,0.7]\n",
    "    weights = torch.tensor(weights, device=device)\n",
    "    print(weights)\n",
    "    return weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('Activity', 'followed_by', 'Activity'): 2,\n",
       " ('time:timestamp', 'related_to', 'time:timestamp'): 2,\n",
       " ('org:resource', 'related_to', 'org:resource'): 2,\n",
       " ('resource country', 'related_to', 'resource country'): 2,\n",
       " ('org:group', 'related_to', 'org:group'): 2,\n",
       " ('org:role', 'related_to', 'org:role'): 2}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_features_dims = {}\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    for k in X_train[i].edge_attr_dict.keys():\n",
    "        edge_features_dims[k] = X_train[i].edge_attr_dict[k].shape[1]\n",
    "for i in range(len(X_valid)):\n",
    "    for k in X_train[i].edge_attr_dict.keys():\n",
    "        edge_features_dims[k] = X_train[i].edge_attr_dict[k].shape[1]\n",
    "for i in range(len(X_test)):\n",
    "    for k in X_train[i].edge_attr_dict.keys():\n",
    "        edge_features_dims[k] = X_train[i].edge_attr_dict[k].shape[1]\n",
    "\n",
    "edge_features_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0]\n",
      "[52, 202, 57, 185, 95]\n",
      "tensor([11.3654,  2.9257, 10.3684,  3.1946,  6.2211], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "act_weights = get_weights(DataLoader(X_train, batch_size=1024, shuffle=False), \"Activity\")\n",
    "# res_roles_weights = get_weights(DataLoader(X_train, batch_size=1024, shuffle=False), \"org:resource:role\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax.service.managed_loop import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import (\n",
    "    HeteroConv,\n",
    "    global_mean_pool,\n",
    "    GATv2Conv\n",
    ")\n",
    "from torch.nn import (\n",
    "    ModuleList,\n",
    "    Module,\n",
    "    Linear\n",
    "  )\n",
    "from typing_extensions import Self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGNN(Module):\n",
    "\n",
    "    def __init__(self, output_cat, output_real,nodes_relations, relations_with_features, parameters) -> Self:  # type: ignore\n",
    "        super().__init__()\n",
    "\n",
    "        # List of convolutional layers\n",
    "        \n",
    "        hid = parameters[\"hid\"]\n",
    "        layers = parameters[\"layers\"]\n",
    "        aggregation = parameters[\"aggregation\"]\n",
    "        n_heads = parameters[\"heads\"]\n",
    "        \n",
    "        self.output_cat = output_cat\n",
    "        self.output_real = output_real\n",
    "        \n",
    "        self.convs = ModuleList()\n",
    "        for _ in range(layers):\n",
    "            conv = HeteroConv(\n",
    "                {\n",
    "                    relation: (\n",
    "                        GATv2Conv((-1,-1), add_self_loops=False, out_channels=hid, heads=n_heads, concat=False)\n",
    "                        if relation not in relations_with_features\n",
    "                        else GATv2Conv((-1,-1), add_self_loops=False, out_channels=hid,heads=n_heads, edge_dim=relations_with_features[relation], concat=False)\n",
    "                    )\n",
    "                    for relation in nodes_relations\n",
    "                },\n",
    "                aggr=aggregation,\n",
    "            )\n",
    "\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        self.FC = {}\n",
    "        \n",
    "        for k in output_cat:\n",
    "            self.FC[k] = Linear(hid, output_cat[k], device=device)\n",
    "        for k in output_real:\n",
    "            self.FC[k] = Linear(hid, 1, device=device)\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, batch):\n",
    "\n",
    "        for i in range(len(self.convs)):\n",
    "            batch.x_dict = self.convs[i]( \n",
    "                batch.x_dict, batch.edge_index_dict, batch.edge_attr_dict\n",
    "            )\n",
    "\n",
    "            batch.x_dict = {key: x.relu() for key, x in batch.x_dict.items()}\n",
    "\n",
    "\n",
    "        output = {}\n",
    "        \n",
    "        for k in self.output_cat:\n",
    "            output[k] = global_mean_pool(batch.x_dict[k], batch[k].batch)\n",
    "            output[k] = self.FC[k](output[k])\n",
    "        for k in self.output_real:\n",
    "            output[k] = global_mean_pool(batch.x_dict[k], batch[k].batch)\n",
    "            output[k] = self.FC[k](output[k]).reshape(1,-1)[0]\n",
    "            \n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torcheval.metrics.functional import multiclass_accuracy, multiclass_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def train_hgnn(config, output_cat, output_real, epochs=20):\n",
    "    print(config)\n",
    "\n",
    "    net = HGNN(\n",
    "        parameters=config,\n",
    "        output_cat=output_cat,\n",
    "        output_real=output_real,\n",
    "        nodes_relations=edge_types,\n",
    "        relations_with_features=edge_features_dims,\n",
    "    )\n",
    "    net = net.to(device)\n",
    "\n",
    "    losses = {}\n",
    "\n",
    "    for k in output_cat:\n",
    "        losses[k] = (\n",
    "            nn.CrossEntropyLoss()\n",
    "            if k != \"Activity\"\n",
    "            else nn.CrossEntropyLoss(act_weights)\n",
    "        )\n",
    "    for k in output_real:\n",
    "        losses[k] = nn.L1Loss()\n",
    "\n",
    "    train_loader = DataLoader(X_train, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "    valid_loader = DataLoader(X_valid, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "    best_model = None\n",
    "    best_loss = 0\n",
    "    patience = 10\n",
    "    pat_count = 0\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    for epoch in range(0, epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        print(f\"Epoch: {epoch}\\n\")\n",
    "\n",
    "        net.train()\n",
    "        for _, x in enumerate(train_loader):\n",
    "            x = x.to(device)\n",
    "\n",
    "            labels = x.y\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(x)\n",
    "\n",
    "            losses_step = {k: losses[k](outputs[k], labels[k]) for k in losses}\n",
    "\n",
    "            total_loss = 0\n",
    "            for k in losses_step:\n",
    "                total_loss += losses_step[k]\n",
    "\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        predictions_categorical = {k: [] for k in output_cat}\n",
    "        target_categorical = {k: [] for k in output_cat}\n",
    "\n",
    "        avg_MAE = {k: [] for k in output_real}\n",
    "\n",
    "        running_total_loss = []\n",
    "\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, x in enumerate(valid_loader):\n",
    "                x = x.to(device)\n",
    "\n",
    "                labels = x.y\n",
    "\n",
    "                outputs = net(x)\n",
    "\n",
    "                losses_step = {k: losses[k](outputs[k], labels[k]) for k in losses}\n",
    "\n",
    "                running_total_loss.append(sum(list(losses_step.values())))\n",
    "\n",
    "                for k in output_cat:\n",
    "                    predictions_categorical[k].append(\n",
    "                        torch.argmax(torch.softmax(outputs[k], dim=1), 1)\n",
    "                    )\n",
    "                    target_categorical[k].append(labels[k])\n",
    "\n",
    "                for k in output_real:\n",
    "                    avg_MAE[k].append(losses_step[k])\n",
    "\n",
    "        for k in predictions_categorical:\n",
    "            predictions_categorical[k] = torch.cat(predictions_categorical[k])\n",
    "            target_categorical[k] = torch.cat(target_categorical[k])\n",
    "\n",
    "        macro_f1_activity = multiclass_f1_score(\n",
    "            predictions_categorical[\"Activity\"],\n",
    "            target_categorical[\"Activity\"],\n",
    "            num_classes=output_cat[\"Activity\"],\n",
    "            average=\"macro\",\n",
    "        )\n",
    "\n",
    "        accuracy = {\n",
    "            k: multiclass_accuracy(\n",
    "                predictions_categorical[k],\n",
    "                target_categorical[k],\n",
    "                num_classes=output_cat[k],\n",
    "            )\n",
    "            for k in output_cat\n",
    "        }\n",
    "\n",
    "        avg_MAE = {k: sum(avg_MAE[k]) / len(avg_MAE[k]) for k in avg_MAE}\n",
    "\n",
    "        val_loss = sum(running_total_loss) / len(running_total_loss)\n",
    "\n",
    "        print(f\"\\nVALIDATION\")\n",
    "        for k in accuracy:\n",
    "            (\n",
    "                print(\"{}: acc {:.4f}\".format(k, accuracy[k]))\n",
    "                if k != \"Activity\"\n",
    "                else print(\n",
    "                    \"{}: acc {:.4f} macroF1 {:.4f}\".format(\n",
    "                        k, accuracy[k], macro_f1_activity.item()\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        for k in avg_MAE:\n",
    "            print(\"{}: MAE {:.4f}\".format(k, avg_MAE[k]))\n",
    "        print(\"TOTAL_LOSS: {:.4f}\".format(val_loss))\n",
    "        print(\"epoch time {}s\\n\".format(time.time() - start_time))\n",
    "\n",
    "        if epoch == 0:\n",
    "            best_model = deepcopy(net)\n",
    "            best_loss = val_loss\n",
    "        else:\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                best_model = deepcopy(net)\n",
    "                pat_count = 0\n",
    "                print(\"new best model found\")\n",
    "            if pat_count == patience:\n",
    "                print(\n",
    "                    \"Validation performance didn't improve for {} epochs. Training stops.\".format(\n",
    "                        pat_count\n",
    "                    )\n",
    "                )\n",
    "                return best_model\n",
    "        pat_count += 1\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_hgnn(net, output_cat, output_real):\n",
    "    test_loader = DataLoader(X_test, batch_size=128, shuffle=False)\n",
    "    \n",
    "    losses = {}\n",
    "    \n",
    "    for k in output_cat:\n",
    "        losses[k] = (\n",
    "            nn.CrossEntropyLoss()\n",
    "            if k != \"Activity\"\n",
    "            else nn.CrossEntropyLoss(act_weights)\n",
    "        )\n",
    "    for k in output_real:\n",
    "        losses[k] = nn.L1Loss()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    predictions_categorical = {k: [] for k in output_cat}\n",
    "    target_categorical = {k: [] for k in output_cat}\n",
    "\n",
    "    avg_MAE = {k : [] for k in output_real}\n",
    "    \n",
    "    total_loss = []\n",
    "        \n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, x in enumerate(test_loader):\n",
    "            x = x.to(device)\n",
    "            \n",
    "            labels = x.y\n",
    "            \n",
    "            outputs = net(x)\n",
    "            \n",
    "     \n",
    "            losses_step = {k: losses[k](outputs[k], labels[k]).item() for k in losses}\n",
    "            total_loss.append(sum(list(losses_step.values())))\n",
    "            \n",
    "            for k in output_cat:\n",
    "                    predictions_categorical[k].append(\n",
    "                        torch.argmax(torch.softmax(outputs[k], dim=1), 1)\n",
    "                    )\n",
    "                    target_categorical[k].append(labels[k])\n",
    "            \n",
    "            \n",
    "            for k in output_real:\n",
    "                    avg_MAE[k].append(losses_step[k])\n",
    "                    \n",
    "    for k in predictions_categorical:\n",
    "            predictions_categorical[k] = torch.cat(predictions_categorical[k])\n",
    "            target_categorical[k] = torch.cat(target_categorical[k])\n",
    "               \n",
    "            \n",
    "    macro_f1_activity = multiclass_f1_score(\n",
    "            predictions_categorical[\"Activity\"],\n",
    "            target_categorical[\"Activity\"],\n",
    "            num_classes=output_cat[\"Activity\"],\n",
    "            average=\"macro\",\n",
    "        )\n",
    "            \n",
    "    accuracy = {\n",
    "            k: multiclass_accuracy(\n",
    "                predictions_categorical[k],\n",
    "                target_categorical[k],\n",
    "                num_classes=output_cat[k],\n",
    "            )\n",
    "            for k in output_cat\n",
    "        }\n",
    "    \n",
    "    resource_to_role_acc = multiclass_accuracy(\n",
    "        torch.tensor([map_resource_to_role[x.item()] for x in predictions_categorical[\"org:resource\"]], device=device),\n",
    "        target_categorical[\"org:resource:role\"],\n",
    "        num_classes=output_cat[\"org:resource:role\"]\n",
    "    )\n",
    "    \n",
    "    avg_MAE = {k : sum(avg_MAE[k]) / len(avg_MAE[k]) for k in avg_MAE}\n",
    "    \n",
    "    \n",
    "    Average_total_loss = sum(total_loss) / len(total_loss)\n",
    "    \n",
    "    res = {f\"{k}_acc\" : accuracy[k].item() for k in accuracy} | {\"Resource_to_role_acc\" : resource_to_role_acc.item()} |{\"MacroF1Act\" : macro_f1_activity.item()} | {f\"{k}_mae\" : avg_MAE[k] for k in avg_MAE} | {\"AVG_total_loss\" : Average_total_loss} \n",
    "    \n",
    "    #print(res)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'org:group': 11, 'resource country': 14, 'org:resource': 240, 'oranization country': 14, 'org:role': 26, 'Activity': 5, 'impact': 4, 'product': 139, 'org:resource:role': 2}\n",
      "['time:timestamp']\n"
     ]
    }
   ],
   "source": [
    "outputcat = {k : len(list_unique[k]) for k in list_unique}\n",
    "outputreal = real_value_columns\n",
    "print(outputcat)\n",
    "print(outputreal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(config):\n",
    "    trained_net = train_hgnn(config, output_cat=outputcat, output_real=outputreal, epochs=80)\n",
    "    return test_hgnn(trained_net, output_cat=outputcat, output_real=outputreal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 02-13 11:25:00] ax.service.utils.instantiation: Choice parameter layers contains only one value, converting to a fixed parameter instead.\n",
      "[INFO 02-13 11:25:00] ax.service.utils.instantiation: Choice parameter aggregation contains only one value, converting to a fixed parameter instead.\n",
      "[INFO 02-13 11:25:00] ax.service.utils.instantiation: Created search space: SearchSpace(parameters=[ChoiceParameter(name='hid', parameter_type=INT, values=[16, 64, 128], is_ordered=True, sort_values=False), FixedParameter(name='layers', parameter_type=INT, value=2), RangeParameter(name='lr', parameter_type=FLOAT, range=[0.0001, 0.1], log_scale=True), ChoiceParameter(name='batch_size', parameter_type=INT, values=[32, 64, 128, 256], is_ordered=True, sort_values=False), ChoiceParameter(name='heads', parameter_type=INT, values=[1, 2], is_ordered=True, sort_values=False), FixedParameter(name='aggregation', parameter_type=STRING, value='max')], parameter_constraints=[]).\n",
      "[INFO 02-13 11:25:00] ax.modelbridge.dispatch_utils: Using Models.BOTORCH_MODULAR since there is at least one ordered parameter and there are no unordered categorical parameters.\n",
      "[INFO 02-13 11:25:00] ax.modelbridge.dispatch_utils: Calculating the number of remaining initialization trials based on num_initialization_trials=None max_initialization_trials=None num_tunable_parameters=4 num_trials=None use_batch_trials=False\n",
      "[INFO 02-13 11:25:00] ax.modelbridge.dispatch_utils: calculated num_initialization_trials=8\n",
      "[INFO 02-13 11:25:00] ax.modelbridge.dispatch_utils: num_completed_initialization_trials=0 num_remaining_initialization_trials=8\n",
      "[INFO 02-13 11:25:00] ax.modelbridge.dispatch_utils: `verbose`, `disable_progbar`, and `jit_compile` are not yet supported when using `choose_generation_strategy` with ModularBoTorchModel, dropping these arguments.\n",
      "[INFO 02-13 11:25:00] ax.modelbridge.dispatch_utils: Using Bayesian Optimization generation strategy: GenerationStrategy(name='Sobol+BoTorch', steps=[Sobol for 8 trials, BoTorch for subsequent trials]). Iterations after 8 will take longer to generate due to model-fitting.\n",
      "[INFO 02-13 11:25:00] ax.service.managed_loop: Started full optimization with 100 steps.\n",
      "[INFO 02-13 11:25:00] ax.service.managed_loop: Running optimization trial 1...\n",
      "/home/sebdis/ProcessMining/HGNN/hgnn_env/lib/python3.10/site-packages/ax/modelbridge/cross_validation.py:463: UserWarning: Encountered exception in computing model fit quality: RandomModelBridge does not support prediction.\n",
      "  warn(\"Encountered exception in computing model fit quality: \" + str(e))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hid': 16, 'lr': 0.005537727881833665, 'batch_size': 64, 'heads': 2, 'layers': 2, 'aggregation': 'max'}\n",
      "Epoch: 0\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_parameters, values, experiment, model \u001b[38;5;241m=\u001b[39m \u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchoice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mis_ordered\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msort_values\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#{\"name\": \"layers\", \"type\": \"choice\", \"values\": [2, 3, 4, 5], \"value_type\": \"int\", \"is_ordered\" : True, \"sort_values\":False},\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlayers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchoice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mis_ordered\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msort_values\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrange\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbounds\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfloat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlog_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchoice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mis_ordered\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msort_values\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mheads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchoice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mis_ordered\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msort_values\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#{\"name\": \"heads\", \"type\": \"choice\", \"values\": [1], \"value_type\": \"int\", \"is_ordered\" : True,\"sort_values\":False},\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#{\"name\": \"aggregation\", \"type\" : \"choice\", \"values\" :[\"sum\", \"mean\", \"max\"], \"value_type\" : \"str\"}\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maggregation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchoice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m     \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m  \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluation_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_evaluate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjective_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAVG_total_loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43marms_per_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mminimize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m123\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_trials\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\n\u001b[1;32m     22\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(best_parameters)\n\u001b[1;32m     25\u001b[0m means, covariances \u001b[38;5;241m=\u001b[39m values\n",
      "File \u001b[0;32m~/ProcessMining/HGNN/hgnn_env/lib/python3.10/site-packages/ax/service/managed_loop.py:307\u001b[0m, in \u001b[0;36moptimize\u001b[0;34m(parameters, evaluation_function, experiment_name, objective_name, minimize, parameter_constraints, outcome_constraints, total_trials, arms_per_trial, random_seed, generation_strategy)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Construct and run a full optimization loop.\"\"\"\u001b[39;00m\n\u001b[1;32m    294\u001b[0m loop \u001b[38;5;241m=\u001b[39m OptimizationLoop\u001b[38;5;241m.\u001b[39mwith_evaluation_function(\n\u001b[1;32m    295\u001b[0m     parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    296\u001b[0m     objective_name\u001b[38;5;241m=\u001b[39mobjective_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    305\u001b[0m     generation_strategy\u001b[38;5;241m=\u001b[39mgeneration_strategy,\n\u001b[1;32m    306\u001b[0m )\n\u001b[0;32m--> 307\u001b[0m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m parameterization, values \u001b[38;5;241m=\u001b[39m loop\u001b[38;5;241m.\u001b[39mget_best_point()\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m parameterization, values, loop\u001b[38;5;241m.\u001b[39mexperiment, loop\u001b[38;5;241m.\u001b[39mget_current_model()\n",
      "File \u001b[0;32m~/ProcessMining/HGNN/hgnn_env/lib/python3.10/site-packages/ax/service/managed_loop.py:238\u001b[0m, in \u001b[0;36mOptimizationLoop.full_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_steps):\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 238\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m SearchSpaceExhausted \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    240\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    241\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped optimization as the search space is exhaused. Message \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom generation strategy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m         )\n",
      "File \u001b[0;32m~/ProcessMining/HGNN/hgnn_env/lib/python3.10/site-packages/ax/utils/common/executils.py:167\u001b[0m, in \u001b[0;36mretry_on_exception.<locals>.func_wrapper.<locals>.actual_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m             wait_interval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\n\u001b[1;32m    164\u001b[0m                 MAX_WAIT_SECONDS, initial_wait_seconds \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    165\u001b[0m             )\n\u001b[1;32m    166\u001b[0m             time\u001b[38;5;241m.\u001b[39msleep(wait_interval)\n\u001b[0;32m--> 167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# If we are here, it means the retries were finished but\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The error was suppressed. Hence return the default value provided.\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m default_return_on_suppression\n",
      "File \u001b[0;32m~/ProcessMining/HGNN/hgnn_env/lib/python3.10/site-packages/ax/service/managed_loop.py:215\u001b[0m, in \u001b[0;36mOptimizationLoop.run_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    211\u001b[0m trial \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_new_trial()\n\u001b[1;32m    213\u001b[0m trial\u001b[38;5;241m.\u001b[39mmark_running(no_runner_required\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    214\u001b[0m _, data \u001b[38;5;241m=\u001b[39m data_and_evaluations_from_raw_data(\n\u001b[0;32m--> 215\u001b[0m     raw_data\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    216\u001b[0m         arm\u001b[38;5;241m.\u001b[39mname: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_evaluation_function(arm\u001b[38;5;241m.\u001b[39mparameters, weight)\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m arm, weight \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_weights_by_arm(trial)\n\u001b[1;32m    218\u001b[0m     },\n\u001b[1;32m    219\u001b[0m     trial_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_trial,\n\u001b[1;32m    220\u001b[0m     sample_sizes\u001b[38;5;241m=\u001b[39m{},\n\u001b[1;32m    221\u001b[0m     data_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment\u001b[38;5;241m.\u001b[39mdefault_data_type,\n\u001b[1;32m    222\u001b[0m     metric_names\u001b[38;5;241m=\u001b[39mnot_none(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment\u001b[38;5;241m.\u001b[39moptimization_config\n\u001b[1;32m    224\u001b[0m     )\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mmetric_names,\n\u001b[1;32m    225\u001b[0m )\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment\u001b[38;5;241m.\u001b[39mattach_data(data\u001b[38;5;241m=\u001b[39mdata)\n\u001b[1;32m    228\u001b[0m trial\u001b[38;5;241m.\u001b[39mmark_completed()\n",
      "File \u001b[0;32m~/ProcessMining/HGNN/hgnn_env/lib/python3.10/site-packages/ax/service/managed_loop.py:216\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    211\u001b[0m trial \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_new_trial()\n\u001b[1;32m    213\u001b[0m trial\u001b[38;5;241m.\u001b[39mmark_running(no_runner_required\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    214\u001b[0m _, data \u001b[38;5;241m=\u001b[39m data_and_evaluations_from_raw_data(\n\u001b[1;32m    215\u001b[0m     raw_data\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m--> 216\u001b[0m         arm\u001b[38;5;241m.\u001b[39mname: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_evaluation_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43marm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m arm, weight \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_weights_by_arm(trial)\n\u001b[1;32m    218\u001b[0m     },\n\u001b[1;32m    219\u001b[0m     trial_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_trial,\n\u001b[1;32m    220\u001b[0m     sample_sizes\u001b[38;5;241m=\u001b[39m{},\n\u001b[1;32m    221\u001b[0m     data_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment\u001b[38;5;241m.\u001b[39mdefault_data_type,\n\u001b[1;32m    222\u001b[0m     metric_names\u001b[38;5;241m=\u001b[39mnot_none(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment\u001b[38;5;241m.\u001b[39moptimization_config\n\u001b[1;32m    224\u001b[0m     )\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mmetric_names,\n\u001b[1;32m    225\u001b[0m )\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment\u001b[38;5;241m.\u001b[39mattach_data(data\u001b[38;5;241m=\u001b[39mdata)\n\u001b[1;32m    228\u001b[0m trial\u001b[38;5;241m.\u001b[39mmark_completed()\n",
      "File \u001b[0;32m~/ProcessMining/HGNN/hgnn_env/lib/python3.10/site-packages/ax/service/managed_loop.py:154\u001b[0m, in \u001b[0;36mOptimizationLoop._call_evaluation_function\u001b[0;34m(self, parameterization, weight)\u001b[0m\n\u001b[1;32m    151\u001b[0m num_evaluation_function_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(signature\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_evaluation_function_params \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;66;03m# pyre-ignore [20]: Can't run instance checks on subscripted generics.\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m     evaluation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameterization\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m num_evaluation_function_params \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# pyre-ignore [19]: Can't run instance checks on subscripted generics.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     evaluation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_function(parameterization, weight)\n",
      "Cell \u001b[0;32mIn[27], line 2\u001b[0m, in \u001b[0;36mtrain_evaluate\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_evaluate\u001b[39m(config):\n\u001b[0;32m----> 2\u001b[0m     trained_net \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_hgnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_cat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputcat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_real\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutputreal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m80\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m test_hgnn(trained_net, output_cat\u001b[38;5;241m=\u001b[39moutputcat, output_real\u001b[38;5;241m=\u001b[39moutputreal)\n",
      "Cell \u001b[0;32mIn[24], line 45\u001b[0m, in \u001b[0;36mtrain_hgnn\u001b[0;34m(config, output_cat, output_real, epochs)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     44\u001b[0m net\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     46\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     48\u001b[0m     labels \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39my\n",
      "File \u001b[0;32m~/ProcessMining/HGNN/hgnn_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/ProcessMining/HGNN/hgnn_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/ProcessMining/HGNN/hgnn_env/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ProcessMining/HGNN/hgnn_env/lib/python3.10/site-packages/torch_geometric/loader/dataloader.py:27\u001b[0m, in \u001b[0;36mCollater.__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     25\u001b[0m elem \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, BaseData):\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_data_list\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfollow_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexclude_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default_collate(batch)\n",
      "File \u001b[0;32m~/ProcessMining/HGNN/hgnn_env/lib/python3.10/site-packages/torch_geometric/data/batch.py:97\u001b[0m, in \u001b[0;36mBatch.from_data_list\u001b[0;34m(cls, data_list, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_data_list\u001b[39m(\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m     exclude_keys: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     88\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m     89\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Constructs a :class:`~torch_geometric.data.Batch` object from a\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m    list of :class:`~torch_geometric.data.Data` or\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    :class:`~torch_geometric.data.HeteroData` objects.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m    Will exclude any keys given in :obj:`exclude_keys`.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m     batch, slice_dict, inc_dict \u001b[38;5;241m=\u001b[39m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincrement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     batch\u001b[38;5;241m.\u001b[39m_num_graphs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_list)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     batch\u001b[38;5;241m.\u001b[39m_slice_dict \u001b[38;5;241m=\u001b[39m slice_dict  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[0;32m~/ProcessMining/HGNN/hgnn_env/lib/python3.10/site-packages/torch_geometric/data/collate.py:109\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# Collate attributes into a unified representation:\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m value, slices, incs \u001b[38;5;241m=\u001b[39m \u001b[43m_collate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# If parts of the data are already on GPU, make sure that auxiliary\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# data like `batch` or `ptr` are also created on GPU:\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Tensor) \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mis_cuda:\n",
      "File \u001b[0;32m~/ProcessMining/HGNN/hgnn_env/lib/python3.10/site-packages/torch_geometric/data/collate.py:169\u001b[0m, in \u001b[0;36m_collate\u001b[0;34m(key, values, data_list, stores, increment)\u001b[0m\n\u001b[1;32m    167\u001b[0m slices \u001b[38;5;241m=\u001b[39m cumsum(sizes)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m increment:\n\u001b[0;32m--> 169\u001b[0m     incs \u001b[38;5;241m=\u001b[39m \u001b[43mget_incs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstores\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m incs\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mint\u001b[39m(incs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    171\u001b[0m         values \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    172\u001b[0m             value \u001b[38;5;241m+\u001b[39m inc\u001b[38;5;241m.\u001b[39mto(value\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    173\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m value, inc \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(values, incs)\n\u001b[1;32m    174\u001b[0m         ]\n",
      "File \u001b[0;32m~/ProcessMining/HGNN/hgnn_env/lib/python3.10/site-packages/torch_geometric/data/collate.py:327\u001b[0m, in \u001b[0;36mget_incs\u001b[0;34m(key, values, data_list, stores)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_incs\u001b[39m(key, values: List[Any], data_list: List[BaseData],\n\u001b[1;32m    326\u001b[0m              stores: List[BaseStorage]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 327\u001b[0m     repeats \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    328\u001b[0m         data\u001b[38;5;241m.\u001b[39m__inc__(key, value, store)\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m value, data, store \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(values, data_list, stores)\n\u001b[1;32m    330\u001b[0m     ]\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(repeats[\u001b[38;5;241m0\u001b[39m], Tensor):\n\u001b[1;32m    332\u001b[0m         repeats \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(repeats, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/ProcessMining/HGNN/hgnn_env/lib/python3.10/site-packages/torch_geometric/data/collate.py:328\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_incs\u001b[39m(key, values: List[Any], data_list: List[BaseData],\n\u001b[1;32m    326\u001b[0m              stores: List[BaseStorage]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    327\u001b[0m     repeats \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 328\u001b[0m         \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__inc__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m value, data, store \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(values, data_list, stores)\n\u001b[1;32m    330\u001b[0m     ]\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(repeats[\u001b[38;5;241m0\u001b[39m], Tensor):\n\u001b[1;32m    332\u001b[0m         repeats \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(repeats, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/ProcessMining/HGNN/hgnn_env/lib/python3.10/site-packages/torch_geometric/data/hetero_data.py:354\u001b[0m, in \u001b[0;36mHeteroData.__inc__\u001b[0;34m(self, key, value, store, *args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(value\u001b[38;5;241m.\u001b[39mmax()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(store, EdgeStorage) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key:\n\u001b[0;32m--> 354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_parameters, values, experiment, model = optimize(\n",
    "    parameters=[\n",
    "        {\"name\": \"hid\", \"type\": \"choice\", \"values\": [16, 64, 128], \"value_type\": \"int\", \"is_ordered\" : True,\"sort_values\":False},\n",
    "        #{\"name\": \"layers\", \"type\": \"choice\", \"values\": [2, 3, 4, 5], \"value_type\": \"int\", \"is_ordered\" : True, \"sort_values\":False},\n",
    "        {\"name\": \"layers\", \"type\": \"choice\", \"values\": [2], \"value_type\": \"int\", \"is_ordered\" : True, \"sort_values\":False},\n",
    "        {\"name\": \"lr\", \"type\": \"range\", \"bounds\": [1e-4, 1e-1], \"value_type\": \"float\", \"log_scale\": True},\n",
    "        {\"name\": \"batch_size\", \"type\": \"choice\", \"values\": [32, 64, 128, 256], \"value_type\": \"int\", \"is_ordered\" : True,\"sort_values\":False}, \n",
    "        {\"name\": \"heads\", \"type\": \"choice\", \"values\": [1,2], \"value_type\": \"int\", \"is_ordered\" : True,\"sort_values\":False},\n",
    "        #{\"name\": \"heads\", \"type\": \"choice\", \"values\": [1], \"value_type\": \"int\", \"is_ordered\" : True,\"sort_values\":False},\n",
    "        \n",
    "        #{\"name\": \"aggregation\", \"type\" : \"choice\", \"values\" :[\"sum\", \"mean\", \"max\"], \"value_type\" : \"str\"}\n",
    "        {\"name\": \"aggregation\", \"type\" : \"choice\", \"values\" :[\"max\"], \"value_type\" : \"str\"},\n",
    "     \n",
    "    ],\n",
    "  \n",
    "    evaluation_function=train_evaluate,\n",
    "    objective_name='AVG_total_loss',\n",
    "    arms_per_trial=1,\n",
    "    minimize = True,\n",
    "    random_seed = 123,\n",
    "    total_trials = 20\n",
    ")\n",
    "\n",
    "print(best_parameters)\n",
    "means, covariances = values\n",
    "print(means)\n",
    "print(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'lr': 0.013969377507803457, 'batch_size': 64, 'heads': 1, 'hid': 128, 'layers': 2, 'aggregation': 'max'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_evaluate(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ax.service.utils.report_utils import exp_to_df\n",
    "\n",
    "results = exp_to_df(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values(by=\"AVG_total_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.sort_values(by=\"AVG_total_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"results/BPI13O.csv\", sep=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hgnn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
