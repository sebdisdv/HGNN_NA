{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from os.path import dirname\n",
    "\n",
    "\n",
    "\n",
    "root_path = dirname(os.getcwd()) + \"/HGNN_NA\"\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "data_dir = root_path + \"/data/datasets/original/\"\n",
    "data_dir_processed = root_path + \"/data/datasets/processed/\"\n",
    "data_dir_graphs = root_path + \"/data/datasets/graphs/\"\n",
    "\n",
    "print(root_path, data_dir, data_dir_processed, data_dir_graphs, sep=\"\\n\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"BPI_Challenge_2012_A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_all = pd.read_csv(data_dir_processed+dataset+\"_processed_all.csv\")\n",
    "print(tab_all.head())\n",
    "list_activities = list(tab_all[\"Activity\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir_graphs + dataset + \"_TRAIN_event_prediction.pkl\", \"rb\") as f:\n",
    "    X_train, Y_train = pickle.load(f)\n",
    "with open(data_dir_graphs + dataset + \"_VALID_event_prediction.pkl\", \"rb\") as f:\n",
    "    X_valid, Y_valid = pickle.load(f)\n",
    "with open(data_dir_graphs + dataset + \"_TEST_event_prediction.pkl\", \"rb\") as f:\n",
    "    X_test, Y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Self\n",
    "from torch_geometric.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.transforms import ToUndirected, NormalizeFeatures\n",
    "\n",
    "transform = ToUndirected()\n",
    "t2 = NormalizeFeatures()\n",
    "\n",
    "\n",
    "class Het_graph_data(Dataset):\n",
    "    def __init__(self, prefix_graphs, labels) -> Self:\n",
    "        self.X = prefix_graphs\n",
    "        self.Y = labels\n",
    "\n",
    "    # get the number of rows in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "\n",
    "    # get a row at a particular index in the dataset\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "\n",
    "    @staticmethod\n",
    "    def collate(batch):\n",
    "        # print(batch)\n",
    "        data = [t2(item[0]) for item in batch]\n",
    "        # data = [transform(item[0]) for item in batch]\n",
    "        \n",
    "        Y = [item[1] for item in batch]\n",
    "        return [data, Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    Het_graph_data(X_train + X_valid, Y_train + Y_valid),\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    collate_fn=Het_graph_data.collate,\n",
    ")\n",
    "\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    Het_graph_data(X_valid, Y_valid),\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    collate_fn=Het_graph_data.collate,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    Het_graph_data(X_test, Y_test),\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    collate_fn=Het_graph_data.collate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Class to keep track of the metrics of the classification process\n",
    "class ClassificationMetrics:\n",
    "\n",
    "  # Constructor takes the number of classes, in our case 20\n",
    "  def __init__(self, num_classes=20):\n",
    "    self.num_classes = num_classes\n",
    "    # Initialize a confusion matrix\n",
    "    self.C = torch.zeros(num_classes, num_classes)\n",
    "\n",
    "  # Update the confusion matrix with the new scores\n",
    "  def add(self, yp, yt):\n",
    "    # yp: 1D tensor with predictions\n",
    "    # yt: 1D tensor with ground-truth targets\n",
    "    yp = yp.to(\"cpu\")\n",
    "    yt = yt.to(\"cpu\")\n",
    "    with torch.no_grad(): # We require no computation graph\n",
    "      self.C+=(yt*self.C.shape[1]+yp).bincount(minlength=self.C.numel()).view(self.C.shape).float()\n",
    "\n",
    "  def clear(self):\n",
    "    # We set the confusion matrix to zero\n",
    "    self.C.zero_()\n",
    "\n",
    "  # Computes the global accuracy\n",
    "  def acc(self):\n",
    "    return self.C.diag().sum().item()/self.C.sum()\n",
    "\n",
    "  # Computes the class-averaged accuracy\n",
    "  def mAcc(self):\n",
    "    return (self.C.diag()/self.C.sum(-1)).mean().item()\n",
    "\n",
    "  # Computers the class-averaged Intersection over Union\n",
    "  def mIoU(self):\n",
    "    return (self.C.diag()/(self.C.sum(0)+self.C.sum(1)-self.C.diag())).mean().item()\n",
    "\n",
    "  # Returns the confusion matrix\n",
    "  def confusion_matrix(self):\n",
    "    return self.C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = {\"train\": train_loader, \"validation\" : valid_loader, \"test\" : test_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_types, edge_types = X_train[0].metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "from torch import nn\n",
    "from tqdm.notebook import tqdm\n",
    "from copy import deepcopy\n",
    "from typing_extensions import Self\n",
    "from torch_geometric.nn import SAGEConv, HeteroConv, GATConv, GCN  # Linear, GCNConv\n",
    "from torch.nn import ModuleList, Module, Sequential, Softmax, Dropout, Linear, ReLU\n",
    "from torch import mean, stack, concat\n",
    "\n",
    "\n",
    "class HGNN(Module):\n",
    "\n",
    "    def __init__(self, hid, out, layers, node_types, nodes_relations) -> Self:  # type: ignore\n",
    "        super().__init__()\n",
    "\n",
    "        # List of convolutional layers\n",
    "        self.convs = ModuleList()\n",
    "        for _ in range(layers):\n",
    "            conv = HeteroConv(\n",
    "                {relation: SAGEConv((-1, -1), hid, normalize=False) for relation in nodes_relations}\n",
    "                # {('Activity', 'followed_by', 'Activity') : SAGEConv((-1,-1), hid),\n",
    "                #  (\"org:resource\", \"related_to\", 'org:resource') : SAGEConv((-1,-1), hid),\n",
    "                #  ('time:timestamp', \"related_to\", \"time:timestamp\") : SAGEConv((-1,-1), hid)}\n",
    "                ,\n",
    "                aggr=\"sum\",\n",
    "            )\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        # print(nodes_relations)\n",
    "        # Take each node hid representation and apply a linear layer\n",
    "        # self.linear_nodes = Sequential(Linear(hid, hid),ReLU(), Dropout(p=0.5), Linear(hid, hid), ReLU(), Dropout(p=0.5), Linear(hid, int(hid / 2)), ReLU())\n",
    "\n",
    "        # Return the softmax with the class probabilities\n",
    "        # self.fc = Sequential(Linear(int(hid/2)*(len(node_types)), out), ReLU(), Softmax(dim=0))\n",
    "        self.fc_NA = Sequential(\n",
    "            Linear(hid * (len(node_types)), 256),\n",
    "            ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            Dropout(p=0.5),\n",
    "            Linear(256, 128),\n",
    "            ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            Linear(128, out),\n",
    "            # Softmax(dim=1)\n",
    "            # ReLU()\n",
    "        )\n",
    "        self.fc_timestamp = Sequential(\n",
    "            Linear(hid * (len(node_types)), 256),\n",
    "            ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            Dropout(p=0.5),\n",
    "            Linear(256, 128),\n",
    "            ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            Linear(128, 1),\n",
    "            \n",
    "        )\n",
    "        self.fc_org_resource = Sequential(\n",
    "            Linear(hid * (len(node_types)), 256),\n",
    "            ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            Dropout(p=0.5),\n",
    "            Linear(256, 128),\n",
    "            ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            Linear(128, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        outs = []\n",
    "        for i in range(len(x)):\n",
    "            for conv in self.convs:\n",
    "                x[i] = conv(x[i], edge_index[i])\n",
    "                x[i] = {node_type: nodes_features.relu() for node_type, nodes_features in x[i].items()}\n",
    "\n",
    "            # Node features of each node in the graph\n",
    "            nodes_features = [x[i][key] for key in x[i].keys()]\n",
    "            # print(nodes_features)\n",
    "            \n",
    "\n",
    "            # Global sum of each node type\n",
    "            for j in range(len(nodes_features)):\n",
    "                nodes_features[j] = torch.sum(nodes_features[j], dim=0)\n",
    "\n",
    "            # Global mean pooling\n",
    "            # nodes_features = mean(stack(nodes_features), dim=0)\n",
    "            nodes_features = concat(nodes_features)\n",
    "            outs.append(nodes_features)\n",
    "\n",
    "        outs = stack(outs)\n",
    "\n",
    "        activities = self.fc_NA(outs)\n",
    "        org_resources = self.fc_org_resource(outs)\n",
    "        timestamps = self.fc_timestamp(outs)\n",
    "\n",
    "        return [activities, timestamps, org_resources]  # {key : self.linear(x_dict[key]) for key in x_dict.keys()}, nodes_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "org:resource, related_to, org:resource)={\n",
    "    edge_attr=[1, 1],\n",
    "    edge_index=[2, 1],\n",
    "  },\n",
    "  (Activity, followed_by, Activity)={\n",
    "    edge_attr=[1, 1],\n",
    "    edge_index=[2, 1],\n",
    "  },\n",
    "  (time:timestamp, related_to, time:timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_train = {key:0 for key in range(10)}\n",
    "for i,(x,y) in enumerate(train_loader):\n",
    "    _,classes = torch.max(stack(y), dim=1)\n",
    "    for c in list(classes):\n",
    "        try:\n",
    "            cl_train[c.item()] +=1\n",
    "        except KeyError:\n",
    "            cl_train[c.item()] = 1\n",
    "            \n",
    "cl_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_val = {key:0 for key in range(10)}\n",
    "for i,(x,y) in enumerate(valid_loader):\n",
    "    _,classes = torch.max(stack(y), dim=1)\n",
    "    for c in list(classes):\n",
    "        try:\n",
    "            cl_val[c.item()] +=1\n",
    "        except KeyError:\n",
    "            cl_val[c.item()] = 1\n",
    "            \n",
    "cl_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_test = {key:0 for key in range(10)}\n",
    "for i,(x,y) in enumerate(test_loader):\n",
    "    _,classes = torch.max(stack(y), dim=1)\n",
    "    for c in list(classes):\n",
    "        try:\n",
    "            cl_test[c.item()] +=1\n",
    "        except KeyError:\n",
    "            cl_test[c.item()] = 1\n",
    "            \n",
    "cl_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "\n",
    "\n",
    "s = 0\n",
    "for i in cl_train:\n",
    "    s += cl_train[i]\n",
    "weights = [s/cl_train[k] if cl_train[k] != 0 else 0 for k in cl_train ]\n",
    "\n",
    "# weights = [0.7,0.7,1,0.7,0.7,0.7,0.7,0.7,0.7,0.7]\n",
    "weights = tensor(weights, device=device)\n",
    "weights[0] *= 0.7\n",
    "weights[1] *= 1\n",
    "weights[2] *= 0.7\n",
    "weights[3] *= 0.7\n",
    "weights[4] *= 1\n",
    "\n",
    "weights[0] *= 1\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HGNN(\n",
       "  (convs): ModuleList(\n",
       "    (0-3): 4 x HeteroConv(num_relations=8)\n",
       "  )\n",
       "  (fc_NA): Sequential(\n",
       "    (0): Linear(in_features=1536, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Linear(in_features=32, out_features=10, bias=True)\n",
       "  )\n",
       "  (fc_timestamp): Sequential(\n",
       "    (0): Linear(in_features=1536, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       "  (fc_org_resource): Sequential(\n",
       "    (0): Linear(in_features=1536, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = HGNN(hid=256, out=len(list_activities), layers=4, node_types=node_types, nodes_relations=edge_types)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i,(x,y) in enumerate(train_loader):\n",
    "        x = [xx.to(device) for xx in x]\n",
    "        \n",
    "        x_edge_index_dicts = [xx.edge_index_dict for xx in x]\n",
    "        x_dicts = [xx.x_dict for xx in x]\n",
    "        # print(\"//\"*50)\n",
    "        #print(x)\n",
    "        #print(x.edge_index_dict)\n",
    "        #print(x.x_dict)\n",
    "        # print(\"//\"*50)\n",
    "        \n",
    "        y = [yy.to(device) for yy in y]\n",
    "        y = stack(y)\n",
    "        model(x_dicts, x_edge_index_dicts)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1\n",
      "\n",
      "-- EPOCH 1/20 -------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b28d68218419436ba36ae0381dcca03f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26215/1584725792.py:164: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(preds.to(int32)), torch.tensor(true_preds.to(int32))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTRAIN | NA_acc: 0.6315 | mae_timestamp(s): 5.6924 | mae_org_resource: 7929.3899\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a69a45c1f10340428b7786354d74955c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTEST | NA_acc: 0.6248 | mae_timestamp(s): 46.4347 | mae_org_resource: 7807.4701\n",
      "\n",
      "-- EPOCH 2/20 -------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e528d427d0d411696e6b88cf44aa064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTRAIN | NA_acc: 0.6362 | mae_timestamp(s): 59.0460 | mae_org_resource: 7515.5884\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca321a19c1d248e6bf8f5fa198567c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTEST | NA_acc: 0.6943 | mae_timestamp(s): 87.2106 | mae_org_resource: 7118.8269\n",
      "SAVING MODEL..............\n",
      "\n",
      "\n",
      "-- EPOCH 3/20 -------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f39e0e3df84482f870b8ec1f43f5a72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTRAIN | NA_acc: 0.6723 | mae_timestamp(s): 180.2215 | mae_org_resource: 6580.6769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63df36df676d428791d695fbe303d3aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTEST | NA_acc: 0.7231 | mae_timestamp(s): 155.9060 | mae_org_resource: 6057.8764\n",
      "SAVING MODEL..............\n",
      "\n",
      "\n",
      "-- EPOCH 4/20 -------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "835b61b7beb544278a790b662e9c1891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTRAIN | NA_acc: 0.6759 | mae_timestamp(s): 293.7596 | mae_org_resource: 5101.8325\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb7f408147fa4d1faee87a13e07cf4b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTEST | NA_acc: 0.7092 | mae_timestamp(s): 280.7663 | mae_org_resource: 3936.1477\n",
      "\n",
      "-- EPOCH 5/20 -------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7886a40ea1be4325930477dbbb496b27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTRAIN | NA_acc: 0.6859 | mae_timestamp(s): 419.9242 | mae_org_resource: 3219.9729\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c0a60d960df404892ea327dc01cad26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTEST | NA_acc: 0.7057 | mae_timestamp(s): 108.6922 | mae_org_resource: 2056.3482\n",
      "\n",
      "-- EPOCH 6/20 -------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08a7438df40d459fa62f3d7dcb6c8513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTRAIN | NA_acc: 0.6818 | mae_timestamp(s): 277.3064 | mae_org_resource: 2096.6965\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94fdd8770d544c6c84a3abe2c40d4493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTEST | NA_acc: 0.7272 | mae_timestamp(s): 65.4186 | mae_org_resource: 1813.2149\n",
      "SAVING MODEL..............\n",
      "\n",
      "\n",
      "-- EPOCH 7/20 -------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc5344714be149a79a45af6afca2b61b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTRAIN | NA_acc: 0.6946 | mae_timestamp(s): 227.0166 | mae_org_resource: 2024.0435\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e2b68257895416fab1898fed13cde28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTEST | NA_acc: 0.7305 | mae_timestamp(s): 195.0237 | mae_org_resource: 1812.0186\n",
      "SAVING MODEL..............\n",
      "\n",
      "\n",
      "-- EPOCH 8/20 -------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2d8add41a5440a8a299a9e97b5aa174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTRAIN | NA_acc: 0.7049 | mae_timestamp(s): 229.5566 | mae_org_resource: 2014.5107\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a36690821dc49e79c08a3f3f3e6aeef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTEST | NA_acc: 0.6964 | mae_timestamp(s): 103.7995 | mae_org_resource: 1837.9572\n",
      "\n",
      "-- EPOCH 9/20 -------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2555c84d9d594dcb9eb95c51e35627b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTRAIN | NA_acc: 0.7119 | mae_timestamp(s): 226.7061 | mae_org_resource: 1994.9011\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c53bc4b447634ab9ab2cc20b99cabf07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTEST | NA_acc: 0.7279 | mae_timestamp(s): 39.5226 | mae_org_resource: 1800.0591\n",
      "\n",
      "-- EPOCH 10/20 -------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c041ec35b1f04d6fbd8cc2741c993e76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTRAIN | NA_acc: 0.7154 | mae_timestamp(s): 249.6753 | mae_org_resource: 1996.6585\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "facf5e9ca6f840628adf7524abf1bdce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTEST | NA_acc: 0.6895 | mae_timestamp(s): 146.0253 | mae_org_resource: 1849.4247\n",
      "\n",
      "-- EPOCH 11/20 -------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6f6fcc0deb649d9bd1b0f5b81f1e449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTRAIN | NA_acc: 0.7167 | mae_timestamp(s): 261.4873 | mae_org_resource: 1987.9747\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c6afc99a4649c4b82479571d1336e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTEST | NA_acc: 0.7644 | mae_timestamp(s): 54.6314 | mae_org_resource: 1834.8758\n",
      "SAVING MODEL..............\n",
      "\n",
      "\n",
      "-- EPOCH 12/20 -------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfd9742c12424b89af81658156ad5388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTRAIN | NA_acc: 0.7177 | mae_timestamp(s): 267.3299 | mae_org_resource: 1954.5316\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "191bf01e0cda4e33a3548d57ed926e7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTEST | NA_acc: 0.7057 | mae_timestamp(s): 145.2725 | mae_org_resource: 1836.0791\n",
      "\n",
      "-- EPOCH 13/20 -------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e86e78ea0c84eb4a2f0c2f077cbdda2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTRAIN | NA_acc: 0.7180 | mae_timestamp(s): 269.7009 | mae_org_resource: 1953.9154\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94473dae7d434ee58a4d064fc1e2edc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTEST | NA_acc: 0.7330 | mae_timestamp(s): 112.3218 | mae_org_resource: 1859.6975\n",
      "\n",
      "-- EPOCH 14/20 -------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b56379b209b461492fe59113e4fc45d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 120\u001b[0m\n\u001b[1;32m    116\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    118\u001b[0m _, true_preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(activities_labels, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 120\u001b[0m outputs_act, outputs_timestamp, outputs_org_resource \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_edge_index_dicts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m act_loss_step \u001b[38;5;241m=\u001b[39m act_loss(outputs_act, true_preds)\n\u001b[1;32m    125\u001b[0m timestamp_loss_step \u001b[38;5;241m=\u001b[39m timestamp_loss(outputs_timestamp, outputs_org_resource)\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[42], line 74\u001b[0m, in \u001b[0;36mHGNN.forward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(x)):\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs:\n\u001b[0;32m---> 74\u001b[0m         x[i] \u001b[38;5;241m=\u001b[39m \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m         x[i] \u001b[38;5;241m=\u001b[39m {node_type: nodes_features\u001b[38;5;241m.\u001b[39mrelu() \u001b[38;5;28;01mfor\u001b[39;00m node_type, nodes_features \u001b[38;5;129;01min\u001b[39;00m x[i]\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;66;03m# Node features of each node in the graph\u001b[39;00m\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch_geometric/nn/conv/hetero_conv.py:158\u001b[0m, in \u001b[0;36mHeteroConv.forward\u001b[0;34m(self, *args_dict, **kwargs_dict)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_edge_level_arg:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dst \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m out_dict:\n\u001b[1;32m    161\u001b[0m     out_dict[dst] \u001b[38;5;241m=\u001b[39m [out]\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch_geometric/nn/conv/sage_conv.py:134\u001b[0m, in \u001b[0;36mSAGEConv.forward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m    131\u001b[0m     x \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mrelu(), x[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor)\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_l(out)\n\u001b[1;32m    137\u001b[0m x_r \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/tmp/torch_geometric.nn.conv.sage_conv_SAGEConv_propagate_tclekm3w.py:229\u001b[0m, in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, x, size)\u001b[0m\n\u001b[1;32m    221\u001b[0m             kwargs \u001b[38;5;241m=\u001b[39m CollectArgs(\n\u001b[1;32m    222\u001b[0m                 x_j\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mx_j,\n\u001b[1;32m    223\u001b[0m                 index\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    224\u001b[0m                 ptr\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mptr\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    225\u001b[0m                 dim_size\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdim_size\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    226\u001b[0m             )\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# End Aggregate Forward Pre Hook #######################################\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43mptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m# Begin Aggregate Forward Hook #########################################\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:594\u001b[0m, in \u001b[0;36mMessagePassing.aggregate\u001b[0;34m(self, inputs, index, ptr, dim_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maggregate\u001b[39m(\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    579\u001b[0m     inputs: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m     dim_size: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    583\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    584\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Aggregates messages from neighbors as\u001b[39;00m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;124;03m    :math:`\\bigoplus_{j \\in \\mathcal{N}(i)}`.\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;124;03m    as specified in :meth:`__init__` by the :obj:`aggr` argument.\u001b[39;00m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 594\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggr_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch_geometric/experimental.py:117\u001b[0m, in \u001b[0;36mdisable_dynamic_shapes.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_experimental_mode_enabled(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisable_dynamic_shapes\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m required_arg \u001b[38;5;129;01min\u001b[39;00m required_args:\n\u001b[1;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m required_args_pos[required_arg]\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch_geometric/nn/aggr/base.py:131\u001b[0m, in \u001b[0;36mAggregation.__call__\u001b[0;34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m     dim_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(index\u001b[38;5;241m.\u001b[39mmax()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch_geometric/nn/aggr/basic.py:36\u001b[0m, in \u001b[0;36mMeanAggregation.forward\u001b[0;34m(self, x, index, ptr, dim_size, dim)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor, index: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     34\u001b[0m             ptr: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, dim_size: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     35\u001b[0m             dim: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch_geometric/nn/aggr/base.py:185\u001b[0m, in \u001b[0;36mAggregation.reduce\u001b[0;34m(self, x, index, ptr, dim_size, dim, reduce)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAggregation requires \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to be specified\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch_geometric/utils/_scatter.py:79\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     78\u001b[0m     count \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mnew_zeros(dim_size)\n\u001b[0;32m---> 79\u001b[0m     \u001b[43mcount\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter_add_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_ones\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     count \u001b[38;5;241m=\u001b[39m count\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     82\u001b[0m     index \u001b[38;5;241m=\u001b[39m broadcast(index, src, dim)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch import int32, tensor\n",
    "\n",
    "# model = HGNN(hid=16, out=len(list_activities), layers=2, node_types=node_types, nodes_relations=edge_types)\n",
    "\n",
    "\n",
    "num_epochs = 20\n",
    "best_accuracy = 0\n",
    "early_stop_patience = 10\n",
    "lr_value = 0.01\n",
    "\n",
    "best_model = None\n",
    "\n",
    "num_runs = 1\n",
    "running_time = []\n",
    "\n",
    "metric_tracker = ClassificationMetrics(num_classes=len(list_activities))\n",
    "\n",
    "for run in range(num_runs):\n",
    "\n",
    "    start = datetime.datetime.now()\n",
    "    print(\"Run: {}\".format(run + 1))\n",
    "\n",
    "    # model = model.to(device)\n",
    "\n",
    "    # print(\"compiling...\")\n",
    "    # model = torch.compile(model, dynamic=True)\n",
    "    # print(\"Compiled model\")\n",
    "\n",
    "    # criterion = nn.CrossEntropyLoss(weight=weights, label_smoothing=0.1)\n",
    "    # criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "    act_loss = nn.CrossEntropyLoss()\n",
    "    timestamp_loss = nn.L1Loss()\n",
    "    org_resource_loss = nn.L1Loss()\n",
    "\n",
    "    # optimizer = torch.optim.Adagrad(model.parameters(), lr=lr_value) # momentum=0.9, weight_decay=1e-1)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr_value)\n",
    "\n",
    "    not_improved_count = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\n",
    "            \"\\n-- EPOCH {}/{} -------------------------\\n\".format(epoch + 1, num_epochs)\n",
    "        )\n",
    "        torch.cuda.empty_cache()\n",
    "        count_train = [0 for _ in range(len(list_activities))]\n",
    "        count_true_train = [0 for _ in range(len(list_activities))]\n",
    "        count_val = [0 for _ in range(len(list_activities))]\n",
    "        count_true_val = [0 for _ in range(len(list_activities))]\n",
    "\n",
    "\n",
    "        avg_mse_timestamp = []\n",
    "        avg_mse_org_resource = []\n",
    "\n",
    "        for state in [\"train\", \"test\"]:\n",
    "\n",
    "\n",
    "            if state == \"train\":\n",
    "                model.train()\n",
    "                metric_tracker.clear()\n",
    "             \n",
    "\n",
    "            else:\n",
    "\n",
    "         \n",
    "                print(\n",
    "                    \"\\tTRAIN | NA_acc: {:.4f} | mae_timestamp(s): {:.4f} | mae_org_resource: {:.4f}\".format(\n",
    "                        metric_tracker.acc(),\n",
    "                        sum(avg_mse_timestamp) / len(avg_mse_timestamp),\n",
    "                        sum(avg_mse_org_resource) / len(avg_mse_org_resource)\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                avg_mse_timestamp = []\n",
    "                avg_mse_org_resource = []\n",
    "                metric_tracker.clear()\n",
    "                model.eval()\n",
    "             \n",
    "\n",
    "            \n",
    "\n",
    "            for i, (x, y) in tqdm(enumerate(loaders[state])):\n",
    "\n",
    "                # if i % 1 == 0:\n",
    "                #     print(metric_tracker.acc())\n",
    "                #     # print(running_loss/i)\n",
    "                #     print(metric_tracker.confusion_matrix())\n",
    "                #     # print(count_train)\n",
    "                #     # print(count_true_train)\n",
    "                #     print(\"//\" * 14)\n",
    "                # print(\"X\")\n",
    "                # print(\"//\"*50)\n",
    "                # print(x)\n",
    "                # print(\"//\"*50)\n",
    "                # print(y)\n",
    "                x = [xx.to(device) for xx in x]\n",
    "                x_edge_index_dicts = [xx.edge_index_dict for xx in x]\n",
    "                x_dicts = [xx.x_dict for xx in x]\n",
    "                # print(\"//\"*50)\n",
    "                # print(x)\n",
    "                # print(x.edge_index_dict)\n",
    "                # print(x.x_dict)\n",
    "                # print(\"//\"*50)\n",
    "\n",
    "                activities_labels = [yy[0].to(device) for yy in y]\n",
    "                activities_labels = stack(activities_labels)\n",
    "\n",
    "                timestamp_labels = [yy[1].to(device) for yy in y]\n",
    "                timestamp_labels = stack(timestamp_labels)\n",
    "\n",
    "                org_resource_labels = [yy[2].to(device) for yy in y]\n",
    "                org_resource_labels = stack(org_resource_labels)\n",
    "\n",
    "               \n",
    "\n",
    "                if state == \"train\":\n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    _, true_preds = torch.max(activities_labels, 1)\n",
    "                    \n",
    "                    outputs_act, outputs_timestamp, outputs_org_resource = model(x_dicts, x_edge_index_dicts)\n",
    "                    \n",
    "                    act_loss_step = act_loss(outputs_act, true_preds)\n",
    "                    \n",
    "                    \n",
    "                    timestamp_loss_step = timestamp_loss(outputs_timestamp, outputs_org_resource)\n",
    "                    avg_mse_timestamp.append(timestamp_loss_step.item())\n",
    "\n",
    "                    \n",
    "                    org_resource_loss_step = org_resource_loss(outputs_org_resource, org_resource_labels)\n",
    "                    avg_mse_org_resource.append(org_resource_loss_step.item())\n",
    "                    \n",
    "                    \n",
    "                    total_loss = act_loss_step + timestamp_loss_step + 3*org_resource_loss_step\n",
    "                    total_loss.backward()\n",
    "\n",
    "                    optimizer.step()\n",
    "                else:\n",
    "                    with torch.no_grad():\n",
    "                        _, true_preds = torch.max(activities_labels, 1)\n",
    "                        \n",
    "                        \n",
    "                        outputs_act, outputs_timestamp, outputs_org_resource = model(x_dicts, x_edge_index_dicts)\n",
    "\n",
    "                        # act_loss_step = act_loss(outputs_act, true_preds)\n",
    "\n",
    "                        timestamp_loss_step = timestamp_loss(outputs_timestamp, outputs_org_resource)\n",
    "                        avg_mse_timestamp.append(timestamp_loss_step.item())\n",
    "\n",
    "                        org_resource_loss_step = org_resource_loss(outputs_org_resource, org_resource_labels)\n",
    "                        avg_mse_org_resource.append(org_resource_loss_step.item())\n",
    "                    \n",
    "                    \n",
    "                   \n",
    "\n",
    "\n",
    "                _, preds = torch.max(outputs_act, 1)\n",
    "\n",
    "                \n",
    "                \n",
    "                preds = preds.to(device)\n",
    "                true_preds = true_preds.to(device)\n",
    "                \n",
    "                metric_tracker.add(\n",
    "                    torch.tensor(preds.to(int32)), torch.tensor(true_preds.to(int32))\n",
    "                )\n",
    "                \n",
    "\n",
    "        \n",
    "        print(\n",
    "                    \"\\tTEST | NA_acc: {:.4f} | mae_timestamp(s): {:.4f} | mae_org_resource: {:.4f}\".format(\n",
    "                        metric_tracker.acc(),\n",
    "                        sum(avg_mse_timestamp) / len(avg_mse_timestamp),\n",
    "                        sum(avg_mse_org_resource) / len(avg_mse_org_resource)\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        if epoch == 0:\n",
    "            best_accuracy = metric_tracker.acc()\n",
    "\n",
    "        else:\n",
    "            if metric_tracker.acc() > best_accuracy:\n",
    "                print(\"SAVING MODEL..............\\n\")\n",
    "                best_accuracy = metric_tracker.acc()\n",
    "                not_improved_count = 0\n",
    "            else:\n",
    "                not_improved_count += 1\n",
    "\n",
    "        if not_improved_count == early_stop_patience:\n",
    "            print(\n",
    "                \"Validation performance didn't improve for {} epochs. \"\n",
    "                \"Training stops.\".format(early_stop_patience)\n",
    "            )\n",
    "            break\n",
    "\n",
    "    running_time.append((datetime.datetime.now() - start).total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"multi_obj_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hgnn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
