{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from os.path import dirname\n",
    "\n",
    "\n",
    "\n",
    "root_path = dirname(os.getcwd()) + \"/HGNN_NA\"\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "data_dir = root_path + \"/data/datasets/original/\"\n",
    "data_dir_processed = root_path + \"/data/datasets/processed/\"\n",
    "data_dir_graphs = root_path + \"/data/datasets/graphs/\"\n",
    "\n",
    "print(root_path, data_dir, data_dir_processed, data_dir_graphs, sep=\"\\n\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"BPI_Challenge_2012_A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_all = pd.read_csv(data_dir_processed+dataset+\"_processed_all.csv\")\n",
    "print(tab_all.head())\n",
    "list_activities = list(tab_all[\"Activity\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir_graphs + dataset + \"_TRAIN.pkl\", \"rb\") as f:\n",
    "    X_train, Y_train = pickle.load(f)\n",
    "with open(data_dir_graphs + dataset + \"_VALID.pkl\", \"rb\") as f:\n",
    "    X_valid, Y_valid = pickle.load(f)\n",
    "with open(data_dir_graphs + dataset + \"_TEST.pkl\", \"rb\") as f:\n",
    "    X_test, Y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Self\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "class Het_graph_data(Dataset):\n",
    "    def __init__(self, prefix_graphs, labels) -> Self:\n",
    "        self.X = prefix_graphs\n",
    "        self.Y = labels\n",
    "\n",
    "    # get the number of rows in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "\n",
    "    # get a row at a particular index in the dataset\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "\n",
    "    @staticmethod\n",
    "    def collate(batch):\n",
    "        # print(batch)\n",
    "        data = [item[0] for item in batch]\n",
    "        Y = [item[1] for item in batch]\n",
    "        return [data, Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    Het_graph_data(X_train, Y_train),\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    collate_fn=Het_graph_data.collate,\n",
    ")\n",
    "\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    Het_graph_data(X_valid, Y_valid),\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    collate_fn=Het_graph_data.collate,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    Het_graph_data(X_test, Y_test),\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    collate_fn=Het_graph_data.collate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Class to keep track of the metrics of the classification process\n",
    "class ClassificationMetrics:\n",
    "\n",
    "  # Constructor takes the number of classes, in our case 20\n",
    "  def __init__(self, num_classes=20):\n",
    "    self.num_classes = num_classes\n",
    "    # Initialize a confusion matrix\n",
    "    self.C = torch.zeros(num_classes, num_classes)\n",
    "\n",
    "  # Update the confusion matrix with the new scores\n",
    "  def add(self, yp, yt):\n",
    "    # yp: 1D tensor with predictions\n",
    "    # yt: 1D tensor with ground-truth targets\n",
    "    yp = yp.to(\"cpu\")\n",
    "    yt = yt.to(\"cpu\")\n",
    "    with torch.no_grad(): # We require no computation graph\n",
    "      self.C+=(yt*self.C.shape[1]+yp).bincount(minlength=self.C.numel()).view(self.C.shape).float()\n",
    "\n",
    "  def clear(self):\n",
    "    # We set the confusion matrix to zero\n",
    "    self.C.zero_()\n",
    "\n",
    "  # Computes the global accuracy\n",
    "  def acc(self):\n",
    "    return self.C.diag().sum().item()/self.C.sum()\n",
    "\n",
    "  # Computes the class-averaged accuracy\n",
    "  def mAcc(self):\n",
    "    return (self.C.diag()/self.C.sum(-1)).mean().item()\n",
    "\n",
    "  # Computers the class-averaged Intersection over Union\n",
    "  def mIoU(self):\n",
    "    return (self.C.diag()/(self.C.sum(0)+self.C.sum(1)-self.C.diag())).mean().item()\n",
    "\n",
    "  # Returns the confusion matrix\n",
    "  def confusion_matrix(self):\n",
    "    return self.C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = {\"train\": train_loader, \"validation\" : valid_loader, \"test\" : test_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_types, edge_types = X_train[0].metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].x_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models.models import HGNN\n",
    "import datetime\n",
    "\n",
    "from torch import nn\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Self\n",
    "from torch_geometric.nn import SAGEConv, HeteroConv, GATConv, Linear, GCNConv\n",
    "from torch.nn import ModuleList, Module, Sequential, Softmax, Dropout\n",
    "from torch import mean, stack, sum, concat\n",
    "\n",
    "\n",
    "class HGNN(Module):\n",
    "\n",
    "    def __init__(self, hid, out, layers, node_types, nodes_relations) -> Self:  # type: ignore\n",
    "        super().__init__()\n",
    "\n",
    "        # List of convolutional layers\n",
    "        self.convs = ModuleList()\n",
    "        for _ in range(layers):\n",
    "            self.convs.append(\n",
    "                HeteroConv(\n",
    "                    {relation:SAGEConv((-1, -1), hid) for relation in nodes_relations}\n",
    "                    ,\n",
    "                    aggr=\"mean\",\n",
    "                )\n",
    "            )\n",
    "        print(nodes_relations)\n",
    "        # Take each node hid representation and apply a linear layer\n",
    "        self.linear_nodes = Linear(hid, hid)\n",
    "\n",
    "        # Return the softmax with the class probabilities\n",
    "        self.fc = Sequential(Linear(hid*len(node_types), out), Softmax())\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        \n",
    "        x_dict = x_dict[0]\n",
    "        edge_index_dict = edge_index_dict[0]\n",
    "        # Convolutional layers\n",
    "        for conv in self.convs:\n",
    "            print(\"HEYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYY\")\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "            print(\"HEYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYY\")\n",
    "            x_dict = {key: x.relu() for key, x in x_dict.items()}\n",
    "\n",
    "        print(x_dict)\n",
    "        # Node features of each node in the graph\n",
    "        nodes_features = [\n",
    "            self.linear_nodes(x_dict[key]).relu() for key in x_dict.keys()\n",
    "        ]\n",
    "        print(nodes_features)\n",
    "        # Global mean of each node type\n",
    "        for i in range(len(nodes_features)):\n",
    "            nodes_features[i] = mean(nodes_features[i], dim=0)\n",
    "\n",
    "        # print(nodes_features)\n",
    "        # print(concat(nodes_features))\n",
    "        # Global mean pooling\n",
    "        #nodes_features = mean(stack(nodes_features), dim=0)\n",
    "        nodes_features = concat(nodes_features)\n",
    "        nodes_features = self.fc(nodes_features)\n",
    "\n",
    "        return nodes_features  # {key : self.linear(x_dict[key]) for key in x_dict.keys()}, nodes_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('org:resource', 'related_to', 'org:resource'),\n",
      " ('Activity', 'followed_by', 'Activity'),\n",
      " ('time:timestamp', 'related_to', 'time:timestamp'),\n",
      " ('Activity', 'related_to', 'org:resource'),\n",
      " ('Activity', 'related_to', 'lifecycle:transition'),\n",
      " ('Activity', 'related_to', 'time:timestamp'),\n",
      " ('Activity', 'related_to', 'case:REG_DATE'),\n",
      " ('Activity', 'related_to', 'case:AMOUNT_REQ')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HGNN(\n",
       "  (convs): ModuleList(\n",
       "    (0-3): 4 x HeteroConv(num_relations=8)\n",
       "  )\n",
       "  (linear_nodes): Linear(64, 64, bias=True)\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(384, 10, bias=True)\n",
       "    (1): Softmax(dim=None)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = HGNN(hid=64, out=len(list_activities), layers=4, node_types=node_types, nodes_relations=edge_types)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].x_dict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].edge_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint as print\n",
    "print(\"x_dict:\")\n",
    "print({k: v.shape for k, v in X_train[0].x_dict.items()})\n",
    "print(\"edge_index_dict:\")\n",
    "print({k: v.shape for k, v in X_train[0].edge_index_dict.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'HEYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYY'\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got -2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_dict\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index_dict\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[27], line 36\u001b[0m, in \u001b[0;36mHGNN.forward\u001b[0;34m(self, x_dict, edge_index_dict)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m     x_dict \u001b[38;5;241m=\u001b[39m \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m     x_dict \u001b[38;5;241m=\u001b[39m {key: x\u001b[38;5;241m.\u001b[39mrelu() \u001b[38;5;28;01mfor\u001b[39;00m key, x \u001b[38;5;129;01min\u001b[39;00m x_dict\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch_geometric/nn/conv/hetero_conv.py:158\u001b[0m, in \u001b[0;36mHeteroConv.forward\u001b[0;34m(self, *args_dict, **kwargs_dict)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_edge_level_arg:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dst \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m out_dict:\n\u001b[1;32m    161\u001b[0m     out_dict[dst] \u001b[38;5;241m=\u001b[39m [out]\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch_geometric/nn/conv/sage_conv.py:134\u001b[0m, in \u001b[0;36mSAGEConv.forward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m    131\u001b[0m     x \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mrelu(), x[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor)\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_l(out)\n\u001b[1;32m    137\u001b[0m x_r \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/tmp/torch_geometric.nn.conv.sage_conv_SAGEConv_propagate__c9jly_z.py:173\u001b[0m, in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, x, size)\u001b[0m\n\u001b[1;32m    167\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m    168\u001b[0m         out,\n\u001b[1;32m    169\u001b[0m     )\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmutable_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;66;03m# Begin Message Forward Pre Hook #######################################\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "File \u001b[0;32m/tmp/torch_geometric.nn.conv.sage_conv_SAGEConv_propagate__c9jly_z.py:82\u001b[0m, in \u001b[0;36mcollect\u001b[0;34m(self, edge_index, x, size)\u001b[0m\n\u001b[1;32m     80\u001b[0m _x_0, _x_1 \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m0\u001b[39m], x[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(_x_0, Tensor):\n\u001b[0;32m---> 82\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_x_0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m     x_j \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_select(_x_0, edge_index_j)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:257\u001b[0m, in \u001b[0;36mMessagePassing._set_size\u001b[0;34m(self, size, dim, src)\u001b[0m\n\u001b[1;32m    255\u001b[0m the_size \u001b[38;5;241m=\u001b[39m size[dim]\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m the_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 257\u001b[0m     size[dim] \u001b[38;5;241m=\u001b[39m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m the_size \u001b[38;5;241m!=\u001b[39m src\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEncountered tensor with size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdimension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but expected size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mthe_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got -2)"
     ]
    }
   ],
   "source": [
    "model([X_train[0].x_dict],[X_train[0].edge_index_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "best_accuracy = 0\n",
    "early_stop_patience = 10\n",
    "lr_value = 1e-2\n",
    "\n",
    "best_model = None\n",
    "\n",
    "num_runs = 1\n",
    "running_time = []\n",
    "\n",
    "metric_tracker = ClassificationMetrics(num_classes=len(list_activities))\n",
    "\n",
    "for run in range(num_runs):\n",
    "    \n",
    "    start = datetime.datetime.now()\n",
    "    print(\"Run: {}\".format(run + 1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = model.to(device)\n",
    "    #print(\"compiling...\")\n",
    "    #model = torch.compile(model, dynamic=True)\n",
    "    #print(\"Compiled model\")\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr_value) # momentum=0.9, weight_decay=1e-1)\n",
    "\n",
    "    \n",
    "    not_improved_count = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(\n",
    "            \"\\n-- EPOCH {}/{} -------------------------\\n\".format(epoch + 1, num_epochs)\n",
    "        )\n",
    "        torch.cuda.empty_cache()\n",
    "        count_train = [0 for _ in range(len(list_activities))]\n",
    "        count_val = [0 for _ in range(len(list_activities))]\n",
    "        for state in [\"train\", \"validation\"]:\n",
    "            if state == \"train\":\n",
    "                model.train()\n",
    "                metric_tracker.clear()\n",
    "                # true_label = []\n",
    "                # predictions = []\n",
    "                # scores = []\n",
    "\n",
    "            else:\n",
    "                \n",
    "                # print(metric_tracker.confusion_matrix())\n",
    "                print(count_train)\n",
    "                \n",
    "                print(\"\\tTRAIN | acc: {:.4f} | mAcc: {:.4f} | mIoU: {:.4f}\".format(metric_tracker.acc(),\n",
    "                                                                                   #metric_tracker.mAcc(),\n",
    "                                                                                   #metric_tracker.mIoU()\n",
    "                                                                                   0,0))\n",
    "                \n",
    "                # y_true = np.concatenate(true_label)\n",
    "                # y_pred = np.concatenate(predictions)\n",
    "                # scores = np.concatenate(scores)\n",
    "                \n",
    "                # print(\"TRAIN\")\n",
    "                # print(conta(y_true, 0), conta(y_true, 1))\n",
    "                # print(conta(y_pred, 0), conta(y_pred, 1))\n",
    "                \n",
    "                # print_stats(y_pred, y_true, scores)\n",
    "                metric_tracker.clear()\n",
    "                model.eval()\n",
    "                # true_label = []\n",
    "                # predictions = []\n",
    "                # scores = []\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for i,(x,y) in tqdm(enumerate(loaders[state])):\n",
    "                # print(\"X\")\n",
    "                # print(\"//\"*50)\n",
    "                # print(x)\n",
    "                # print(\"//\"*50)\n",
    "                # print(y)\n",
    "                x = x[0].to(device)\n",
    "                print(\"//\"*50)\n",
    "                #print(x)\n",
    "                #print(x.edge_index_dict)\n",
    "                #print(x.x_dict)\n",
    "                print(\"//\"*50)\n",
    "                \n",
    "                y = y[0].to(device)\n",
    "                \n",
    "                #x = [[sub_item.to(device=device) for sub_item in item] for item in x]\n",
    "\n",
    "\n",
    "                #y = torch.tensor([torch.max(yi,0)[1] for yi in y])\n",
    "\n",
    "                #y = y.to(device)\n",
    "                \n",
    "                outputs = model([x.x_dict], [x.edge_index_dict])\n",
    "                \n",
    "         \n",
    "                \n",
    "                outputs = outputs.to(device)\n",
    "                \n",
    "                loss = criterion(outputs, y)\n",
    "\n",
    "                if state == \"train\":\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                _, preds = torch.max(outputs, 1)                \n",
    "                preds = preds.to(device)\n",
    "                if state == \"train\":\n",
    "                    for i in preds:\n",
    "                        count_train[i] += 1\n",
    "                else:\n",
    "                    for i in preds:\n",
    "                        count_val[i] += 1              \n",
    "                metric_tracker.add(preds, y)\n",
    "                \n",
    "                \n",
    "        print(count_val)\n",
    "        print(\"\\tEVAL  | acc: {:.4f} | mAcc: {:.4f} | mIoU: {:.4f}\\n\".format(metric_tracker.acc(),\n",
    "                                                                             # metric_tracker.mAcc(),\n",
    "                                                                             # metric_tracker.mIoU()\n",
    "                                                                             # )\n",
    "                                                                            0,0)   )     \n",
    "                   \n",
    "\n",
    "        if epoch == 0:# HERE WE KEEP BEST AUC VALUE\n",
    "            best_accuracy = metric_tracker.acc()\n",
    "            \n",
    "        else:\n",
    "            if metric_tracker.acc() > best_accuracy:\n",
    "                print(\"SAVING MODEL..............\\n\")\n",
    "                best_accuracy = metric_tracker.acc()\n",
    "                not_improved_count = 0\n",
    "            else:\n",
    "                not_improved_count += 1\n",
    "\n",
    "        if not_improved_count == early_stop_patience:\n",
    "            print(\n",
    "                \"Validation performance didn't improve for {} epochs. \"\n",
    "                \"Training stops.\".format(early_stop_patience)\n",
    "            )\n",
    "            break\n",
    "\n",
    "    running_time.append((datetime.datetime.now() - start).total_seconds())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hgnn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
