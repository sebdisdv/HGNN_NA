{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sebdis/ProcessMining/HGNN/HGNN_NA\n",
      "/home/sebdis/ProcessMining/HGNN/HGNN_NA/data/datasets/original/\n",
      "/home/sebdis/ProcessMining/HGNN/HGNN_NA/data/datasets/processed/\n",
      "/home/sebdis/ProcessMining/HGNN/HGNN_NA/data/datasets/graphs/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from os.path import dirname\n",
    "\n",
    "\n",
    "\n",
    "root_path = dirname(os.getcwd()) + \"/HGNN_NA\"\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "data_dir = root_path + \"/data/datasets/original/\"\n",
    "data_dir_processed = root_path + \"/data/datasets/processed/\"\n",
    "data_dir_graphs = root_path + \"/data/datasets/graphs/\"\n",
    "\n",
    "print(root_path, data_dir, data_dir_processed, data_dir_graphs, sep=\"\\n\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"BPI_Challenge_2012_A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   org:resource lifecycle:transition           Activity       time:timestamp  \\\n",
      "0           112             COMPLETE        A_SUBMITTED  2011/09/30 22:38:44   \n",
      "1           112             COMPLETE  A_PARTLYSUBMITTED  2011/09/30 22:38:44   \n",
      "2           112             COMPLETE      A_PREACCEPTED  2011/09/30 22:39:37   \n",
      "3         10862             COMPLETE         A_ACCEPTED  2011/10/01 09:42:43   \n",
      "4         10862             COMPLETE        A_FINALIZED  2011/10/01 09:45:09   \n",
      "\n",
      "         case:REG_DATE  CaseID  case:AMOUNT_REQ  \n",
      "0  2011/10/01 00:38:44  173688            20000  \n",
      "1  2011/10/01 00:38:44  173688            20000  \n",
      "2  2011/10/01 00:38:44  173688            20000  \n",
      "3  2011/10/01 00:38:44  173688            20000  \n",
      "4  2011/10/01 00:38:44  173688            20000  \n"
     ]
    }
   ],
   "source": [
    "tab_all = pd.read_csv(data_dir_processed+dataset+\"_processed_all.csv\")\n",
    "print(tab_all.head())\n",
    "list_activities = list(tab_all[\"Activity\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir_graphs + dataset + \"_TRAIN.pkl\", \"rb\") as f:\n",
    "    X_train, Y_train = pickle.load(f)\n",
    "with open(data_dir_graphs + dataset + \"_VALID.pkl\", \"rb\") as f:\n",
    "    X_valid, Y_valid = pickle.load(f)\n",
    "with open(data_dir_graphs + dataset + \"_TEST.pkl\", \"rb\") as f:\n",
    "    X_test, Y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Self\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.transforms import ToUndirected\n",
    "\n",
    "transform = ToUndirected()\n",
    "\n",
    "class Het_graph_data(Dataset):\n",
    "    def __init__(self, prefix_graphs, labels) -> Self:\n",
    "        self.X = prefix_graphs\n",
    "        self.Y = labels\n",
    "\n",
    "    # get the number of rows in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "\n",
    "    # get a row at a particular index in the dataset\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "\n",
    "    @staticmethod\n",
    "    def collate(batch):\n",
    "        # print(batch)\n",
    "        data = [transform(item[0]) for item in batch]\n",
    "        Y = [item[1] for item in batch]\n",
    "        return [data, Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    Het_graph_data(X_train, Y_train),\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    collate_fn=Het_graph_data.collate,\n",
    ")\n",
    "\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    Het_graph_data(X_valid, Y_valid),\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    collate_fn=Het_graph_data.collate,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    Het_graph_data(X_test, Y_test),\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    collate_fn=Het_graph_data.collate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Class to keep track of the metrics of the classification process\n",
    "class ClassificationMetrics:\n",
    "\n",
    "  # Constructor takes the number of classes, in our case 20\n",
    "  def __init__(self, num_classes=20):\n",
    "    self.num_classes = num_classes\n",
    "    # Initialize a confusion matrix\n",
    "    self.C = torch.zeros(num_classes, num_classes)\n",
    "\n",
    "  # Update the confusion matrix with the new scores\n",
    "  def add(self, yp, yt):\n",
    "    # yp: 1D tensor with predictions\n",
    "    # yt: 1D tensor with ground-truth targets\n",
    "    yp = yp.to(\"cpu\")\n",
    "    yt = yt.to(\"cpu\")\n",
    "    with torch.no_grad(): # We require no computation graph\n",
    "      self.C+=(yt*self.C.shape[1]+yp).bincount(minlength=self.C.numel()).view(self.C.shape).float()\n",
    "\n",
    "  def clear(self):\n",
    "    # We set the confusion matrix to zero\n",
    "    self.C.zero_()\n",
    "\n",
    "  # Computes the global accuracy\n",
    "  def acc(self):\n",
    "    return self.C.diag().sum().item()/self.C.sum()\n",
    "\n",
    "  # Computes the class-averaged accuracy\n",
    "  def mAcc(self):\n",
    "    return (self.C.diag()/self.C.sum(-1)).mean().item()\n",
    "\n",
    "  # Computers the class-averaged Intersection over Union\n",
    "  def mIoU(self):\n",
    "    return (self.C.diag()/(self.C.sum(0)+self.C.sum(1)-self.C.diag())).mean().item()\n",
    "\n",
    "  # Returns the confusion matrix\n",
    "  def confusion_matrix(self):\n",
    "    return self.C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = {\"train\": train_loader, \"validation\" : valid_loader, \"test\" : test_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_types, edge_types = X_train[0].metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].x_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models.models import HGNN\n",
    "import datetime\n",
    "\n",
    "from torch import nn\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from typing_extensions import Self\n",
    "from torch_geometric.nn import SAGEConv, HeteroConv, GATConv # Linear, GCNConv\n",
    "from torch.nn import ModuleList, Module, Sequential, Softmax, Dropout, Linear\n",
    "from torch import mean, stack, sum, concat\n",
    "\n",
    "\n",
    "class HGNN(Module):\n",
    "\n",
    "    def __init__(self, hid, out, layers, node_types, nodes_relations) -> Self:  # type: ignore\n",
    "        super().__init__()\n",
    "\n",
    "        # List of convolutional layers\n",
    "        self.convs = ModuleList()\n",
    "        for _ in range(layers):\n",
    "            conv = HeteroConv(\n",
    "                    {relation:SAGEConv((-1, -1), hid) for relation in nodes_relations}\n",
    "                    # {('Activity', 'followed_by', 'Activity') : SAGEConv((-1,-1), hid),\n",
    "                    #  (\"org:resource\", \"related_to\", 'org:resource') : SAGEConv((-1,-1), hid),\n",
    "                    #  ('time:timestamp', \"related_to\", \"time:timestamp\") : SAGEConv((-1,-1), hid)}\n",
    "                    ,\n",
    "                    aggr=\"sum\",\n",
    "                )\n",
    "            self.convs.append(conv)\n",
    "            \n",
    "        #print(nodes_relations)\n",
    "        # Take each node hid representation and apply a linear layer\n",
    "        self.linear_nodes = Sequential(Linear(hid, hid), Dropout(p=0.7), Linear(hid, int(hid / 2)))\n",
    "\n",
    "        # Return the softmax with the class probabilities\n",
    "        self.fc = Sequential(Linear(int(hid/2)*(len(node_types)), out), Softmax(dim=0))\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        \n",
    "        # x_dict = x_dict[0]\n",
    "        # edge_index_dict = edge_index_dict[0]\n",
    "        # Convolutional layers\n",
    "        # print(x_dict)\n",
    "        # x_dict_copy = deepcopy(x_dict)\n",
    "        # print(edge_index_dict)\n",
    "        for conv in self.convs:\n",
    "            #print(\"HEYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYY\")\n",
    "            #print(x_dict)\n",
    "            #print(conv)\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "            #print(x_dict)\n",
    "            #print(\"HEYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYY\")\n",
    "            x_dict = {key: x.relu() for key, x in x_dict.items()}\n",
    "\n",
    "        # print(x_dict)\n",
    "        # Node features of each node in the graph\n",
    "        nodes_features = [\n",
    "            self.linear_nodes(x_dict[key]).relu() for key in x_dict.keys()\n",
    "        ]\n",
    "        # print(nodes_features)\n",
    "        # Global mean of each node type\n",
    "        for i in range(len(nodes_features)):\n",
    "            nodes_features[i] = mean(nodes_features[i], dim=0)\n",
    "\n",
    "        # print(nodes_features)\n",
    "        # print(concat(nodes_features))\n",
    "        # Global mean pooling\n",
    "        #nodes_features = mean(stack(nodes_features), dim=0)\n",
    "        nodes_features = concat(nodes_features)\n",
    "        nodes_features = self.fc(nodes_features)\n",
    "\n",
    "        return nodes_features  # {key : self.linear(x_dict[key]) for key in x_dict.keys()}, nodes_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "org:resource, related_to, org:resource)={\n",
    "    edge_attr=[1, 1],\n",
    "    edge_index=[2, 1],\n",
    "  },\n",
    "  (Activity, followed_by, Activity)={\n",
    "    edge_attr=[1, 1],\n",
    "    edge_index=[2, 1],\n",
    "  },\n",
    "  (time:timestamp, related_to, time:timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HGNN(\n",
       "  (convs): ModuleList(\n",
       "    (0-1): 2 x HeteroConv(num_relations=8)\n",
       "  )\n",
       "  (linear_nodes): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (1): Dropout(p=0.3, inplace=False)\n",
       "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=96, out_features=10, bias=True)\n",
       "    (1): Softmax(dim=0)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = HGNN(hid=128, out=len(list_activities), layers=4, node_types=node_types, nodes_relations=edge_types)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].x_dict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].edge_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.transforms import ToUndirected\n",
    "\n",
    "X_train[0] = ToUndirected()(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].x_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].edge_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].is_directed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    print(model(X_train[0].x_dict,X_train[0].edge_index_dict))\n",
    "    print(Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_t = {}\n",
    "for i,(x,y) in enumerate(loaders['test']):\n",
    "    _,pr = torch.max(y[0], dim=0)\n",
    "    try:\n",
    "        k_t[pr.item()] += 1\n",
    "    except KeyError:\n",
    "        k_t[pr.item()] = 1\n",
    "k_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_t = []\n",
    "for i,(x,y) in enumerate(loaders['validation']):\n",
    "    k_t.append(\"__\".join(list(x[0].x_dict.keys())))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_t[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_t_s = set(k_t)\n",
    "k_t_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "m  =  ClassificationMetrics(num_classes=5)\n",
    "m.add(tensor([1]),tensor([2]))\n",
    "print(m.confusion_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1\n",
      "\n",
      "-- EPOCH 1/3 -------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb3d8c6318d648ce8baf74f023b72834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "////////////////////////////\n",
      "tensor(0.0709)\n",
      "tensor([[ 0., 19.,  0.,  1.,  0., 29.,  1., 20.,  1., 68.],\n",
      "        [ 0.,  1.,  0.,  0.,  0., 16.,  0.,  3.,  3., 38.],\n",
      "        [ 0.,  4.,  0.,  1.,  0., 14.,  0.,  5.,  1., 34.],\n",
      "        [ 0.,  5.,  0.,  0.,  0., 30.,  1., 14.,  5., 45.],\n",
      "        [ 0., 12.,  6.,  0.,  3., 21., 19., 70., 13., 93.],\n",
      "        [ 0.,  7.,  0.,  0.,  0., 38.,  0., 12.,  3., 68.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0., 20.,  1.,  3.,  1., 53.,  7., 28.,  7., 98.],\n",
      "        [ 0.,  5.,  0.,  0.,  0., 19.,  0.,  8.,  1., 26.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "////////////////////////////\n",
      "tensor(0.0725)\n",
      "tensor([[  0.,  32.,   0.,   2.,   0.,  68.,   1.,  36.,   6., 158.],\n",
      "        [  0.,   8.,   0.,   0.,   0.,  36.,   0.,   8.,   4.,  56.],\n",
      "        [  0.,  12.,   0.,   1.,   0.,  33.,   0.,  12.,   2.,  72.],\n",
      "        [  0.,  11.,   0.,   0.,   0.,  51.,   3.,  23.,   7.,  95.],\n",
      "        [  0.,  22.,  14.,   0.,   6.,  46.,  34., 126.,  19., 181.],\n",
      "        [  0.,  28.,   0.,   0.,   0.,  68.,   1.,  21.,   7., 142.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [  0.,  40.,   1.,   6.,   1.,  98.,  11.,  59.,  17., 190.],\n",
      "        [  0.,   7.,   0.,   0.,   0.,  36.,   0.,  12.,   4.,  67.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])\n",
      "////////////////////////////\n",
      "tensor(0.0756)\n",
      "tensor([[  0.,  50.,   0.,   3.,   1., 110.,   2.,  53.,  10., 237.],\n",
      "        [  0.,  12.,   0.,   0.,   0.,  57.,   0.,  13.,   6.,  94.],\n",
      "        [  0.,  16.,   0.,   1.,   0.,  53.,   0.,  17.,   5., 105.],\n",
      "        [  0.,  17.,   1.,   1.,   0.,  64.,   5.,  30.,   9., 140.],\n",
      "        [  0.,  34.,  16.,   2.,   8.,  71.,  40., 187.,  21., 272.],\n",
      "        [  0.,  40.,   0.,   0.,   0., 110.,   1.,  35.,  10., 221.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [  1.,  56.,   2.,   9.,   2., 132.,  17.,  90.,  30., 287.],\n",
      "        [  0.,   9.,   0.,   0.,   0.,  61.,   0.,  13.,   6., 106.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])\n",
      "////////////////////////////\n",
      "tensor(0.0712)\n",
      "tensor([[  0.,  70.,   0.,   4.,   1., 147.,   2.,  73.,  16., 319.],\n",
      "        [  0.,  15.,   0.,   0.,   0.,  71.,   0.,  19.,   8., 128.],\n",
      "        [  0.,  17.,   0.,   1.,   0.,  82.,   0.,  25.,   6., 133.],\n",
      "        [  0.,  26.,   1.,   1.,   0.,  96.,   8.,  38.,  12., 182.],\n",
      "        [  0.,  47.,  19.,   4.,  10., 104.,  55., 241.,  27., 379.],\n",
      "        [  0.,  51.,   0.,   0.,   0., 145.,   1.,  45.,  12., 279.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [  1.,  69.,   2.,  11.,   2., 181.,  19., 106.,  36., 388.],\n",
      "        [  0.,  13.,   0.,   0.,   0.,  81.,   0.,  18.,   8., 146.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])\n",
      "////////////////////////////\n",
      "tensor(0.0714)\n",
      "tensor([[  0.,  80.,   0.,   4.,   1., 189.,   2.,  87.,  22., 386.],\n",
      "        [  0.,  19.,   0.,   0.,   0.,  85.,   0.,  24.,  11., 174.],\n",
      "        [  0.,  22.,   0.,   1.,   0.,  96.,   0.,  27.,   8., 177.],\n",
      "        [  0.,  32.,   1.,   2.,   1., 110.,   9.,  43.,  13., 235.],\n",
      "        [  0.,  57.,  25.,   5.,  13., 127.,  66., 300.,  30., 474.],\n",
      "        [  0.,  61.,   0.,   0.,   0., 178.,   1.,  52.,  17., 365.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [  1.,  86.,   2.,  15.,   2., 237.,  21., 134.,  46., 489.],\n",
      "        [  0.,  18.,   0.,   0.,   0., 102.,   0.,  24.,  11., 181.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])\n",
      "////////////////////////////\n",
      "tensor(0.0732)\n",
      "tensor([[  0.,  88.,   0.,   4.,   1., 222.,   2., 100.,  26., 448.],\n",
      "        [  0.,  27.,   0.,   0.,   0., 101.,   1.,  30.,  15., 211.],\n",
      "        [  0.,  28.,   0.,   1.,   0., 111.,   0.,  38.,  12., 214.],\n",
      "        [  0.,  42.,   1.,   2.,   1., 127.,   9.,  48.,  18., 286.],\n",
      "        [  0.,  69.,  31.,   7.,  15., 159.,  76., 359.,  33., 570.],\n",
      "        [  0.,  75.,   0.,   0.,   0., 221.,   1.,  62.,  24., 454.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [  1., 100.,   2.,  17.,   3., 289.,  24., 162.,  51., 580.],\n",
      "        [  0.,  21.,   0.,   0.,   0., 115.,   0.,  27.,  12., 227.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])\n",
      "////////////////////////////\n",
      "tensor(0.0713)\n",
      "tensor([[  0.,  99.,   0.,   6.,   1., 263.,   3., 119.,  31., 518.],\n",
      "        [  0.,  31.,   0.,   0.,   0., 119.,   1.,  33.,  15., 241.],\n",
      "        [  0.,  35.,   0.,   1.,   0., 124.,   0.,  42.,  14., 254.],\n",
      "        [  0.,  47.,   1.,   2.,   1., 144.,  12.,  58.,  19., 330.],\n",
      "        [  0.,  81.,  40.,   9.,  18., 186.,  93., 418.,  38., 646.],\n",
      "        [  0.,  85.,   0.,   0.,   0., 255.,   2.,  75.,  30., 539.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [  1., 116.,   3.,  20.,   3., 351.,  26., 180.,  68., 682.],\n",
      "        [  0.,  26.,   0.,   0.,   0., 136.,   0.,  39.,  13., 258.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])\n",
      "////////////////////////////\n",
      "tensor(0.0711)\n",
      "tensor([[  0., 114.,   0.,   6.,   1., 300.,   3., 129.,  33., 595.],\n",
      "        [  0.,  37.,   0.,   0.,   0., 134.,   2.,  37.,  17., 281.],\n",
      "        [  0.,  40.,   0.,   1.,   0., 144.,   0.,  45.,  16., 289.],\n",
      "        [  0.,  52.,   1.,   2.,   1., 166.,  13.,  70.,  23., 377.],\n",
      "        [  0.,  94.,  44.,  11.,  20., 209., 110., 455.,  42., 755.],\n",
      "        [  0.,  97.,   0.,   0.,   0., 289.,   2.,  92.,  37., 618.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [  1., 139.,   3.,  22.,   4., 405.,  28., 207.,  76., 780.],\n",
      "        [  0.,  31.,   0.,   0.,   0., 155.,   0.,  43.,  14., 289.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])\n",
      "////////////////////////////\n",
      "tensor(0.0708)\n",
      "tensor([[  0., 131.,   0.,   7.,   1., 331.,   4., 145.,  35., 647.],\n",
      "        [  0.,  43.,   0.,   0.,   0., 152.,   2.,  41.,  21., 316.],\n",
      "        [  0.,  46.,   0.,   1.,   0., 161.,   0.,  49.,  21., 325.],\n",
      "        [  0.,  61.,   1.,   2.,   1., 185.,  14.,  85.,  27., 417.],\n",
      "        [  0., 104.,  51.,  12.,  21., 240., 125., 513.,  50., 863.],\n",
      "        [  0., 109.,   0.,   0.,   0., 324.,   2., 105.,  42., 707.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [  1., 161.,   3.,  24.,   4., 439.,  35., 229.,  80., 879.],\n",
      "        [  0.,  41.,   0.,   0.,   0., 165.,   0.,  50.,  18., 332.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])\n",
      "////////////////////////////\n",
      "tensor(0.0716)\n",
      "tensor([[  0., 150.,   0.,   9.,   1., 372.,   6., 164.,  42., 711.],\n",
      "        [  0.,  48.,   0.,   1.,   0., 170.,   2.,  48.,  22., 348.],\n",
      "        [  0.,  55.,   0.,   1.,   0., 173.,   0.,  50.,  25., 362.],\n",
      "        [  0.,  67.,   4.,   2.,   1., 199.,  17.,  92.,  32., 450.],\n",
      "        [  0., 120.,  57.,  12.,  22., 274., 140., 555.,  58., 942.],\n",
      "        [  0., 124.,   0.,   1.,   0., 368.,   2., 123.,  45., 786.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [  1., 181.,   4.,  28.,   6., 490.,  38., 255.,  88., 982.],\n",
      "        [  0.,  47.,   0.,   0.,   0., 180.,   0.,  57.,  21., 370.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])\n",
      "////////////////////////////\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 146\u001b[0m\n\u001b[1;32m    142\u001b[0m     count_val[preds] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m      \n\u001b[1;32m    143\u001b[0m     count_true_val[true_preds] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m      \n\u001b[0;32m--> 146\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# print(outputs, y, sep=\"\\n\")\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# print(preds, true_preds, sep=\"\\n\")\u001b[39;00m\n\u001b[1;32m    150\u001b[0m metric_tracker\u001b[38;5;241m.\u001b[39madd(torch\u001b[38;5;241m.\u001b[39mtensor([preds\u001b[38;5;241m.\u001b[39mto(int32)]), torch\u001b[38;5;241m.\u001b[39mtensor([true_preds\u001b[38;5;241m.\u001b[39mto(int32)]))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch import int32\n",
    "\n",
    "\n",
    "num_epochs = 3\n",
    "best_accuracy = 0\n",
    "early_stop_patience = 10\n",
    "lr_value = 0.001\n",
    "\n",
    "best_model = None\n",
    "\n",
    "num_runs = 1\n",
    "running_time = []\n",
    "\n",
    "metric_tracker = ClassificationMetrics(num_classes=len(list_activities))\n",
    "\n",
    "for run in range(num_runs):\n",
    "    \n",
    "    start = datetime.datetime.now()\n",
    "    print(\"Run: {}\".format(run + 1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = model.to(device)\n",
    "    #print(\"compiling...\")\n",
    "    #model = torch.compile(model, dynamic=True)\n",
    "    #print(\"Compiled model\")\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr_value) # momentum=0.9, weight_decay=1e-1)\n",
    "\n",
    "    \n",
    "    not_improved_count = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(\n",
    "            \"\\n-- EPOCH {}/{} -------------------------\\n\".format(epoch + 1, num_epochs)\n",
    "        )\n",
    "        torch.cuda.empty_cache()\n",
    "        count_train = [0 for _ in range(len(list_activities))]\n",
    "        count_true_train = [0 for _ in range(len(list_activities))]\n",
    "        count_val = [0 for _ in range(len(list_activities))]\n",
    "        count_true_val = [0 for _ in range(len(list_activities))]\n",
    "        for state in [\"train\", \"validation\"]:\n",
    "            if state == \"train\":\n",
    "                model.train()\n",
    "                metric_tracker.clear()\n",
    "                # true_label = []\n",
    "                # predictions = []\n",
    "                # scores = []\n",
    "\n",
    "            else:\n",
    "                \n",
    "                # print(metric_tracker.confusion_matrix())\n",
    "                #print(count_train)\n",
    "                #print(count_true_train)\n",
    "                \n",
    "                print(\"\\tTRAIN | acc: {:.4f} | mAcc: {:.4f} | mIoU: {:.4f}\".format(metric_tracker.acc(),\n",
    "                                                                                   #metric_tracker.mAcc(),\n",
    "                                                                                   #metric_tracker.mIoU()\n",
    "                                                                                   0,0))\n",
    "                \n",
    "                # y_true = np.concatenate(true_label)\n",
    "                # y_pred = np.concatenate(predictions)\n",
    "                # scores = np.concatenate(scores)\n",
    "                \n",
    "                # print(\"TRAIN\")\n",
    "                # print(conta(y_true, 0), conta(y_true, 1))\n",
    "                # print(conta(y_pred, 0), conta(y_pred, 1))\n",
    "                \n",
    "                # print_stats(y_pred, y_true, scores)\n",
    "                metric_tracker.clear()\n",
    "                model.eval()\n",
    "                # true_label = []\n",
    "                # predictions = []\n",
    "                # scores = []\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for i,(x,y) in tqdm(enumerate(loaders[state])):\n",
    "                \n",
    "                if i % 1000 == 1:\n",
    "                    print(metric_tracker.acc())\n",
    "                    # print(running_loss/i)\n",
    "                    print(metric_tracker.confusion_matrix())\n",
    "                    #print(count_train)\n",
    "                    #print(count_true_train)\n",
    "                    print(\"//\"*14)\n",
    "                # print(\"X\")\n",
    "                # print(\"//\"*50)\n",
    "                # print(x)\n",
    "                # print(\"//\"*50)\n",
    "                # print(y)\n",
    "                x = x[0].to(device)\n",
    "                # print(\"//\"*50)\n",
    "                #print(x)\n",
    "                #print(x.edge_index_dict)\n",
    "                #print(x.x_dict)\n",
    "                # print(\"//\"*50)\n",
    "                \n",
    "                y = y[0].to(device)\n",
    "                \n",
    "                #x = [[sub_item.to(device=device) for sub_item in item] for item in x]\n",
    "\n",
    "\n",
    "                #y = torch.tensor([torch.max(yi,0)[1] for yi in y])\n",
    "\n",
    "                #y = y.to(device)\n",
    "                \n",
    "                outputs = model(x.x_dict, x.edge_index_dict)\n",
    "                \n",
    "                # print(outputs)\n",
    "                # print(\"//\"*30)\n",
    "                \n",
    "                \n",
    "                # outputs = outputs.to(device)\n",
    "                \n",
    "                \n",
    "                \n",
    "                loss = criterion(outputs, y)\n",
    "\n",
    "                if state == \"train\":\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                _, preds = torch.max(outputs, 0)\n",
    "                \n",
    "                # print(y)\n",
    "                _, true_preds = torch.max(y, 0)                  \n",
    "                # print(true_preds)\n",
    "                preds = preds.to(device)\n",
    "                true_preds = true_preds.to(device)\n",
    "                if state == \"train\": # For now batch is set to one\n",
    "                    #for i in preds:\n",
    "                    count_train[preds] += 1\n",
    "                    count_true_train[true_preds] += 1\n",
    "                    \n",
    "                else:\n",
    "                    #for i in preds:\n",
    "                    count_val[preds] += 1      \n",
    "                    count_true_val[true_preds] += 1      \n",
    "                      \n",
    "                      \n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                # print(outputs, y, sep=\"\\n\")\n",
    "                # print(preds, true_preds, sep=\"\\n\")\n",
    "                metric_tracker.add(torch.tensor([preds.to(int32)]), torch.tensor([true_preds.to(int32)]))\n",
    "                # print(metric_tracker.confusion_matrix())\n",
    "                \n",
    "                \n",
    "        print(count_val)\n",
    "        print(\"\\tEVAL  | acc: {:.4f} | mAcc: {:.4f} | mIoU: {:.4f}\\n\".format(metric_tracker.acc(),\n",
    "                                                                             # metric_tracker.mAcc(),\n",
    "                                                                             # metric_tracker.mIoU()\n",
    "                                                                             # )\n",
    "                                                                            0,0)   )     \n",
    "                   \n",
    "\n",
    "        if epoch == 0:# HERE WE KEEP BEST AUC VALUE\n",
    "            best_accuracy = metric_tracker.acc()\n",
    "            \n",
    "        else:\n",
    "            if metric_tracker.acc() > best_accuracy:\n",
    "                print(\"SAVING MODEL..............\\n\")\n",
    "                best_accuracy = metric_tracker.acc()\n",
    "                not_improved_count = 0\n",
    "            else:\n",
    "                not_improved_count += 1\n",
    "\n",
    "        if not_improved_count == early_stop_patience:\n",
    "            print(\n",
    "                \"Validation performance didn't improve for {} epochs. \"\n",
    "                \"Training stops.\".format(early_stop_patience)\n",
    "            )\n",
    "            break\n",
    "\n",
    "    running_time.append((datetime.datetime.now() - start).total_seconds())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hgnn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
