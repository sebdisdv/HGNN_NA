{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sebdis/HGNN/HGNN_NA\n",
      "/home/sebdis/HGNN/HGNN_NA/data/datasets/original/\n",
      "/home/sebdis/HGNN/HGNN_NA/data/datasets/processed/\n",
      "/home/sebdis/HGNN/HGNN_NA/data/datasets/graphs/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from os.path import dirname\n",
    "\n",
    "\n",
    "\n",
    "root_path = dirname(os.getcwd()) + \"/HGNN_NA\"\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "data_dir = root_path + \"/data/datasets/original/\"\n",
    "data_dir_processed = root_path + \"/data/datasets/processed/\"\n",
    "data_dir_graphs = root_path + \"/data/datasets/graphs/\"\n",
    "\n",
    "print(root_path, data_dir, data_dir_processed, data_dir_graphs, sep=\"\\n\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"BPI_Challenge_2012_A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   org:resource lifecycle:transition           Activity       time:timestamp  \\\n",
      "0           112             COMPLETE        A_SUBMITTED  2011/09/30 22:38:44   \n",
      "1           112             COMPLETE  A_PARTLYSUBMITTED  2011/09/30 22:38:44   \n",
      "2           112             COMPLETE      A_PREACCEPTED  2011/09/30 22:39:37   \n",
      "3         10862             COMPLETE         A_ACCEPTED  2011/10/01 09:42:43   \n",
      "4         10862             COMPLETE        A_FINALIZED  2011/10/01 09:45:09   \n",
      "\n",
      "         case:REG_DATE  CaseID  case:AMOUNT_REQ  \n",
      "0  2011/10/01 00:38:44  173688            20000  \n",
      "1  2011/10/01 00:38:44  173688            20000  \n",
      "2  2011/10/01 00:38:44  173688            20000  \n",
      "3  2011/10/01 00:38:44  173688            20000  \n",
      "4  2011/10/01 00:38:44  173688            20000  \n"
     ]
    }
   ],
   "source": [
    "tab_all = pd.read_csv(data_dir_processed+dataset+\"_processed_all.csv\")\n",
    "print(tab_all.head())\n",
    "list_activities = list(tab_all[\"Activity\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_dir_graphs + dataset + \"_TRAIN.pkl\", \"rb\") as f:\n",
    "    X_train, Y_train = pickle.load(f)\n",
    "with open(data_dir_graphs + dataset + \"_VALID.pkl\", \"rb\") as f:\n",
    "    X_valid, Y_valid = pickle.load(f)\n",
    "with open(data_dir_graphs + dataset + \"_TEST.pkl\", \"rb\") as f:\n",
    "    X_test, Y_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Self\n",
    "from torch_geometric.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.transforms import ToUndirected, NormalizeFeatures\n",
    "\n",
    "transform = ToUndirected()\n",
    "t2 = NormalizeFeatures()\n",
    "\n",
    "class Het_graph_data(Dataset):\n",
    "    def __init__(self, prefix_graphs, labels) -> Self:\n",
    "        self.X = prefix_graphs\n",
    "        self.Y = labels\n",
    "\n",
    "    # get the number of rows in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "\n",
    "    # get a row at a particular index in the dataset\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "\n",
    "    @staticmethod\n",
    "    def collate(batch):\n",
    "        # print(batch)\n",
    "        data = [t2(transform(item[0])) for item in batch]\n",
    "        Y = [item[1] for item in batch]\n",
    "        return [data, Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    Het_graph_data(X_train, Y_train),\n",
    "    batch_size=256,\n",
    "    shuffle=True,\n",
    "    collate_fn=Het_graph_data.collate,\n",
    ")\n",
    "\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    Het_graph_data(X_valid, Y_valid),\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    collate_fn=Het_graph_data.collate,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    Het_graph_data(X_test, Y_test),\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    collate_fn=Het_graph_data.collate,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Class to keep track of the metrics of the classification process\n",
    "class ClassificationMetrics:\n",
    "\n",
    "  # Constructor takes the number of classes, in our case 20\n",
    "  def __init__(self, num_classes=20):\n",
    "    self.num_classes = num_classes\n",
    "    # Initialize a confusion matrix\n",
    "    self.C = torch.zeros(num_classes, num_classes)\n",
    "\n",
    "  # Update the confusion matrix with the new scores\n",
    "  def add(self, yp, yt):\n",
    "    # yp: 1D tensor with predictions\n",
    "    # yt: 1D tensor with ground-truth targets\n",
    "    yp = yp.to(\"cpu\")\n",
    "    yt = yt.to(\"cpu\")\n",
    "    with torch.no_grad(): # We require no computation graph\n",
    "      self.C+=(yt*self.C.shape[1]+yp).bincount(minlength=self.C.numel()).view(self.C.shape).float()\n",
    "\n",
    "  def clear(self):\n",
    "    # We set the confusion matrix to zero\n",
    "    self.C.zero_()\n",
    "\n",
    "  # Computes the global accuracy\n",
    "  def acc(self):\n",
    "    return self.C.diag().sum().item()/self.C.sum()\n",
    "\n",
    "  # Computes the class-averaged accuracy\n",
    "  def mAcc(self):\n",
    "    return (self.C.diag()/self.C.sum(-1)).mean().item()\n",
    "\n",
    "  # Computers the class-averaged Intersection over Union\n",
    "  def mIoU(self):\n",
    "    return (self.C.diag()/(self.C.sum(0)+self.C.sum(1)-self.C.diag())).mean().item()\n",
    "\n",
    "  # Returns the confusion matrix\n",
    "  def confusion_matrix(self):\n",
    "    return self.C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = {\"train\": train_loader, \"validation\" : valid_loader, \"test\" : test_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_types, edge_types = X_train[0].metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].x_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['org:resource',\n",
       " 'lifecycle:transition',\n",
       " 'Activity',\n",
       " 'time:timestamp',\n",
       " 'case:REG_DATE',\n",
       " 'case:AMOUNT_REQ']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('org:resource', 'related_to', 'org:resource'),\n",
       " ('Activity', 'followed_by', 'Activity'),\n",
       " ('time:timestamp', 'related_to', 'time:timestamp'),\n",
       " ('Activity', 'related_to', 'org:resource'),\n",
       " ('Activity', 'related_to', 'lifecycle:transition'),\n",
       " ('Activity', 'related_to', 'time:timestamp'),\n",
       " ('Activity', 'related_to', 'case:REG_DATE'),\n",
       " ('Activity', 'related_to', 'case:AMOUNT_REQ')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models.models import HGNN\n",
    "import datetime\n",
    "\n",
    "from torch import nn\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from typing_extensions import Self\n",
    "from torch_geometric.nn import SAGEConv, HeteroConv, GATConv # Linear, GCNConv\n",
    "from torch.nn import ModuleList, Module, Sequential, Softmax, Dropout, Linear, ReLU\n",
    "from torch import mean, stack, sum, concat\n",
    "\n",
    "\n",
    "class HGNN(Module):\n",
    "\n",
    "    def __init__(self, hid, out, layers, node_types, nodes_relations) -> Self:  # type: ignore\n",
    "        super().__init__()\n",
    "\n",
    "        # List of convolutional layers\n",
    "        self.convs = ModuleList()\n",
    "        for _ in range(layers):\n",
    "            conv = HeteroConv(\n",
    "                    {relation:SAGEConv((-1, -1), hid) for relation in nodes_relations}\n",
    "                    # {('Activity', 'followed_by', 'Activity') : SAGEConv((-1,-1), hid),\n",
    "                    #  (\"org:resource\", \"related_to\", 'org:resource') : SAGEConv((-1,-1), hid),\n",
    "                    #  ('time:timestamp', \"related_to\", \"time:timestamp\") : SAGEConv((-1,-1), hid)}\n",
    "                    ,\n",
    "                    aggr=\"mean\",\n",
    "                )\n",
    "            self.convs.append(conv)\n",
    "            \n",
    "        #print(nodes_relations)\n",
    "        # Take each node hid representation and apply a linear layer\n",
    "        # self.linear_nodes = Sequential(Linear(hid, hid),ReLU(), Dropout(p=0.5), Linear(hid, hid), ReLU(), Dropout(p=0.5), Linear(hid, int(hid / 2)), ReLU())\n",
    "\n",
    "        # Return the softmax with the class probabilities\n",
    "        # self.fc = Sequential(Linear(int(hid/2)*(len(node_types)), out), ReLU(), Softmax(dim=0))\n",
    "        self.fc = Sequential(Linear(hid*(len(node_types)), 64), ReLU(), Dropout(p=0.4), Linear(64, 64), ReLU(), nn.BatchNorm1d(64), Linear(64, out))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        outs = []\n",
    "        for i in range(len(x)):\n",
    "            for conv in self.convs:\n",
    "                \n",
    "                x[i] = conv(x[i], edge_index[i])\n",
    "                \n",
    "                x[i] = {key: x.relu() for key, x in x[i].items()}\n",
    "\n",
    "        \n",
    "            # Node features of each node in the graph\n",
    "            nodes_features = [\n",
    "                x[i][key] for key in x[i].keys()\n",
    "            ]\n",
    "        \n",
    "            # Global mean of each node type\n",
    "            for i in range(len(nodes_features)):\n",
    "                nodes_features[i] = mean(nodes_features[i], dim=0)\n",
    "\n",
    "        \n",
    "            # Global mean pooling\n",
    "            #nodes_features = mean(stack(nodes_features), dim=0)\n",
    "            nodes_features = concat(nodes_features)\n",
    "            outs.append(nodes_features)\n",
    "        \n",
    "        out = self.fc(stack(outs))\n",
    "        \n",
    "\n",
    "        return out  # {key : self.linear(x_dict[key]) for key in x_dict.keys()}, nodes_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "org:resource, related_to, org:resource)={\n",
    "    edge_attr=[1, 1],\n",
    "    edge_index=[2, 1],\n",
    "  },\n",
    "  (Activity, followed_by, Activity)={\n",
    "    edge_attr=[1, 1],\n",
    "    edge_index=[2, 1],\n",
    "  },\n",
    "  (time:timestamp, related_to, time:timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HGNN(\n",
       "  (convs): ModuleList(\n",
       "    (0-1): 2 x HeteroConv(num_relations=8)\n",
       "  )\n",
       "  (linear_nodes): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (1): Dropout(p=0.3, inplace=False)\n",
       "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=96, out_features=10, bias=True)\n",
       "    (1): Softmax(dim=0)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = HGNN(hid=128, out=len(list_activities), layers=4, node_types=node_types, nodes_relations=edge_types)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].x_dict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].edge_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.transforms import ToUndirected\n",
    "\n",
    "X_train[0] = ToUndirected()(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].x_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].edge_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].is_directed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    print(model(X_train[0].x_dict,X_train[0].edge_index_dict))\n",
    "    print(Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_t = {}\n",
    "for i,(x,y) in enumerate(loaders['test']):\n",
    "    _,pr = torch.max(y[0], dim=0)\n",
    "    try:\n",
    "        k_t[pr.item()] += 1\n",
    "    except KeyError:\n",
    "        k_t[pr.item()] = 1\n",
    "k_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_t = []\n",
    "for i,(x,y) in enumerate(loaders['validation']):\n",
    "    k_t.append(\"__\".join(list(x[0].x_dict.keys())))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_t[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_t_s = set(k_t)\n",
    "k_t_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 3., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "from torch import tensor\n",
    "m  =  ClassificationMetrics(num_classes=5)\n",
    "m.add(tensor([1,1,1]),tensor([2,2,2]))\n",
    "print(m.confusion_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('Activity', 'followed_by', 'Activity'): tensor([[0, 1],\n",
      "        [1, 0]]), ('time:timestamp', 'related_to', 'time:timestamp'): tensor([[0, 1],\n",
      "        [1, 0]]), ('Activity', 'related_to', 'org:resource'): tensor([[0, 1],\n",
      "        [0, 0]]), ('Activity', 'related_to', 'lifecycle:transition'): tensor([[0, 1],\n",
      "        [0, 0]]), ('Activity', 'related_to', 'time:timestamp'): tensor([[0, 1],\n",
      "        [0, 1]]), ('Activity', 'related_to', 'case:REG_DATE'): tensor([[0, 1],\n",
      "        [0, 0]]), ('Activity', 'related_to', 'case:AMOUNT_REQ'): tensor([[0, 1],\n",
      "        [0, 0]]), ('org:resource', 'rev_related_to', 'Activity'): tensor([[0, 0],\n",
      "        [0, 1]]), ('lifecycle:transition', 'rev_related_to', 'Activity'): tensor([[0, 0],\n",
      "        [0, 1]]), ('time:timestamp', 'rev_related_to', 'Activity'): tensor([[0, 1],\n",
      "        [0, 1]]), ('case:REG_DATE', 'rev_related_to', 'Activity'): tensor([[0, 0],\n",
      "        [0, 1]]), ('case:AMOUNT_REQ', 'rev_related_to', 'Activity'): tensor([[0, 0],\n",
      "        [0, 1]])}\n"
     ]
    }
   ],
   "source": [
    "for i,(x,y) in enumerate(valid_loader):\n",
    "    print(x[0].edge_index_dict)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1\n",
      "\n",
      "-- EPOCH 1/10 -------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53ff353d8a24efaa37195063a1221aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(nan)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "////////////////////////////\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_905/572328102.py:159: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  metric_tracker.add(torch.tensor(preds.to(int32)), torch.tensor(true_preds.to(int32)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0977)\n",
      "tensor([[ 2.,  7.,  5.,  7.,  3.,  2.,  0.,  1.,  7.,  5.],\n",
      "        [ 1.,  1.,  1.,  3.,  1.,  1.,  1.,  0.,  3.,  1.],\n",
      "        [ 3.,  0.,  1.,  3.,  3.,  1.,  1.,  1.,  4.,  1.],\n",
      "        [ 4.,  2.,  2.,  4.,  3.,  3.,  0.,  1.,  1.,  2.],\n",
      "        [ 3.,  7.,  4.,  5.,  9.,  2.,  2.,  8., 11.,  6.],\n",
      "        [ 3.,  7.,  3.,  6.,  3.,  3.,  6.,  1.,  7.,  2.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 6.,  9.,  6.,  3.,  5.,  3.,  2.,  4.,  6.,  7.],\n",
      "        [ 0.,  5.,  1.,  3.,  0.,  1.,  1.,  2.,  1.,  1.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "////////////////////////////\n",
      "tensor(0.1426)\n",
      "tensor([[ 5., 12.,  5.,  7., 18., 11.,  2.,  2.,  8.,  9.],\n",
      "        [ 3.,  1.,  1.,  3.,  8.,  7.,  1.,  2.,  5.,  3.],\n",
      "        [ 6.,  1.,  2.,  3.,  8.,  3.,  1.,  1.,  4.,  3.],\n",
      "        [11.,  3.,  2.,  4.,  7.,  6.,  0.,  4.,  2.,  2.],\n",
      "        [10.,  8.,  6.,  9., 41.,  8.,  2., 14., 12., 10.],\n",
      "        [11.,  9.,  7.,  6., 14.,  8.,  6.,  1.,  7.,  9.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [11., 14.,  6.,  3., 17.,  8.,  2.,  9., 10., 10.],\n",
      "        [ 3.,  5.,  1.,  3.,  6.,  7.,  1.,  5.,  3.,  4.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "////////////////////////////\n",
      "tensor(0.1771)\n",
      "tensor([[13., 12.,  5., 15., 19., 19.,  2., 16., 11.,  9.],\n",
      "        [ 4.,  1.,  1.,  4.,  9., 14.,  1., 12.,  8.,  3.],\n",
      "        [12.,  1.,  2.,  5.,  9.,  4.,  1.,  4.,  5.,  3.],\n",
      "        [12.,  3.,  2.,  6., 10., 10.,  0., 11.,  4.,  2.],\n",
      "        [24.,  8.,  6., 14., 71., 16.,  2., 20., 12., 10.],\n",
      "        [22., 10.,  7.,  7., 17., 15.,  6.,  9., 11.,  9.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [18., 14.,  7.,  7., 18., 21.,  2., 25., 15., 10.],\n",
      "        [ 8.,  5.,  1.,  3.,  6., 10.,  1., 10.,  3.,  4.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "////////////////////////////\n",
      "tensor(0.1807)\n",
      "tensor([[22., 12.,  6., 15., 31., 25.,  2., 27., 11.,  9.],\n",
      "        [ 8.,  1.,  1.,  4., 11., 18.,  1., 13.,  8.,  3.],\n",
      "        [19.,  1.,  2.,  5., 14.,  5.,  1., 11.,  5.,  3.],\n",
      "        [14.,  3.,  2.,  6., 15., 12.,  0., 20.,  4.,  2.],\n",
      "        [42., 10.,  6., 14., 97., 20.,  2., 31., 12., 10.],\n",
      "        [30., 12.,  7.,  8., 24., 20.,  6., 21., 11.,  9.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [33., 15.,  7., 10., 35., 32.,  2., 34., 15., 10.],\n",
      "        [13.,  5.,  1.,  3.,  8., 13.,  1., 16.,  3.,  4.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "////////////////////////////\n",
      "tensor(0.1852)\n",
      "tensor([[ 22.,  12.,   6.,  15.,  55.,  25.,   2.,  32.,  11.,   9.],\n",
      "        [  8.,   1.,   1.,   4.,  27.,  18.,   1.,  16.,   8.,   3.],\n",
      "        [ 19.,   1.,   2.,   5.,  25.,   5.,   1.,  15.,   5.,   3.],\n",
      "        [ 14.,   3.,   2.,   6.,  34.,  12.,   0.,  23.,   4.,   2.],\n",
      "        [ 43.,  15.,   6.,  14., 143.,  20.,   2.,  36.,  12.,  10.],\n",
      "        [ 30.,  12.,   7.,   8.,  56.,  20.,   6.,  29.,  11.,   9.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [ 33.,  16.,   7.,  10.,  80.,  32.,   2.,  40.,  15.,  10.],\n",
      "        [ 13.,   5.,   1.,   3.,  24.,  13.,   1.,  22.,   3.,   4.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])\n",
      "////////////////////////////\n",
      "tensor(0.1992)\n",
      "tensor([[ 22.,  12.,   6.,  15.,  55.,  25.,   2.,  63.,  11.,   9.],\n",
      "        [  8.,   1.,   1.,   4.,  27.,  18.,   1.,  29.,   8.,   3.],\n",
      "        [ 19.,   1.,   2.,   5.,  25.,   5.,   1.,  29.,   5.,   3.],\n",
      "        [ 14.,   3.,   2.,   6.,  34.,  12.,   0.,  41.,   4.,   2.],\n",
      "        [ 43.,  15.,   6.,  14., 150.,  21.,   2.,  88.,  12.,  10.],\n",
      "        [ 30.,  12.,   7.,   8.,  56.,  20.,   6.,  70.,  11.,   9.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [ 33.,  16.,   7.,  10.,  80.,  32.,   2., 102.,  15.,  10.],\n",
      "        [ 13.,   5.,   1.,   3.,  24.,  13.,   1.,  39.,   3.,   4.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])\n",
      "////////////////////////////\n",
      "tensor(0.2009)\n",
      "tensor([[ 22.,  12.,   6.,  15.,  55.,  25.,   2.,  92.,  11.,   9.],\n",
      "        [  8.,   1.,   1.,   4.,  27.,  18.,   1.,  41.,   8.,   3.],\n",
      "        [ 19.,   1.,   2.,   5.,  25.,   5.,   1.,  58.,   5.,   3.],\n",
      "        [ 14.,   3.,   2.,   6.,  34.,  12.,   0.,  56.,   4.,   2.],\n",
      "        [ 43.,  15.,   6.,  16., 150.,  21.,   2., 140.,  12.,  10.],\n",
      "        [ 30.,  12.,   7.,   8.,  56.,  20.,   6., 111.,  11.,   9.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [ 33.,  16.,   7.,  10.,  80.,  32.,   2., 156.,  15.,  10.],\n",
      "        [ 13.,   5.,   1.,   3.,  24.,  13.,   1.,  61.,   3.,   4.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])\n",
      "////////////////////////////\n",
      "tensor(0.1890)\n",
      "tensor([[ 22.,  12.,   6.,  15.,  55.,  66.,   2.,  92.,  11.,   9.],\n",
      "        [  8.,   1.,   1.,   4.,  28.,  38.,   1.,  41.,   8.,   3.],\n",
      "        [ 19.,   1.,   2.,   5.,  25.,  25.,   1.,  58.,   5.,   3.],\n",
      "        [ 14.,   3.,   2.,   6.,  34.,  27.,   0.,  56.,   4.,   2.],\n",
      "        [ 43.,  15.,   6.,  16., 150.,  80.,   2., 140.,  12.,  10.],\n",
      "        [ 30.,  12.,   7.,   8.,  57.,  47.,   6., 111.,  11.,   9.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [ 33.,  16.,   7.,  10.,  81.,  83.,   2., 156.,  15.,  10.],\n",
      "        [ 13.,   5.,   1.,   3.,  24.,  33.,   1.,  61.,   3.,   4.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])\n",
      "////////////////////////////\n",
      "tensor(0.1931)\n",
      "tensor([[ 22.,  12.,   6.,  15.,  89.,  66.,   2.,  92.,  11.,   9.],\n",
      "        [  8.,   1.,   1.,   4.,  50.,  38.,   1.,  41.,   8.,   3.],\n",
      "        [ 19.,   1.,   2.,   5.,  37.,  25.,   1.,  58.,   5.,   3.],\n",
      "        [ 14.,   3.,   2.,   6.,  61.,  27.,   0.,  56.,   4.,   2.],\n",
      "        [ 43.,  15.,   6.,  16., 208.,  80.,   2., 140.,  12.,  10.],\n",
      "        [ 30.,  12.,   7.,   8.,  90.,  47.,   6., 111.,  11.,   9.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [ 33.,  16.,   7.,  10., 136.,  83.,   2., 156.,  15.,  10.],\n",
      "        [ 13.,   5.,   1.,   3.,  39.,  33.,   1.,  61.,   3.,   4.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])\n",
      "////////////////////////////\n",
      "tensor(0.1988)\n",
      "tensor([[ 22.,  12.,   6.,  15., 127.,  66.,   2.,  92.,  11.,   9.],\n",
      "        [  8.,   1.,   1.,   4.,  67.,  38.,   1.,  41.,   8.,   3.],\n",
      "        [ 19.,   1.,   2.,   5.,  52.,  25.,   1.,  58.,   5.,   3.],\n",
      "        [ 14.,   3.,   2.,   6.,  83.,  28.,   0.,  56.,   4.,   2.],\n",
      "        [ 43.,  15.,   6.,  16., 272.,  80.,   2., 141.,  12.,  10.],\n",
      "        [ 30.,  12.,   7.,   8., 122.,  47.,   6., 111.,  11.,   9.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [ 33.,  16.,   7.,  10., 186.,  83.,   2., 156.,  15.,  10.],\n",
      "        [ 13.,   5.,   1.,   3.,  55.,  33.,   1.,  61.,   3.,   4.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])\n",
      "////////////////////////////\n",
      "tensor(0.2024)\n",
      "tensor([[ 22.,  12.,   6.,  15., 163.,  66.,   2.,  92.,  11.,   9.],\n",
      "        [  8.,   1.,   1.,   4.,  83.,  38.,   1.,  41.,   8.,   3.],\n",
      "        [ 19.,   1.,   2.,   5.,  61.,  25.,   1.,  58.,   5.,   3.],\n",
      "        [ 14.,   3.,   2.,   6., 107.,  28.,   0.,  56.,   4.,   2.],\n",
      "        [ 43.,  15.,   6.,  16., 333.,  80.,   2., 141.,  12.,  10.],\n",
      "        [ 30.,  12.,   7.,   8., 162.,  47.,   6., 111.,  11.,   9.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [ 33.,  16.,   7.,  10., 236.,  83.,   2., 156.,  15.,  10.],\n",
      "        [ 13.,   5.,   1.,   3.,  74.,  34.,   1.,  61.,   3.,   4.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])\n",
      "////////////////////////////\n",
      "tensor(0.2044)\n",
      "tensor([[ 22.,  12.,   6.,  15., 194.,  66.,   2.,  92.,  11.,   9.],\n",
      "        [  8.,   1.,   1.,   4., 101.,  38.,   1.,  41.,   8.,   3.],\n",
      "        [ 19.,   1.,   2.,   5.,  75.,  25.,   1.,  58.,   5.,   3.],\n",
      "        [ 14.,   3.,   2.,   6., 130.,  28.,   0.,  56.,   4.,   2.],\n",
      "        [ 43.,  15.,   6.,  16., 391.,  80.,   2., 141.,  12.,  10.],\n",
      "        [ 30.,  12.,   7.,   8., 196.,  47.,   6., 111.,  11.,   9.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [ 33.,  16.,   7.,  10., 288.,  83.,   2., 156.,  15.,  10.],\n",
      "        [ 13.,   5.,   1.,   3., 100.,  34.,   1.,  61.,   3.,   4.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])\n",
      "////////////////////////////\n",
      "tensor(0.1995)\n",
      "tensor([[ 22.,  12.,   6.,  15., 195.,  92.,   2.,  92.,  11.,   9.],\n",
      "        [  8.,   1.,   1.,   4., 101.,  56.,   1.,  41.,   8.,   3.],\n",
      "        [ 19.,   1.,   2.,   5.,  75.,  42.,   1.,  58.,   5.,   3.],\n",
      "        [ 14.,   3.,   2.,   6., 130.,  47.,   0.,  56.,   4.,   2.],\n",
      "        [ 43.,  15.,   6.,  16., 392., 142.,   2., 141.,  12.,  10.],\n",
      "        [ 30.,  12.,   7.,   8., 196.,  82.,   6., 111.,  11.,   9.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [ 33.,  16.,   7.,  10., 289., 146.,   2., 156.,  15.,  10.],\n",
      "        [ 13.,   5.,   1.,   3., 100.,  47.,   1.,  61.,   3.,   4.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])\n",
      "////////////////////////////\n",
      "tensor(0.2015)\n",
      "tensor([[ 22.,  12.,   6.,  15., 195.,  92.,   2., 126.,  11.,   9.],\n",
      "        [  8.,   1.,   1.,   4., 101.,  56.,   1.,  63.,   8.,   3.],\n",
      "        [ 19.,   1.,   2.,   5.,  75.,  42.,   1.,  70.,   5.,   3.],\n",
      "        [ 14.,   3.,   2.,   6., 130.,  47.,   0.,  78.,   4.,   2.],\n",
      "        [ 43.,  15.,   6.,  16., 392., 142.,   2., 205.,  12.,  10.],\n",
      "        [ 30.,  12.,   7.,   8., 196.,  82.,   6., 143.,  11.,   9.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [ 33.,  16.,   7.,  10., 289., 146.,   2., 214.,  15.,  10.],\n",
      "        [ 13.,   5.,   1.,   3., 100.,  47.,   1.,  73.,   3.,   4.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])\n",
      "////////////////////////////\n",
      "tensor(0.2029)\n",
      "tensor([[ 22.,  12.,   6.,  15., 195.,  92.,   2., 161.,  11.,   9.],\n",
      "        [  8.,   1.,   1.,   4., 101.,  56.,   1.,  87.,   8.,   3.],\n",
      "        [ 19.,   1.,   2.,   5.,  75.,  42.,   1.,  83.,   5.,   3.],\n",
      "        [ 14.,   3.,   2.,   6., 130.,  47.,   0.,  97.,   4.,   2.],\n",
      "        [ 43.,  15.,   6.,  16., 392., 142.,   2., 263.,  12.,  10.],\n",
      "        [ 30.,  12.,   7.,   8., 196.,  82.,   6., 176.,  11.,   9.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [ 33.,  16.,   7.,  10., 289., 146.,   2., 271.,  15.,  10.],\n",
      "        [ 13.,   5.,   1.,   3., 100.,  47.,   1.,  90.,   3.,   4.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])\n",
      "////////////////////////////\n",
      "tensor(0.2000)\n",
      "tensor([[ 22.,  12.,   6.,  15., 195.,  92.,   2., 194.,  11.,   9.],\n",
      "        [  8.,   1.,   1.,   4., 101.,  56.,   1., 109.,   8.,   3.],\n",
      "        [ 19.,   1.,   2.,   5.,  75.,  42.,   1., 110.,   5.,   3.],\n",
      "        [ 14.,   3.,   2.,   6., 130.,  47.,   0., 115.,   4.,   2.],\n",
      "        [ 43.,  15.,   6.,  16., 392., 142.,   2., 321.,  12.,  10.],\n",
      "        [ 30.,  12.,   7.,   8., 196.,  82.,   6., 220.,  11.,   9.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [ 33.,  16.,   7.,  10., 289., 146.,   2., 311.,  15.,  10.],\n",
      "        [ 13.,   5.,   1.,   3., 100.,  47.,   1., 104.,   3.,   4.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])\n",
      "////////////////////////////\n",
      "tensor(0.2015)\n",
      "tensor([[ 22.,  12.,   6.,  15., 225.,  92.,   2., 194.,  11.,   9.],\n",
      "        [  8.,   1.,   1.,   4., 120.,  56.,   1., 109.,   8.,   3.],\n",
      "        [ 19.,   1.,   2.,   5.,  97.,  42.,   1., 110.,   5.,   3.],\n",
      "        [ 14.,   3.,   2.,   6., 147.,  47.,   0., 115.,   4.,   2.],\n",
      "        [ 43.,  15.,   6.,  16., 450., 142.,   2., 321.,  12.,  10.],\n",
      "        [ 30.,  12.,   7.,   8., 228.,  82.,   6., 220.,  11.,   9.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [ 33.,  16.,   7.,  10., 342., 146.,   2., 311.,  15.,  10.],\n",
      "        [ 13.,   5.,   1.,   3., 125.,  47.,   1., 104.,   3.,   4.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])\n",
      "////////////////////////////\n",
      "tensor(0.2033)\n",
      "tensor([[ 22.,  12.,   6.,  15., 262.,  92.,   2., 194.,  11.,   9.],\n",
      "        [  8.,   1.,   1.,   4., 128.,  56.,   1., 109.,   8.,   3.],\n",
      "        [ 19.,   1.,   2.,   5., 116.,  42.,   1., 110.,   5.,   3.],\n",
      "        [ 14.,   3.,   2.,   6., 166.,  47.,   0., 115.,   4.,   2.],\n",
      "        [ 43.,  15.,   6.,  16., 510., 142.,   2., 321.,  12.,  10.],\n",
      "        [ 30.,  12.,   7.,   8., 269.,  82.,   6., 220.,  11.,   9.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [ 33.,  16.,   7.,  10., 394., 146.,   2., 311.,  15.,  10.],\n",
      "        [ 13.,   5.,   1.,   3., 145.,  47.,   1., 104.,   3.,   4.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])\n",
      "////////////////////////////\n",
      "tensor(0.2035)\n",
      "tensor([[ 22.,  12.,   6.,  15., 297.,  92.,   2., 194.,  11.,   9.],\n",
      "        [  8.,   1.,   1.,   4., 153.,  56.,   1., 109.,   8.,   3.],\n",
      "        [ 19.,   1.,   2.,   5., 134.,  42.,   1., 110.,   5.,   3.],\n",
      "        [ 14.,   3.,   2.,   6., 183.,  47.,   0., 115.,   4.,   2.],\n",
      "        [ 43.,  15.,   6.,  16., 563., 142.,   2., 321.,  12.,  10.],\n",
      "        [ 30.,  12.,   7.,   8., 315.,  82.,   6., 220.,  11.,   9.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [ 33.,  16.,   7.,  10., 438., 146.,   2., 311.,  15.,  10.],\n",
      "        [ 13.,   5.,   1.,   3., 163.,  47.,   1., 104.,   3.,   4.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])\n",
      "////////////////////////////\n",
      "tensor(0.2045)\n",
      "tensor([[ 22.,  12.,   6.,  15., 330.,  92.,   2., 194.,  11.,   9.],\n",
      "        [  8.,   1.,   1.,   4., 164.,  56.,   1., 109.,   8.,   3.],\n",
      "        [ 19.,   1.,   2.,   5., 150.,  42.,   1., 110.,   5.,   3.],\n",
      "        [ 14.,   3.,   2.,   6., 207.,  47.,   0., 115.,   4.,   2.],\n",
      "        [ 43.,  15.,   6.,  16., 620., 142.,   2., 321.,  12.,  10.],\n",
      "        [ 30.,  12.,   7.,   8., 357.,  82.,   6., 220.,  11.,   9.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [ 33.,  16.,   7.,  10., 499., 146.,   2., 311.,  15.,  10.],\n",
      "        [ 13.,   5.,   1.,   3., 175.,  47.,   1., 104.,   3.,   4.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])\n",
      "////////////////////////////\n",
      "tensor(0.2046)\n",
      "tensor([[ 22.,  12.,   6.,  15., 330.,  92.,   2., 232.,  11.,   9.],\n",
      "        [  8.,   1.,   1.,   4., 164.,  56.,   1., 125.,   8.,   3.],\n",
      "        [ 19.,   1.,   2.,   5., 150.,  42.,   1., 126.,   5.,   3.],\n",
      "        [ 14.,   3.,   2.,   6., 207.,  47.,   0., 136.,   4.,   2.],\n",
      "        [ 43.,  15.,   6.,  16., 620., 142.,   2., 376.,  12.,  10.],\n",
      "        [ 30.,  12.,   7.,   8., 357.,  82.,   6., 262.,  11.,   9.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [ 33.,  16.,   7.,  10., 499., 146.,   2., 364.,  15.,  10.],\n",
      "        [ 13.,   5.,   1.,   3., 175.,  47.,   1., 119.,   3.,   4.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])\n",
      "////////////////////////////\n",
      "tensor(0.2029)\n",
      "tensor([[ 22.,  12.,   6.,  15., 330.,  92.,   2., 271.,  11.,   9.],\n",
      "        [  8.,   1.,   1.,   4., 164.,  56.,   1., 137.,   8.,   3.],\n",
      "        [ 19.,   1.,   2.,   5., 150.,  42.,   1., 146.,   5.,   3.],\n",
      "        [ 14.,   3.,   2.,   6., 207.,  47.,   0., 163.,   4.,   2.],\n",
      "        [ 43.,  15.,   6.,  16., 620., 142.,   2., 430.,  12.,  10.],\n",
      "        [ 30.,  12.,   7.,   8., 357.,  82.,   6., 298.,  11.,   9.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [ 33.,  16.,   7.,  10., 499., 146.,   2., 407.,  15.,  10.],\n",
      "        [ 13.,   5.,   1.,   3., 175.,  47.,   1., 144.,   3.,   4.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])\n",
      "////////////////////////////\n",
      "tensor(0.2028)\n",
      "tensor([[ 22.,  12.,   6.,  15., 366.,  92.,   2., 271.,  11.,   9.],\n",
      "        [  8.,   1.,   1.,   4., 178.,  56.,   1., 137.,   8.,   3.],\n",
      "        [ 19.,   1.,   2.,   5., 170.,  42.,   1., 146.,   5.,   3.],\n",
      "        [ 14.,   3.,   2.,   6., 225.,  47.,   0., 163.,   4.,   2.],\n",
      "        [ 43.,  15.,   6.,  16., 671., 142.,   2., 430.,  12.,  10.],\n",
      "        [ 30.,  12.,   7.,   8., 392.,  82.,   6., 298.,  11.,   9.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [ 33.,  16.,   7.,  10., 565., 146.,   2., 407.,  15.,  10.],\n",
      "        [ 13.,   5.,   1.,   3., 191.,  47.,   1., 144.,   3.,   4.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])\n",
      "////////////////////////////\n",
      "tensor(0.2033)\n",
      "tensor([[ 22.,  12.,   6.,  15., 400.,  92.,   2., 271.,  11.,   9.],\n",
      "        [  8.,   1.,   1.,   4., 204.,  56.,   1., 137.,   8.,   3.],\n",
      "        [ 19.,   1.,   2.,   5., 190.,  42.,   1., 146.,   5.,   3.],\n",
      "        [ 14.,   3.,   2.,   6., 243.,  47.,   0., 163.,   4.,   2.],\n",
      "        [ 43.,  15.,   6.,  16., 726., 142.,   2., 430.,  12.,  10.],\n",
      "        [ 30.,  12.,   7.,   8., 433.,  82.,   6., 298.,  11.,   9.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [ 33.,  16.,   7.,  10., 608., 146.,   2., 407.,  15.,  10.],\n",
      "        [ 13.,   5.,   1.,   3., 210.,  47.,   1., 144.,   3.,   4.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.]])\n",
      "////////////////////////////\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 117\u001b[0m\n\u001b[1;32m    108\u001b[0m y \u001b[38;5;241m=\u001b[39m stack(y)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m#x = [[sub_item.to(device=device) for sub_item in item] for item in x]\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \n\u001b[1;32m    112\u001b[0m \n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m#y = torch.tensor([torch.max(yi,0)[1] for yi in y])\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m#y = y.to(device)\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_edge_index_dicts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# print(outputs)\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# print(\"//\"*30)\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m#print(outputs)\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m#print(y)\u001b[39;00m\n\u001b[1;32m    128\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, y)\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[83], line 39\u001b[0m, in \u001b[0;36mHGNN.forward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(x)):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs:\n\u001b[0;32m---> 39\u001b[0m         x[i] \u001b[38;5;241m=\u001b[39m \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m         x[i] \u001b[38;5;241m=\u001b[39m {key: x\u001b[38;5;241m.\u001b[39mrelu() \u001b[38;5;28;01mfor\u001b[39;00m key, x \u001b[38;5;129;01min\u001b[39;00m x[i]\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# Node features of each node in the graph\u001b[39;00m\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch_geometric/nn/conv/hetero_conv.py:158\u001b[0m, in \u001b[0;36mHeteroConv.forward\u001b[0;34m(self, *args_dict, **kwargs_dict)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_edge_level_arg:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dst \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m out_dict:\n\u001b[1;32m    161\u001b[0m     out_dict[dst] \u001b[38;5;241m=\u001b[39m [out]\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch_geometric/nn/conv/sage_conv.py:134\u001b[0m, in \u001b[0;36mSAGEConv.forward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m    131\u001b[0m     x \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mrelu(), x[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor)\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_l(out)\n\u001b[1;32m    137\u001b[0m x_r \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/tmp/torch_geometric.nn.conv.sage_conv_SAGEConv_propagate_zh42mf_1.py:229\u001b[0m, in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, x, size)\u001b[0m\n\u001b[1;32m    221\u001b[0m             kwargs \u001b[38;5;241m=\u001b[39m CollectArgs(\n\u001b[1;32m    222\u001b[0m                 x_j\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mx_j,\n\u001b[1;32m    223\u001b[0m                 index\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    224\u001b[0m                 ptr\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mptr\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    225\u001b[0m                 dim_size\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdim_size\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    226\u001b[0m             )\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# End Aggregate Forward Pre Hook #######################################\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43mptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m# Begin Aggregate Forward Hook #########################################\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:594\u001b[0m, in \u001b[0;36mMessagePassing.aggregate\u001b[0;34m(self, inputs, index, ptr, dim_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maggregate\u001b[39m(\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    579\u001b[0m     inputs: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m     dim_size: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    583\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    584\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Aggregates messages from neighbors as\u001b[39;00m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;124;03m    :math:`\\bigoplus_{j \\in \\mathcal{N}(i)}`.\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;124;03m    as specified in :meth:`__init__` by the :obj:`aggr` argument.\u001b[39;00m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 594\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggr_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch_geometric/experimental.py:117\u001b[0m, in \u001b[0;36mdisable_dynamic_shapes.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_experimental_mode_enabled(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisable_dynamic_shapes\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m required_arg \u001b[38;5;129;01min\u001b[39;00m required_args:\n\u001b[1;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m required_args_pos[required_arg]\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch_geometric/nn/aggr/base.py:131\u001b[0m, in \u001b[0;36mAggregation.__call__\u001b[0;34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m     dim_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(index\u001b[38;5;241m.\u001b[39mmax()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch_geometric/nn/aggr/basic.py:36\u001b[0m, in \u001b[0;36mMeanAggregation.forward\u001b[0;34m(self, x, index, ptr, dim_size, dim)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor, index: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     34\u001b[0m             ptr: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, dim_size: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     35\u001b[0m             dim: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch_geometric/nn/aggr/base.py:185\u001b[0m, in \u001b[0;36mAggregation.reduce\u001b[0;34m(self, x, index, ptr, dim_size, dim, reduce)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAggregation requires \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to be specified\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/HGNN/hgnn_env/lib/python3.10/site-packages/torch_geometric/utils/_scatter.py:79\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     78\u001b[0m     count \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mnew_zeros(dim_size)\n\u001b[0;32m---> 79\u001b[0m     \u001b[43mcount\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter_add_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_ones\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     count \u001b[38;5;241m=\u001b[39m count\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     82\u001b[0m     index \u001b[38;5;241m=\u001b[39m broadcast(index, src, dim)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch import int32\n",
    "\n",
    "model = HGNN(hid=128, out=len(list_activities), layers=8, node_types=node_types, nodes_relations=edge_types)\n",
    "\n",
    "\n",
    "num_epochs = 10\n",
    "best_accuracy = 0\n",
    "early_stop_patience = 10\n",
    "lr_value = 0.1\n",
    "\n",
    "best_model = None\n",
    "\n",
    "num_runs = 1\n",
    "running_time = []\n",
    "\n",
    "metric_tracker = ClassificationMetrics(num_classes=len(list_activities))\n",
    "\n",
    "for run in range(num_runs):\n",
    "    \n",
    "    start = datetime.datetime.now()\n",
    "    print(\"Run: {}\".format(run + 1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    #print(\"compiling...\")\n",
    "    #model = torch.compile(model, dynamic=True)\n",
    "    #print(\"Compiled model\")\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr_value) # momentum=0.9, weight_decay=1e-1)\n",
    "\n",
    "    \n",
    "    not_improved_count = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(\n",
    "            \"\\n-- EPOCH {}/{} -------------------------\\n\".format(epoch + 1, num_epochs)\n",
    "        )\n",
    "        torch.cuda.empty_cache()\n",
    "        count_train = [0 for _ in range(len(list_activities))]\n",
    "        count_true_train = [0 for _ in range(len(list_activities))]\n",
    "        count_val = [0 for _ in range(len(list_activities))]\n",
    "        count_true_val = [0 for _ in range(len(list_activities))]\n",
    "        for state in [\"train\", \"validation\"]:\n",
    "            if state == \"train\":\n",
    "                model.train()\n",
    "                metric_tracker.clear()\n",
    "                # true_label = []\n",
    "                # predictions = []\n",
    "                # scores = []\n",
    "\n",
    "            else:\n",
    "                \n",
    "                # print(metric_tracker.confusion_matrix())\n",
    "                #print(count_train)\n",
    "                #print(count_true_train)\n",
    "                \n",
    "                print(\"\\tTRAIN | acc: {:.4f} | mAcc: {:.4f} | mIoU: {:.4f}\".format(metric_tracker.acc(),\n",
    "                                                                                   #metric_tracker.mAcc(),\n",
    "                                                                                   #metric_tracker.mIoU()\n",
    "                                                                                   0,0))\n",
    "                \n",
    "                # y_true = np.concatenate(true_label)\n",
    "                # y_pred = np.concatenate(predictions)\n",
    "                # scores = np.concatenate(scores)\n",
    "                \n",
    "                # print(\"TRAIN\")\n",
    "                # print(conta(y_true, 0), conta(y_true, 1))\n",
    "                # print(conta(y_pred, 0), conta(y_pred, 1))\n",
    "                \n",
    "                # print_stats(y_pred, y_true, scores)\n",
    "                metric_tracker.clear()\n",
    "                model.eval()\n",
    "                # true_label = []\n",
    "                # predictions = []\n",
    "                # scores = []\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for i,(x,y) in tqdm(enumerate(loaders[state])):\n",
    "                \n",
    "                if i % 1 == 0:\n",
    "                    print(metric_tracker.acc())\n",
    "                    # print(running_loss/i)\n",
    "                    print(metric_tracker.confusion_matrix())\n",
    "                    #print(count_train)\n",
    "                    #print(count_true_train)\n",
    "                    print(\"//\"*14)\n",
    "                # print(\"X\")\n",
    "                # print(\"//\"*50)\n",
    "                # print(x)\n",
    "                # print(\"//\"*50)\n",
    "                # print(y)\n",
    "                x = [xx.to(device) for xx in x]\n",
    "                x_edge_index_dicts = [xx.edge_index_dict for xx in x]\n",
    "                x_dicts = [xx.x_dict for xx in x]\n",
    "                # print(\"//\"*50)\n",
    "                #print(x)\n",
    "                #print(x.edge_index_dict)\n",
    "                #print(x.x_dict)\n",
    "                # print(\"//\"*50)\n",
    "                \n",
    "                y = [yy.to(device) for yy in y]\n",
    "                y = stack(y)\n",
    "                \n",
    "                #x = [[sub_item.to(device=device) for sub_item in item] for item in x]\n",
    "\n",
    "\n",
    "                #y = torch.tensor([torch.max(yi,0)[1] for yi in y])\n",
    "\n",
    "                #y = y.to(device)\n",
    "                \n",
    "                outputs = model(x_dicts, x_edge_index_dicts)\n",
    "                \n",
    "                # print(outputs)\n",
    "                # print(\"//\"*30)\n",
    "                \n",
    "                \n",
    "                # outputs = outputs.to(device)\n",
    "                \n",
    "                #print(outputs)\n",
    "                #print(y)\n",
    "                \n",
    "                loss = criterion(outputs, y)\n",
    "\n",
    "                if state == \"train\":\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                \n",
    "                # print(y)\n",
    "                _, true_preds = torch.max(y, 1)                  \n",
    "                # print(true_preds)\n",
    "                preds = preds.to(device)\n",
    "                true_preds = true_preds.to(device)\n",
    "                # if state == \"train\": # For now batch is set to one\n",
    "                #     #for i in preds:\n",
    "                #     count_train[preds] += 1\n",
    "                #     count_true_train[true_preds] += 1\n",
    "                #     \n",
    "                # else:\n",
    "                #     #for i in preds:\n",
    "                #     count_val[preds] += 1      \n",
    "                #     count_true_val[true_preds] += 1      \n",
    "                      \n",
    "                      \n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                # print(outputs, y, sep=\"\\n\")\n",
    "                # print(preds, true_preds, sep=\"\\n\")\n",
    "                # print(preds)\n",
    "                # print(true_preds)\n",
    "                metric_tracker.add(torch.tensor(preds.to(int32)), torch.tensor(true_preds.to(int32)))\n",
    "                # print(metric_tracker.confusion_matrix())\n",
    "                \n",
    "                \n",
    "        print(count_val)\n",
    "        print(\"\\tEVAL  | acc: {:.4f} | mAcc: {:.4f} | mIoU: {:.4f}\\n\".format(metric_tracker.acc(),\n",
    "                                                                             # metric_tracker.mAcc(),\n",
    "                                                                             # metric_tracker.mIoU()\n",
    "                                                                             # )\n",
    "                                                                            0,0)   )     \n",
    "                   \n",
    "\n",
    "        if epoch == 0:# HERE WE KEEP BEST AUC VALUE\n",
    "            best_accuracy = metric_tracker.acc()\n",
    "            \n",
    "        else:\n",
    "            if metric_tracker.acc() > best_accuracy:\n",
    "                print(\"SAVING MODEL..............\\n\")\n",
    "                best_accuracy = metric_tracker.acc()\n",
    "                not_improved_count = 0\n",
    "            else:\n",
    "                not_improved_count += 1\n",
    "\n",
    "        if not_improved_count == early_stop_patience:\n",
    "            print(\n",
    "                \"Validation performance didn't improve for {} epochs. \"\n",
    "                \"Training stops.\".format(early_stop_patience)\n",
    "            )\n",
    "            break\n",
    "\n",
    "    running_time.append((datetime.datetime.now() - start).total_seconds())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hgnn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
