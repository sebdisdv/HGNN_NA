{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sebdis/ProcessMining/HGNN/HGNN_NA\n",
      "/home/sebdis/ProcessMining/HGNN/HGNN_NA/data/datasets/original/\n",
      "/home/sebdis/ProcessMining/HGNN/HGNN_NA/data/datasets/processed/\n",
      "/home/sebdis/ProcessMining/HGNN/HGNN_NA/data/datasets/graphs/\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from os.path import dirname\n",
    "\n",
    "root_path = dirname(os.getcwd())\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "data_dir = root_path + \"/data/datasets/original/\"\n",
    "data_dir_processed = root_path + \"/data/datasets/processed/\"\n",
    "data_dir_graphs = root_path + \"/data/datasets/graphs/\"\n",
    "\n",
    "print(root_path, data_dir, data_dir_processed, data_dir_graphs, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"BPI_Challenge_2012_W_Complete\"\n",
    "data_dir_dataset_encoders = root_path + \"/data/datasets/encoders/\" + dataset\n",
    "filename = data_dir + dataset + \".csv\"\n",
    "raw_data = pd.read_csv(filename, index_col=False)\n",
    "raw_data = raw_data.drop(columns=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_all = raw_data.rename(\n",
    "    columns={\"case:concept:name\": \"CaseID\", \"concept:name\": \"Activity\"}\n",
    ")\n",
    "# tab_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>org:resource</th>\n",
       "      <th>lifecycle:transition</th>\n",
       "      <th>Activity</th>\n",
       "      <th>time:timestamp</th>\n",
       "      <th>case:REG_DATE</th>\n",
       "      <th>CaseID</th>\n",
       "      <th>case:AMOUNT_REQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10912.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>2011/10/01 10:10:25</td>\n",
       "      <td>2011/10/01 09:58:30</td>\n",
       "      <td>173712</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11019.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>2011/10/01 13:03:35</td>\n",
       "      <td>2011/10/01 09:58:30</td>\n",
       "      <td>173712</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11180.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>2011/10/03 11:17:29</td>\n",
       "      <td>2011/10/01 09:58:30</td>\n",
       "      <td>173712</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11180.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>2011/10/03 14:42:55</td>\n",
       "      <td>2011/10/01 09:58:30</td>\n",
       "      <td>173712</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10912.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>2011/10/01 10:16:49</td>\n",
       "      <td>2011/10/01 09:45:37</td>\n",
       "      <td>173706</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   org:resource lifecycle:transition                Activity  \\\n",
       "0       10912.0             COMPLETE      W_Afhandelen leads   \n",
       "1       11019.0             COMPLETE  W_Completeren aanvraag   \n",
       "2       11180.0             COMPLETE  W_Completeren aanvraag   \n",
       "3       11180.0             COMPLETE  W_Completeren aanvraag   \n",
       "4       10912.0             COMPLETE      W_Afhandelen leads   \n",
       "\n",
       "        time:timestamp        case:REG_DATE  CaseID  case:AMOUNT_REQ  \n",
       "0  2011/10/01 10:10:25  2011/10/01 09:58:30  173712            30000  \n",
       "1  2011/10/01 13:03:35  2011/10/01 09:58:30  173712            30000  \n",
       "2  2011/10/03 11:17:29  2011/10/01 09:58:30  173712            30000  \n",
       "3  2011/10/03 14:42:55  2011/10/01 09:58:30  173712            30000  \n",
       "4  2011/10/01 10:16:49  2011/10/01 09:45:37  173706            18000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab_all[\"time:timestamp\"] = [x.split(\".\")[0] for x in tab_all[\"time:timestamp\"]]\n",
    "tab_all[\"case:REG_DATE\"] = [x.split(\".\")[0] for x in tab_all[\"case:REG_DATE\"]]\n",
    "tab_all[\"time:timestamp\"] = tab_all[\"time:timestamp\"].str.replace(\"-\", \"/\")\n",
    "tab_all[\"time:timestamp\"] = tab_all[\"time:timestamp\"].str.split(\"+\", expand=True)[0]\n",
    "tab_all[\"case:REG_DATE\"] = tab_all[\"case:REG_DATE\"].str.replace(\"-\", \"/\")\n",
    "tab_all[\"case:REG_DATE\"] = tab_all[\"case:REG_DATE\"].str.split(\"+\", expand=True)[0]\n",
    "tab_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>org:resource</th>\n",
       "      <th>lifecycle:transition</th>\n",
       "      <th>Activity</th>\n",
       "      <th>time:timestamp</th>\n",
       "      <th>case:REG_DATE</th>\n",
       "      <th>CaseID</th>\n",
       "      <th>case:AMOUNT_REQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10912.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>1.317457e+09</td>\n",
       "      <td>1.317456e+09</td>\n",
       "      <td>173712</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11019.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>1.317467e+09</td>\n",
       "      <td>1.317456e+09</td>\n",
       "      <td>173712</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11180.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>1.317633e+09</td>\n",
       "      <td>1.317456e+09</td>\n",
       "      <td>173712</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11180.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>1.317646e+09</td>\n",
       "      <td>1.317456e+09</td>\n",
       "      <td>173712</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10912.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>1.317457e+09</td>\n",
       "      <td>1.317455e+09</td>\n",
       "      <td>173706</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   org:resource lifecycle:transition                Activity  time:timestamp  \\\n",
       "0       10912.0             COMPLETE      W_Afhandelen leads    1.317457e+09   \n",
       "1       11019.0             COMPLETE  W_Completeren aanvraag    1.317467e+09   \n",
       "2       11180.0             COMPLETE  W_Completeren aanvraag    1.317633e+09   \n",
       "3       11180.0             COMPLETE  W_Completeren aanvraag    1.317646e+09   \n",
       "4       10912.0             COMPLETE      W_Afhandelen leads    1.317457e+09   \n",
       "\n",
       "   case:REG_DATE  CaseID  case:AMOUNT_REQ  \n",
       "0   1.317456e+09  173712            30000  \n",
       "1   1.317456e+09  173712            30000  \n",
       "2   1.317456e+09  173712            30000  \n",
       "3   1.317456e+09  173712            30000  \n",
       "4   1.317455e+09  173706            18000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import translate_time\n",
    "\n",
    "tab_all['time:timestamp'] = tab_all['time:timestamp'].apply(translate_time)\n",
    "tab_all['case:REG_DATE'] = tab_all['case:REG_DATE'].apply(translate_time)\n",
    "tab_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_all.to_csv(data_dir_processed + f\"{dataset}_processed_all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>org:resource</th>\n",
       "      <th>lifecycle:transition</th>\n",
       "      <th>Activity</th>\n",
       "      <th>time:timestamp</th>\n",
       "      <th>case:REG_DATE</th>\n",
       "      <th>CaseID</th>\n",
       "      <th>case:AMOUNT_REQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10912.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>10.442930</td>\n",
       "      <td>1.317456e+09</td>\n",
       "      <td>173712</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11019.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>10.707527</td>\n",
       "      <td>1.317456e+09</td>\n",
       "      <td>173712</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11180.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>12.260206</td>\n",
       "      <td>1.317456e+09</td>\n",
       "      <td>173712</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11180.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>12.316947</td>\n",
       "      <td>1.317456e+09</td>\n",
       "      <td>173712</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10912.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>10.454063</td>\n",
       "      <td>1.317455e+09</td>\n",
       "      <td>173706</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   org:resource lifecycle:transition                Activity  time:timestamp  \\\n",
       "0       10912.0             COMPLETE      W_Afhandelen leads       10.442930   \n",
       "1       11019.0             COMPLETE  W_Completeren aanvraag       10.707527   \n",
       "2       11180.0             COMPLETE  W_Completeren aanvraag       12.260206   \n",
       "3       11180.0             COMPLETE  W_Completeren aanvraag       12.316947   \n",
       "4       10912.0             COMPLETE      W_Afhandelen leads       10.454063   \n",
       "\n",
       "   case:REG_DATE  CaseID  case:AMOUNT_REQ  \n",
       "0   1.317456e+09  173712            30000  \n",
       "1   1.317456e+09  173712            30000  \n",
       "2   1.317456e+09  173712            30000  \n",
       "3   1.317456e+09  173712            30000  \n",
       "4   1.317455e+09  173706            18000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import log\n",
    "import numpy as np\n",
    "\n",
    "min_time = tab_all['time:timestamp'].min() if tab_all['time:timestamp'].min() < tab_all['case:REG_DATE'].min() else tab_all['case:REG_DATE'].min()\n",
    "\n",
    "tab_all['time:timestamp'] -= min_time\n",
    "tab_all['time:timestamp'] = [ log(x)  if x > 0 else 0. for x in tab_all['time:timestamp'].values]\n",
    "# tab_all['time:timestamp'] = np.log(tab_all['time:timestamp'])\n",
    "\n",
    "tab_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>org:resource</th>\n",
       "      <th>lifecycle:transition</th>\n",
       "      <th>Activity</th>\n",
       "      <th>time:timestamp</th>\n",
       "      <th>case:REG_DATE</th>\n",
       "      <th>CaseID</th>\n",
       "      <th>case:AMOUNT_REQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10912.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>10.442930</td>\n",
       "      <td>10.421865</td>\n",
       "      <td>173712</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11019.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>10.707527</td>\n",
       "      <td>10.421865</td>\n",
       "      <td>173712</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11180.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>12.260206</td>\n",
       "      <td>10.421865</td>\n",
       "      <td>173712</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11180.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>12.316947</td>\n",
       "      <td>10.421865</td>\n",
       "      <td>173712</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10912.0</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>W_Afhandelen leads</td>\n",
       "      <td>10.454063</td>\n",
       "      <td>10.398580</td>\n",
       "      <td>173706</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   org:resource lifecycle:transition                Activity  time:timestamp  \\\n",
       "0       10912.0             COMPLETE      W_Afhandelen leads       10.442930   \n",
       "1       11019.0             COMPLETE  W_Completeren aanvraag       10.707527   \n",
       "2       11180.0             COMPLETE  W_Completeren aanvraag       12.260206   \n",
       "3       11180.0             COMPLETE  W_Completeren aanvraag       12.316947   \n",
       "4       10912.0             COMPLETE      W_Afhandelen leads       10.454063   \n",
       "\n",
       "   case:REG_DATE  CaseID  case:AMOUNT_REQ  \n",
       "0      10.421865  173712            30000  \n",
       "1      10.421865  173712            30000  \n",
       "2      10.421865  173712            30000  \n",
       "3      10.421865  173712            30000  \n",
       "4      10.398580  173706            18000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab_all['case:REG_DATE'] -= min_time\n",
    "tab_all['case:REG_DATE'] = [ log(x)  if x > 0 else 0. for x in tab_all['case:REG_DATE'].values]\n",
    "# tab_all['time:timestamp'] = np.log(tab_all['time:timestamp'])\n",
    "\n",
    "tab_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_all['case:AMOUNT_REQ'] = [log(int(x)) if x > 0 else 0 for x in tab_all['case:AMOUNT_REQ'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discover roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "import networkx as nx\n",
    "\n",
    "from operator import itemgetter\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class ResourcePoolAnalyser():\n",
    "    \"\"\"\n",
    "        This class evaluates the tasks durations and associates resources to it\n",
    "     \"\"\"\n",
    "\n",
    "    def __init__(self, log, drawing=False, sim_threshold=0.7):\n",
    "        \"\"\"constructor\"\"\"\n",
    "        self.data = self.read_resource_pool(log)\n",
    "        self.drawing = drawing\n",
    "        self.sim_threshold = sim_threshold\n",
    "        \n",
    "        self.tasks = {val: i for i, val in enumerate(self.data[\"Activity\"].unique())}\n",
    "        self.users = {val: i for i, val in enumerate(self.data[\"org:resource\"].unique())}\n",
    "        \n",
    "        self.roles, self.resource_table = self.discover_roles()\n",
    "\n",
    "    def read_resource_pool(self, log):\n",
    "        if isinstance(log, pd.DataFrame):\n",
    "            filtered_list = log[['Activity', 'org:resource']]\n",
    "        else:\n",
    "            filtered_list = pd.DataFrame(log.data)[['Activity', 'org:resource']]\n",
    "        #filtered_list = filtered_list[~filtered_list.task.isin(['Start', 'End'])]\n",
    "        #filtered_list = filtered_list[filtered_list.user != 'AUTO']\n",
    "        return filtered_list\n",
    "\n",
    "\n",
    "    def discover_roles(self):\n",
    "        associations = lambda x: (self.tasks[x['Activity']], self.users[x['org:resource']])\n",
    "        self.data['ac_rl'] = self.data.apply(associations, axis=1)\n",
    "    \n",
    "        freq_matrix = (self.data.groupby(by='ac_rl')['Activity']\n",
    "                       .count()\n",
    "                       .reset_index()\n",
    "                       .rename(columns={'Activity': 'freq'}))\n",
    "        freq_matrix = {x['ac_rl']: x['freq'] for x in freq_matrix.to_dict('records')}\n",
    "        \n",
    "        profiles = self.build_profile(freq_matrix)\n",
    "    \n",
    "        print(((20 / 100)* 100),'Analysing resource pool ')\n",
    "        # building of a correl matrix between resouces profiles\n",
    "        correl_matrix = self.det_correl_matrix(profiles)\n",
    "        print(((40 / 100)* 100),'Analysing resource pool ')\n",
    "        # creation of a rel network between resouces\n",
    "        g = nx.Graph()\n",
    "        for user in self.users.values():\n",
    "            g.add_node(user)\n",
    "        for rel in correl_matrix:\n",
    "            # creation of edges between nodes excluding the same elements\n",
    "            # and those below the similarity threshold \n",
    "            if rel['distance'] > self.sim_threshold and rel['x'] != rel['y']:\n",
    "                g.add_edge(rel['x'],\n",
    "                           rel['y'],\n",
    "                           weight=rel['distance'])\n",
    "        print(((60 / 100) * 100),'Analysing resource pool ')\n",
    "        # extraction of fully conected subgraphs as roles\n",
    "        sub_graphs = list(nx.connected_components(g))\n",
    "        print(((80 / 100) * 100),'Analysing resource pool ')\n",
    "        # role definition from graph\n",
    "        roles = self.role_definition(sub_graphs)\n",
    "        # plot creation (optional)\n",
    "        # if drawing == True:\n",
    "        #     graph_network(g, sub_graphs)\n",
    "        print(((100 / 100)* 100),'Analysing resource pool ')\n",
    "        \n",
    "        \n",
    "        import pprint\n",
    "        pprint.pprint(f\"ROLES \\n\\n{roles}\\n\\n\")\n",
    "        return roles\n",
    "    \n",
    "    def build_profile(self, freq_matrix):\n",
    "        profiles=list()\n",
    "        for user, idx in self.users.items():\n",
    "            profile = [0,] * len(self.tasks)\n",
    "            for ac_rl, freq in freq_matrix.items():\n",
    "                if idx == ac_rl[1]:\n",
    "                    profile[ac_rl[0]] = freq\n",
    "            profiles.append({'user': idx, 'profile': profile})\n",
    "        return profiles\n",
    "\n",
    "\n",
    "\n",
    "    def det_correl_matrix(self, profiles):\n",
    "        correl_matrix = list()\n",
    "        import numpy\n",
    "        for profile_x in profiles:\n",
    "            for profile_y in profiles:\n",
    "                x = numpy.array(profile_x['profile'])\n",
    "                y = numpy.array(profile_y['profile'])\n",
    "                r_row, p_value = pearsonr(x, y)\n",
    "                correl_matrix.append(({'x': profile_x['user'],\n",
    "                                            'y': profile_y['user'],\n",
    "                                            'distance': r_row}))\n",
    "        return correl_matrix\n",
    "\n",
    "    def role_definition(self, sub_graphs):\n",
    "        user_index = {v: k for k, v in self.users.items()}\n",
    "        records= list()\n",
    "        for i in range(0, len(sub_graphs)):\n",
    "            users_names = [user_index[x] for x in sub_graphs[i]]\n",
    "            records.append({'role': 'Role '+ str(i + 1),\n",
    "                            'quantity': len(sub_graphs[i]),\n",
    "                            'members': users_names})\n",
    "        #Sort roles by number of resources\n",
    "        records = sorted(records, key=itemgetter('quantity'), reverse=True)\n",
    "        for i in range(0,len(records)):\n",
    "            records[i]['role']='Role '+ str(i + 1)\n",
    "        resource_table = list()\n",
    "        for record in records:\n",
    "            for member in record['members']:\n",
    "                resource_table.append({'role': record['role'],\n",
    "                                       'resource': member})\n",
    "        return records, resource_table\n",
    "    \n",
    "    \n",
    "def get_resource_role_map(log):\n",
    "    r = ResourcePoolAnalyser(log)\n",
    "    return r.resource_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_all = tab_all.fillna({key: \"NAN\" for key in [\"org:resource\"]})\n",
    "# tab_all = tab_all.fillna({key: -1 for key in real_value_columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebdis/ProcessMining/HGNN/HGNN_NA/data/utils.py:218: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['ac_rl'] = self.data.apply(associations, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0 Analysing resource pool \n",
      "40.0 Analysing resource pool \n",
      "60.0 Analysing resource pool \n",
      "80.0 Analysing resource pool \n",
      "100.0 Analysing resource pool \n",
      "('ROLES \\n'\n",
      " '\\n'\n",
      " \"([{'role': 'Role 1', 'quantity': 49, 'members': [10912.0, 11019.0, 11180.0, \"\n",
      " \"'NAN', 10982.0, 11002.0, 11049.0, 11122.0, 10913.0, 10889.0, 11121.0, \"\n",
      " '10939.0, 11009.0, 11201.0, 11119.0, 10861.0, 11203.0, 11181.0, 11189.0, '\n",
      " '10899.0, 11000.0, 10863.0, 11169.0, 11179.0, 11001.0, 10228.0, 10909.0, '\n",
      " '10789.0, 10881.0, 10910.0, 10929.0, 10931.0, 11259.0, 10779.0, 10914.0, '\n",
      " '10933.0, 11079.0, 10932.0, 10935.0, 11254.0, 11003.0, 11269.0, 112.0, '\n",
      " \"11299.0, 10124.0, 11309.0, 11300.0, 11302.0, 11319.0]}, {'role': 'Role 2', \"\n",
      " \"'quantity': 9, 'members': [10629.0, 11339.0, 10972.0, 10609.0, 10821.0, \"\n",
      " \"11289.0, 10125.0, 10809.0, 10138.0]}, {'role': 'Role 3', 'quantity': 2, \"\n",
      " \"'members': [11304.0, 10188.0]}], [{'role': 'Role 1', 'resource': 10912.0}, \"\n",
      " \"{'role': 'Role 1', 'resource': 11019.0}, {'role': 'Role 1', 'resource': \"\n",
      " \"11180.0}, {'role': 'Role 1', 'resource': 'NAN'}, {'role': 'Role 1', \"\n",
      " \"'resource': 10982.0}, {'role': 'Role 1', 'resource': 11002.0}, {'role': \"\n",
      " \"'Role 1', 'resource': 11049.0}, {'role': 'Role 1', 'resource': 11122.0}, \"\n",
      " \"{'role': 'Role 1', 'resource': 10913.0}, {'role': 'Role 1', 'resource': \"\n",
      " \"10889.0}, {'role': 'Role 1', 'resource': 11121.0}, {'role': 'Role 1', \"\n",
      " \"'resource': 10939.0}, {'role': 'Role 1', 'resource': 11009.0}, {'role': \"\n",
      " \"'Role 1', 'resource': 11201.0}, {'role': 'Role 1', 'resource': 11119.0}, \"\n",
      " \"{'role': 'Role 1', 'resource': 10861.0}, {'role': 'Role 1', 'resource': \"\n",
      " \"11203.0}, {'role': 'Role 1', 'resource': 11181.0}, {'role': 'Role 1', \"\n",
      " \"'resource': 11189.0}, {'role': 'Role 1', 'resource': 10899.0}, {'role': \"\n",
      " \"'Role 1', 'resource': 11000.0}, {'role': 'Role 1', 'resource': 10863.0}, \"\n",
      " \"{'role': 'Role 1', 'resource': 11169.0}, {'role': 'Role 1', 'resource': \"\n",
      " \"11179.0}, {'role': 'Role 1', 'resource': 11001.0}, {'role': 'Role 1', \"\n",
      " \"'resource': 10228.0}, {'role': 'Role 1', 'resource': 10909.0}, {'role': \"\n",
      " \"'Role 1', 'resource': 10789.0}, {'role': 'Role 1', 'resource': 10881.0}, \"\n",
      " \"{'role': 'Role 1', 'resource': 10910.0}, {'role': 'Role 1', 'resource': \"\n",
      " \"10929.0}, {'role': 'Role 1', 'resource': 10931.0}, {'role': 'Role 1', \"\n",
      " \"'resource': 11259.0}, {'role': 'Role 1', 'resource': 10779.0}, {'role': \"\n",
      " \"'Role 1', 'resource': 10914.0}, {'role': 'Role 1', 'resource': 10933.0}, \"\n",
      " \"{'role': 'Role 1', 'resource': 11079.0}, {'role': 'Role 1', 'resource': \"\n",
      " \"10932.0}, {'role': 'Role 1', 'resource': 10935.0}, {'role': 'Role 1', \"\n",
      " \"'resource': 11254.0}, {'role': 'Role 1', 'resource': 11003.0}, {'role': \"\n",
      " \"'Role 1', 'resource': 11269.0}, {'role': 'Role 1', 'resource': 112.0}, \"\n",
      " \"{'role': 'Role 1', 'resource': 11299.0}, {'role': 'Role 1', 'resource': \"\n",
      " \"10124.0}, {'role': 'Role 1', 'resource': 11309.0}, {'role': 'Role 1', \"\n",
      " \"'resource': 11300.0}, {'role': 'Role 1', 'resource': 11302.0}, {'role': \"\n",
      " \"'Role 1', 'resource': 11319.0}, {'role': 'Role 2', 'resource': 10629.0}, \"\n",
      " \"{'role': 'Role 2', 'resource': 11339.0}, {'role': 'Role 2', 'resource': \"\n",
      " \"10972.0}, {'role': 'Role 2', 'resource': 10609.0}, {'role': 'Role 2', \"\n",
      " \"'resource': 10821.0}, {'role': 'Role 2', 'resource': 11289.0}, {'role': \"\n",
      " \"'Role 2', 'resource': 10125.0}, {'role': 'Role 2', 'resource': 10809.0}, \"\n",
      " \"{'role': 'Role 2', 'resource': 10138.0}, {'role': 'Role 3', 'resource': \"\n",
      " \"11304.0}, {'role': 'Role 3', 'resource': 10188.0}])\\n\"\n",
      " '\\n')\n"
     ]
    }
   ],
   "source": [
    "from utils import get_resource_role_map\n",
    "roles_map = get_resource_role_map(tab_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10912.0: 'Role 1',\n",
       " 11019.0: 'Role 1',\n",
       " 11180.0: 'Role 1',\n",
       " 'NAN': 'Role 1',\n",
       " 10982.0: 'Role 1',\n",
       " 11002.0: 'Role 1',\n",
       " 11049.0: 'Role 1',\n",
       " 11122.0: 'Role 1',\n",
       " 10913.0: 'Role 1',\n",
       " 10889.0: 'Role 1',\n",
       " 11121.0: 'Role 1',\n",
       " 10939.0: 'Role 1',\n",
       " 11009.0: 'Role 1',\n",
       " 11201.0: 'Role 1',\n",
       " 11119.0: 'Role 1',\n",
       " 10861.0: 'Role 1',\n",
       " 11203.0: 'Role 1',\n",
       " 11181.0: 'Role 1',\n",
       " 11189.0: 'Role 1',\n",
       " 10899.0: 'Role 1',\n",
       " 11000.0: 'Role 1',\n",
       " 10863.0: 'Role 1',\n",
       " 11169.0: 'Role 1',\n",
       " 11179.0: 'Role 1',\n",
       " 11001.0: 'Role 1',\n",
       " 10228.0: 'Role 1',\n",
       " 10909.0: 'Role 1',\n",
       " 10789.0: 'Role 1',\n",
       " 10881.0: 'Role 1',\n",
       " 10910.0: 'Role 1',\n",
       " 10929.0: 'Role 1',\n",
       " 10931.0: 'Role 1',\n",
       " 11259.0: 'Role 1',\n",
       " 10779.0: 'Role 1',\n",
       " 10914.0: 'Role 1',\n",
       " 10933.0: 'Role 1',\n",
       " 11079.0: 'Role 1',\n",
       " 10932.0: 'Role 1',\n",
       " 10935.0: 'Role 1',\n",
       " 11254.0: 'Role 1',\n",
       " 11003.0: 'Role 1',\n",
       " 11269.0: 'Role 1',\n",
       " 112.0: 'Role 1',\n",
       " 11299.0: 'Role 1',\n",
       " 10124.0: 'Role 1',\n",
       " 11309.0: 'Role 1',\n",
       " 11300.0: 'Role 1',\n",
       " 11302.0: 'Role 1',\n",
       " 11319.0: 'Role 1',\n",
       " 10629.0: 'Role 2',\n",
       " 11339.0: 'Role 2',\n",
       " 10972.0: 'Role 2',\n",
       " 10609.0: 'Role 2',\n",
       " 10821.0: 'Role 2',\n",
       " 11289.0: 'Role 2',\n",
       " 10125.0: 'Role 2',\n",
       " 10809.0: 'Role 2',\n",
       " 10138.0: 'Role 2',\n",
       " 11304.0: 'Role 3',\n",
       " 10188.0: 'Role 3'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roles_map = {\n",
    "    x[\"resource\"] : x[\"role\"]\n",
    "    for x in roles_map\n",
    "}\n",
    "roles_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_all[\"org:resource:role\"] = [roles_map[role] for role in tab_all[\"org:resource\"].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_all[\"org:resource\"] = [str(x) for x in tab_all[\"org:resource\"].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_all.to_csv(data_dir_processed + f\"{dataset}_processed_all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 2 / 3\n",
    "\n",
    "first_act_tab = (\n",
    "    tab_all.groupby(\"CaseID\").first().sort_values(\"time:timestamp\").reset_index()\n",
    ")\n",
    "first_act_tab = first_act_tab[\n",
    "    ~first_act_tab.duplicated(subset=[\"CaseID\", \"Activity\"], keep=\"first\")\n",
    "]\n",
    "first_act_tab = first_act_tab.reset_index(drop=True)\n",
    "\n",
    "list_train_valid_cases = list(\n",
    "    first_act_tab[: int(split_ratio * len(first_act_tab))][\"CaseID\"].unique()\n",
    ")\n",
    "\n",
    "list_train_cases = list_train_valid_cases[: int(len(list_train_valid_cases) * 0.8)]\n",
    "tab_train = tab_all[tab_all[\"CaseID\"].isin(list_train_cases)].reset_index(drop=True)\n",
    "# tab_train.to_csv(data_dir_processed+ f\"{dataset}_processed_train.csv\", index = False)\n",
    "\n",
    "list_valid_cases = list_train_valid_cases[int(len(list_train_valid_cases) * 0.8) :]\n",
    "tab_valid = tab_all[tab_all[\"CaseID\"].isin(list_valid_cases)].reset_index(drop=True)\n",
    "# tab_valid.to_csv(data_dir_processed+f\"{dataset}_processed_valid.csv\", index = False)\n",
    "\n",
    "list_test_cases = list(\n",
    "    first_act_tab[int(split_ratio * len(first_act_tab)) :][\"CaseID\"].unique()\n",
    ")\n",
    "tab_test = tab_all[tab_all[\"CaseID\"].isin(list_test_cases)].reset_index(drop=True)\n",
    "# tab_test.to_csv(data_dir_processed+ f\"{dataset}_processed_test.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_all['org:resource'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(tab_all['Activity'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoders for categorical attributes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, n_categories):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(n_categories, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(8, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, n_categories),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_categories = [\"Activity\", \"org:resource\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os.path as path\n",
    "\n",
    "encoders = {k: AutoEncoder(n_categories= len(tab_all[k].unique())) for k in cat_categories}\n",
    "print()\n",
    "for k in encoders:\n",
    "    encoders[k].load_state_dict(torch.load(path.join(data_dir_dataset_encoders, f\"encoder_{k}.pt\"), weights_only=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_case_ids, is_static, get_one_hot_encoder, get_one_hot_encodings\n",
    "import utils\n",
    "from torch import tensor, max, int64, float32\n",
    "from torch_geometric.data import HeteroData\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_features(dataset: pd.DataFrame, trace: pd.DataFrame) -> dict:\n",
    "    columns_static = [c for c in trace if is_static(trace[c])]\n",
    "\n",
    "    res = {}\n",
    "\n",
    "    for key in trace:\n",
    "        values = trace[key].values\n",
    "        match key:\n",
    "            case \"Activity\":\n",
    "                onehot_activities = get_one_hot_encoder(dataset, \"Activity\")\n",
    "                res[key] = tensor(\n",
    "                    get_one_hot_encodings(onehot_activities, values), dtype=float32,requires_grad=True\n",
    "                )\n",
    "            case \"time:timestamp\":\n",
    "                res[key] = tensor(\n",
    "                    values,  dtype=float32,requires_grad=True\n",
    "                )\n",
    "                res[key] = res[key].reshape(res[key].shape[0], 1)\n",
    "            case \"org:resource\":\n",
    "                onehot_resource = get_one_hot_encoder(dataset, \"org:resource\")\n",
    "                # if key not in columns_static:\n",
    "                res[key] = tensor(\n",
    "                    get_one_hot_encodings(onehot_resource, values),\n",
    "                    dtype=float32,\n",
    "                    requires_grad=True\n",
    "                )\n",
    "            case \"org:resource:role\":\n",
    "                onehot_resource_role = get_one_hot_encoder(dataset, \"org:resource:role\")\n",
    "                # if key not in columns_static:\n",
    "                res[key] = tensor(\n",
    "                    get_one_hot_encodings(onehot_resource_role, values),\n",
    "                    dtype=float32,\n",
    "                    requires_grad=True\n",
    "                )               \n",
    "\n",
    "            case \"lifecycle:transition\":\n",
    "                onehot_lifecyle_transition = get_one_hot_encoder(\n",
    "                    dataset, \"lifecycle:transition\"\n",
    "                )\n",
    "                if key not in columns_static:\n",
    "                    res[key] = tensor(\n",
    "                        get_one_hot_encodings(onehot_lifecyle_transition, values),\n",
    "                        dtype=float32,\n",
    "                        requires_grad=True\n",
    "                    )\n",
    "                else:\n",
    "                    res[key] = tensor(\n",
    "                        get_one_hot_encodings(\n",
    "                            onehot_lifecyle_transition, np.array([values[0]])\n",
    "                        ),\n",
    "                        dtype=float32,\n",
    "                        requires_grad=True\n",
    "                    )\n",
    "            case \"case:REG_DATE\":\n",
    "                if key not in columns_static:\n",
    "                    res[key] = tensor(\n",
    "                        values, dtype=float32,requires_grad=True\n",
    "                    )\n",
    "                else:\n",
    "                    res[key] = tensor(\n",
    "                        [values[0]],\n",
    "                        dtype=float32,\n",
    "                        requires_grad=True\n",
    "                    )\n",
    "                res[key] = res[key].reshape(res[key].shape[0], 1)\n",
    "            case \"case:AMOUNT_REQ\":\n",
    "                if key not in columns_static:\n",
    "                    res[key] = tensor(values, dtype=float32,requires_grad=True)\n",
    "                else:\n",
    "                    res[key] = tensor([values[0]], dtype=float32,requires_grad=True)\n",
    "                res[key] = res[key].reshape(res[key].shape[0], 1)\n",
    "\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_edges_indexs(node_features: dict, prefix_len):\n",
    "    res = {}\n",
    "    keys = node_features.keys()\n",
    "    # indexes = [[i, j] for i in range(prefix_len) for j in range(i + 1, prefix_len)]\n",
    "    indexes = [[i, i + 1] for i in range(prefix_len-1)]\n",
    "    # activities indexes\n",
    "    for k in keys:\n",
    "        if len(node_features[k]) != 1:\n",
    "            if k == \"Activity\":\n",
    "                res[(k, \"followed_by\", k)] = indexes\n",
    "                for k2 in keys:\n",
    "                    if k2 != k:\n",
    "                        if len(node_features[k2]) == 1:\n",
    "                            res[(k, \"related_to\", k2)] = [\n",
    "                                [i, 0] for i in range(prefix_len)\n",
    "                            ]\n",
    "                        else:\n",
    "                            res[(k, \"related_to\", k2)] = [\n",
    "                                [i, i] for i in range(prefix_len)\n",
    "                            ]\n",
    "            else:\n",
    "                res[(k, \"related_to\", k)] = indexes\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cat\n",
    "\n",
    "\n",
    "def compute_edges_features(node_features, edges_indexes):\n",
    "    res = {}\n",
    "\n",
    "    for k in edges_indexes:\n",
    "        if k[0] == k[2]:\n",
    "            indexes = edges_indexes[k]\n",
    "            res[k] = []\n",
    "            match k[0]:\n",
    "                case \"Activity\":\n",
    "                    for i in indexes:\n",
    "                        res[k].append(\n",
    "                            # cat( (tensor([cosine_similarity(node_features[k[0]][i[1]],node_features[k[0]][i[0]], dim=0)]),tensor([i[1] - i[0]])) )\n",
    "                            cat(\n",
    "                                (\n",
    "                                    #node_features[k[0]][i[1]]\n",
    "                                    #- node_features[k[0]][i[0]],\n",
    "                                    #tensor([torch.cosine_similarity(node_features[k[0]][i[0]], node_features[k[0]][i[1]], dim=0)]),\n",
    "                                    tensor([torch.equal(node_features[k[0]][i[0]],node_features[k[0]][i[1]])], dtype=torch.float32),\n",
    "                                    tensor([i[1] - i[0]], dtype=torch.float32),\n",
    "                                )\n",
    "                            )\n",
    "                        )\n",
    "                case \"org:resource\":\n",
    "                    for i in indexes:\n",
    "                        res[k].append(\n",
    "                            # cat( (tensor([cosine_similarity(node_features[k[0]][i[1]], node_features[k[0]][i[0]], dim=0)]),tensor([i[1] - i[0]])) )\n",
    "                            cat(\n",
    "                                (\n",
    "                                    # node_features[k[0]][i[1]]\n",
    "                                    # - node_features[k[0]][i[0]],\n",
    "                                   #tensor([torch.cosine_similarity(node_features[k[0]][i[0]], node_features[k[0]][i[1]], dim=0)]),\n",
    "                                   tensor([torch.equal(node_features[k[0]][i[0]],node_features[k[0]][i[1]])], dtype=torch.float32),\n",
    "                                   tensor([i[1] - i[0]], dtype=torch.float32),\n",
    "                                )\n",
    "                            )\n",
    "                        )\n",
    "                case \"org:resource:role\":\n",
    "                    for i in indexes:\n",
    "                        res[k].append(\n",
    "                            # cat( (tensor([cosine_similarity(node_features[k[0]][i[1]], node_features[k[0]][i[0]], dim=0)]),tensor([i[1] - i[0]])) )\n",
    "                            cat(\n",
    "                                (\n",
    "                                    # node_features[k[0]][i[1]]\n",
    "                                    # - node_features[k[0]][i[0]],\n",
    "                                   #tensor([torch.cosine_similarity(node_features[k[0]][i[0]], node_features[k[0]][i[1]], dim=0)]),\n",
    "                                   tensor([torch.equal(node_features[k[0]][i[0]],node_features[k[0]][i[1]])], dtype=torch.float32),\n",
    "                                   tensor([i[1] - i[0]], dtype=torch.float32),\n",
    "                                )\n",
    "                            )\n",
    "                        )\n",
    "                case \"time:timestamp\":\n",
    "                    for i in indexes:\n",
    "                        res[k].append(\n",
    "                            tensor(\n",
    "                                [\n",
    "                                    node_features[k[0]][i[1]]\n",
    "                                    - node_features[k[0]][i[0]],\n",
    "                                    i[1] - i[0],\n",
    "                                ]\n",
    "                            )\n",
    "                        )\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pprint import pprint as print\n",
    "\n",
    "from torch import stack\n",
    "from math import log\n",
    "\n",
    "def build_prefixes_graph_from_trace(dataset, trace):\n",
    "    X = []  # graphs\n",
    "    Y = []  # NA, timestamp, resource labels\n",
    "\n",
    "    node_features = get_node_features(dataset, trace)\n",
    "    \n",
    "    #new_node_features = {}\n",
    "    #for k in node_features:\n",
    "    #    if k in cat_categories:\n",
    "    #        new_node_features[k] = []\n",
    "    #        for i in range(len(node_features[k])):\n",
    "    #            new_node_features[k].append(encoders[k].encoder(node_features[k][i]))\n",
    "    #        new_node_features[k] = torch.stack(new_node_features[k])\n",
    "    #    else:\n",
    "    #        new_node_features[k] = node_features[k]\n",
    "    \n",
    "    # !!!!!!!!!!!!!!!!!\n",
    "    new_node_features = node_features\n",
    "    \n",
    "    prefix_lenghts = range(2, len(trace))\n",
    "    # print(prefix_lenghts)\n",
    "    for prefix in prefix_lenghts:\n",
    "        # print(prefix)\n",
    "\n",
    "        # init node types and features\n",
    "        G = HeteroData()\n",
    "        for k in new_node_features:\n",
    "            if k == \"org:resource\":\n",
    "                G[k].x = new_node_features[k][:prefix]\n",
    "            else:\n",
    "                G[k].x = new_node_features[k][:prefix]\n",
    "\n",
    "        edges_indexes = compute_edges_indexs(new_node_features, prefix)\n",
    "\n",
    "        edge_features = compute_edges_features(new_node_features, edges_indexes)\n",
    "    \n",
    "        for k in edge_features:\n",
    "            if k[0] in [\"Activity\", \"org:resource\", \"time:timestamp\", \"org:resource:role\"]:\n",
    "                G[k].edge_attr = stack(edge_features[k])\n",
    "            else:\n",
    "                G[k].edge_attr = tensor(edge_features[k], dtype=float32)\n",
    "\n",
    "        for k in edges_indexes:\n",
    "            ce = [[], []]\n",
    "            for i in range(len(edges_indexes[k])):\n",
    "                ce[0].append(edges_indexes[k][i][0])\n",
    "                ce[1].append(edges_indexes[k][i][1])\n",
    "            edges_indexes[k] = ce\n",
    "\n",
    "        for k in edges_indexes:\n",
    "            G[k].edge_index = tensor(edges_indexes[k], dtype=int64)\n",
    "\n",
    "        \n",
    "        G.y = {\n",
    "            \"Activity\" : torch.max(node_features[\"Activity\"][prefix],0)[1],\n",
    "            \"time:timestamp\" :  torch.tensor([node_features[\"time:timestamp\"][prefix][0]]),\n",
    "            \"org:resource\" : torch.max(node_features[\"org:resource\"][0],0)[1] if len(node_features[\"org:resource\"]) == 1 else torch.max(node_features[\"org:resource\"][prefix], 0)[1],\n",
    "            \"org:resource:role\" : torch.max(node_features[\"org:resource:role\"][0],0)[1] if len(node_features[\"org:resource:role\"]) == 1 else torch.max(node_features[\"org:resource:role\"][prefix], 0)[1],\n",
    "        }\n",
    "        \n",
    "        X.append(G)\n",
    "\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_train_ids = get_case_ids(tab_train)\n",
    "case_valid_ids = get_case_ids(tab_valid)\n",
    "case_test_ids = get_case_ids(tab_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(case_train_ids))\n",
    "print(len(case_valid_ids))\n",
    "print(len(case_test_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = (\n",
    "        tab_train.query(f\"CaseID == {case_train_ids[0]}\")\n",
    "        .reset_index()\n",
    "        .drop(columns=\"index\")\n",
    "        .drop(columns=\"CaseID\")\n",
    "    )\n",
    "trace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = build_prefixes_graph_from_trace(tab_all, trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs[2].edge_attrs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import torch_geometric\n",
    "import torch_geometric.utils\n",
    "#g = torch_geometric.utils.to_networkx(graphs[0])\n",
    "#nx.draw(g, with_labels=True,node_size=500, \n",
    "#    node_color='skyblue', \n",
    "#    font_weight='bold')\n",
    "\n",
    "nx_graph = torch_geometric.utils.convert.to_networkx(graphs[0])\n",
    "\n",
    "nx.draw_shell(nx_graph, with_labels=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs[1].to_homogeneous().node_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs[1].x_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs[1].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs[1].edge_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "print(\"Preparing training dataset...\")\n",
    "\n",
    "X_train = []\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(case_train_ids))):\n",
    "    trace = (\n",
    "        tab_train.query(f\"CaseID == {case_train_ids[i]}\")\n",
    "        .reset_index()\n",
    "        .drop(columns=\"index\")\n",
    "        .drop(columns=\"CaseID\")\n",
    "    )\n",
    "    graphs = build_prefixes_graph_from_trace(dataset=tab_all, trace=trace)\n",
    "    \n",
    "    # print(trace)\n",
    "    # print([x.x_dict for x in graphs[:2]])\n",
    "    # print(labels[:2])\n",
    "    # break\n",
    "\n",
    "    for i in range(len(graphs)):\n",
    "        X_train.append(graphs[i])\n",
    "        \n",
    "\n",
    "# Y_train = tensor(Y_train, dtype=float32)\n",
    "\n",
    "print(\"Done!\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preparing validation dataset...\")\n",
    "\n",
    "X_valid = []\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(case_valid_ids))):\n",
    "    trace = (\n",
    "        tab_valid.query(f\"CaseID == {case_valid_ids[i]}\")\n",
    "        .reset_index()\n",
    "        .drop(columns=\"index\")\n",
    "        .drop(columns=\"CaseID\")\n",
    "    )\n",
    "    graphs = build_prefixes_graph_from_trace(dataset=tab_all, trace=trace)\n",
    "    for i in range(len(graphs)):\n",
    "        X_valid.append(graphs[i])\n",
    "       \n",
    "\n",
    "# Y_valid = tensor(Y_valid)\n",
    "\n",
    "print(\"Done!\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preparing test dataset...\")\n",
    "\n",
    "X_test = []\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(case_test_ids))):\n",
    "    trace = (\n",
    "        tab_test.query(f\"CaseID == {case_test_ids[i]}\")\n",
    "        .reset_index()\n",
    "        .drop(columns=\"index\")\n",
    "        .drop(columns=\"CaseID\")\n",
    "    )\n",
    "    graphs = build_prefixes_graph_from_trace(dataset=tab_all, trace=trace)\n",
    "    for i in range(len(graphs)):\n",
    "        X_test.append(graphs[i])\n",
    "     \n",
    "\n",
    "# Y_test = tensor(Y_test)\n",
    "\n",
    "print(\"Done!\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Save the graph datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(data_dir_graphs + dataset + \"_TRAIN_event_prediction_BOOOH.pkl\", \"wb\") as f:\n",
    "    pickle.dump(X_train, f)\n",
    "with open(data_dir_graphs + dataset + \"_VALID_event_prediction_BOOOH.pkl\", \"wb\") as f:\n",
    "    pickle.dump(X_valid, f)\n",
    "with open(data_dir_graphs + dataset + \"_TEST_event_prediction_BOOOH.pkl\", \"wb\") as f:\n",
    "    pickle.dump(X_test, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hgnn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
